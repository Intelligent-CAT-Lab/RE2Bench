<<FUNCTION_NAME>>

_get_empty_routing

<<CODE>>

from itertools import chain
from numbers import Integral, Real
import numpy as np
from sklearn.base import TransformerMixin, _fit_context, clone
from sklearn.utils import Bunch
from sklearn.utils._metadata_requests import METHODS
from sklearn.utils._param_validation import HasMethods, Hidden, Interval, StrOptions
from sklearn.utils.metaestimators import _BaseComposition

class ColumnTransformer(TransformerMixin, _BaseComposition):
    """Applies transformers to columns of an array or pandas DataFrame.

    This estimator allows different columns or column subsets of the input
    to be transformed separately and the features generated by each transformer
    will be concatenated to form a single feature space.
    This is useful for heterogeneous or columnar data, to combine several
    feature extraction mechanisms or transformations into a single transformer.

    Read more in the :ref:`User Guide <column_transformer>`.

    .. versionadded:: 0.20

    Parameters
    ----------
    transformers : list of tuples
        List of (name, transformer, columns) tuples specifying the
        transformer objects to be applied to subsets of the data.

        name : str
            Like in Pipeline and FeatureUnion, this allows the transformer and
            its parameters to be set using ``set_params`` and searched in grid
            search.
        transformer : {'drop', 'passthrough'} or estimator
            Estimator must support :term:`fit` and :term:`transform`.
            Special-cased strings 'drop' and 'passthrough' are accepted as
            well, to indicate to drop the columns or to pass them through
            untransformed, respectively.
        columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable
            Indexes the data on its second axis. Integers are interpreted as
            positional columns, while strings can reference DataFrame columns
            by name.  A scalar string or int should be used where
            ``transformer`` expects X to be a 1d array-like (vector),
            otherwise a 2d array will be passed to the transformer.
            A callable is passed the input data `X` and can return any of the
            above. To select multiple columns by name or dtype, you can use
            :obj:`make_column_selector`.

    remainder : {'drop', 'passthrough'} or estimator, default='drop'
        By default, only the specified columns in `transformers` are
        transformed and combined in the output, and the non-specified
        columns are dropped. (default of ``'drop'``).
        By specifying ``remainder='passthrough'``, all remaining columns that
        were not specified in `transformers`, but present in the data passed
        to `fit` will be automatically passed through. This subset of columns
        is concatenated with the output of the transformers. For dataframes,
        extra columns not seen during `fit` will be excluded from the output
        of `transform`.
        By setting ``remainder`` to be an estimator, the remaining
        non-specified columns will use the ``remainder`` estimator. The
        estimator must support :term:`fit` and :term:`transform`.
        Note that using this feature requires that the DataFrame columns
        input at :term:`fit` and :term:`transform` have identical order.

    sparse_threshold : float, default=0.3
        If the output of the different transformers contains sparse matrices,
        these will be stacked as a sparse matrix if the overall density is
        lower than this value. Use ``sparse_threshold=0`` to always return
        dense.  When the transformed output consists of all dense data, the
        stacked result will be dense, and this keyword will be ignored.

    n_jobs : int, default=None
        Number of jobs to run in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.

    transformer_weights : dict, default=None
        Multiplicative weights for features per transformer. The output of the
        transformer is multiplied by these weights. Keys are transformer names,
        values the weights.

    verbose : bool, default=False
        If True, the time elapsed while fitting each transformer will be
        printed as it is completed.

    verbose_feature_names_out : bool, str or Callable[[str, str], str], default=True

        - If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix
          all feature names with the name of the transformer that generated that
          feature. It is equivalent to setting
          `verbose_feature_names_out="{transformer_name}__{feature_name}"`.
        - If False, :meth:`ColumnTransformer.get_feature_names_out` will not
          prefix any feature names and will error if feature names are not
          unique.
        - If ``Callable[[str, str], str]``,
          :meth:`ColumnTransformer.get_feature_names_out` will rename all the features
          using the name of the transformer. The first argument of the callable is the
          transformer name and the second argument is the feature name. The returned
          string will be the new feature name.
        - If ``str``, it must be a string ready for formatting. The given string will
          be formatted using two field names: ``transformer_name`` and ``feature_name``.
          e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method
          from the standard library for more info.

        .. versionadded:: 1.0

        .. versionchanged:: 1.6
            `verbose_feature_names_out` can be a callable or a string to be formatted.

    force_int_remainder_cols : bool, default=False
        This parameter has no effect.

        .. note::
            If you do not access the list of columns for the remainder columns
            in the `transformers_` fitted attribute, you do not need to set
            this parameter.

        .. versionadded:: 1.5

        .. versionchanged:: 1.7
           The default value for `force_int_remainder_cols` will change from
           `True` to `False` in version 1.7.

        .. deprecated:: 1.7
           `force_int_remainder_cols` is deprecated and will be removed in 1.9.

    Attributes
    ----------
    transformers_ : list
        The collection of fitted transformers as tuples of (name,
        fitted_transformer, column). `fitted_transformer` can be an estimator,
        or `'drop'`; `'passthrough'` is replaced with an equivalent
        :class:`~sklearn.preprocessing.FunctionTransformer`. In case there were
        no columns selected, this will be the unfitted transformer. If there
        are remaining columns, the final element is a tuple of the form:
        ('remainder', transformer, remaining_columns) corresponding to the
        ``remainder`` parameter. If there are remaining columns, then
        ``len(transformers_)==len(transformers)+1``, otherwise
        ``len(transformers_)==len(transformers)``.

        .. versionadded:: 1.7
            The format of the remaining columns now attempts to match that of the other
            transformers: if all columns were provided as column names (`str`), the
            remaining columns are stored as column names; if all columns were provided
            as mask arrays (`bool`), so are the remaining columns; in all other cases
            the remaining columns are stored as indices (`int`).

    named_transformers_ : :class:`~sklearn.utils.Bunch`
        Read-only attribute to access any transformer by given name.
        Keys are transformer names and values are the fitted transformer
        objects.

    sparse_output_ : bool
        Boolean flag indicating whether the output of ``transform`` is a
        sparse matrix or a dense numpy array, which depends on the output
        of the individual transformers and the `sparse_threshold` keyword.

    output_indices_ : dict
        A dictionary from each transformer name to a slice, where the slice
        corresponds to indices in the transformed output. This is useful to
        inspect which transformer is responsible for which transformed
        feature(s).

        .. versionadded:: 1.0

    n_features_in_ : int
        Number of features seen during :term:`fit`. Only defined if the
        underlying transformers expose such an attribute when fit.

        .. versionadded:: 0.24

    feature_names_in_ : ndarray of shape (`n_features_in_`,)
        Names of features seen during :term:`fit`. Defined only when `X`
        has feature names that are all strings.

        .. versionadded:: 1.0

    See Also
    --------
    make_column_transformer : Convenience function for
        combining the outputs of multiple transformer objects applied to
        column subsets of the original feature space.
    make_column_selector : Convenience function for selecting
        columns based on datatype or the columns name with a regex pattern.

    Notes
    -----
    The order of the columns in the transformed feature matrix follows the
    order of how the columns are specified in the `transformers` list.
    Columns of the original feature matrix that are not specified are
    dropped from the resulting transformed feature matrix, unless specified
    in the `passthrough` keyword. Those columns specified with `passthrough`
    are added at the right to the output of the transformers.

    Examples
    --------
    >>> import numpy as np
    >>> from sklearn.compose import ColumnTransformer
    >>> from sklearn.preprocessing import Normalizer
    >>> ct = ColumnTransformer(
    ...     [("norm1", Normalizer(norm='l1'), [0, 1]),
    ...      ("norm2", Normalizer(norm='l1'), slice(2, 4))])
    >>> X = np.array([[0., 1., 2., 2.],
    ...               [1., 1., 0., 1.]])
    >>> # Normalizer scales each row of X to unit norm. A separate scaling
    >>> # is applied for the two first and two last elements of each
    >>> # row independently.
    >>> ct.fit_transform(X)
    array([[0. , 1. , 0.5, 0.5],
           [0.5, 0.5, 0. , 1. ]])

    :class:`ColumnTransformer` can be configured with a transformer that requires
    a 1d array by setting the column to a string:

    >>> from sklearn.feature_extraction.text import CountVectorizer
    >>> from sklearn.preprocessing import MinMaxScaler
    >>> import pandas as pd   # doctest: +SKIP
    >>> X = pd.DataFrame({
    ...     "documents": ["First item", "second one here", "Is this the last?"],
    ...     "width": [3, 4, 5],
    ... })  # doctest: +SKIP
    >>> # "documents" is a string which configures ColumnTransformer to
    >>> # pass the documents column as a 1d array to the CountVectorizer
    >>> ct = ColumnTransformer(
    ...     [("text_preprocess", CountVectorizer(), "documents"),
    ...      ("num_preprocess", MinMaxScaler(), ["width"])])
    >>> X_trans = ct.fit_transform(X)  # doctest: +SKIP

    For a more detailed example of usage, see
    :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py`.
    """
    _parameter_constraints: dict = {'transformers': [list, Hidden(tuple)], 'remainder': [StrOptions({'drop', 'passthrough'}), HasMethods(['fit', 'transform']), HasMethods(['fit_transform', 'transform'])], 'sparse_threshold': [Interval(Real, 0, 1, closed='both')], 'n_jobs': [Integral, None], 'transformer_weights': [dict, None], 'verbose': ['verbose'], 'verbose_feature_names_out': ['boolean', str, callable], 'force_int_remainder_cols': ['boolean', Hidden(StrOptions({'deprecated'}))]}

    def __init__(self, transformers, *, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False, verbose_feature_names_out=True, force_int_remainder_cols='deprecated'):
        self.transformers = transformers
        self.remainder = remainder
        self.sparse_threshold = sparse_threshold
        self.n_jobs = n_jobs
        self.transformer_weights = transformer_weights
        self.verbose = verbose
        self.verbose_feature_names_out = verbose_feature_names_out
        self.force_int_remainder_cols = force_int_remainder_cols

    def _iter(self, fitted, column_as_labels, skip_drop, skip_empty_columns):
        """
        Generate (name, trans, columns, weight) tuples.


        Parameters
        ----------
        fitted : bool
            If True, use the fitted transformers (``self.transformers_``) to
            iterate through transformers, else use the transformers passed by
            the user (``self.transformers``).

        column_as_labels : bool
            If True, columns are returned as string labels. If False, columns
            are returned as they were given by the user. This can only be True
            if the ``ColumnTransformer`` is already fitted.

        skip_drop : bool
            If True, 'drop' transformers are filtered out.

        skip_empty_columns : bool
            If True, transformers with empty selected columns are filtered out.

        Yields
        ------
        A generator of tuples containing:
            - name : the name of the transformer
            - transformer : the transformer object
            - columns : the columns for that transformer
            - weight : the weight of the transformer
        """
        if fitted:
            transformers = self.transformers_
        else:
            transformers = [(name, trans, column) for (name, trans, _), column in zip(self.transformers, self._columns)]
            if self._remainder[2]:
                transformers = chain(transformers, [self._remainder])
        get_weight = (self.transformer_weights or {}).get
        for name, trans, columns in transformers:
            if skip_drop and trans == 'drop':
                continue
            if skip_empty_columns and _is_empty_column_selection(columns):
                continue
            if column_as_labels:
                columns_is_scalar = np.isscalar(columns)
                indices = self._transformer_to_input_indices[name]
                columns = self.feature_names_in_[indices]
                if columns_is_scalar:
                    columns = columns[0]
            yield (name, trans, columns, get_weight(name))

    def _get_empty_routing(self):
        """Return empty routing.

        Used while routing can be disabled.

        TODO: Remove when ``set_config(enable_metadata_routing=False)`` is no
        more an option.
        """
        return Bunch(**{name: Bunch(**{method: {} for method in METHODS}) for name, step, _, _ in self._iter(fitted=False, column_as_labels=False, skip_drop=True, skip_empty_columns=True)})


<<GROUND_TRUTH_INPUT>>

{'self': {'transformers': [['trans', 'Trans()', '<function test_column_transformer.<locals>.<lambda> at 0x70e5fc5df600>']], 'remainder': 'drop', 'sparse_threshold': 0.3, 'n_jobs': None, 'transformer_weights': None, 'verbose': False, 'verbose_feature_names_out': True, 'force_int_remainder_cols': 'deprecated', 'n_features_in_': 2, '_columns': [0], '_transformer_to_input_indices': {'trans': [0], 'remainder': [1]}, '_remainder': ['remainder', 'drop', [1]]}, 'args': {}, 'kwargs': {}}

<<GROUND_TRUTH_OUTPUT>>

{'trans': {'fit': {}, 'partial_fit': {}, 'predict': {}, 'predict_proba': {}, 'predict_log_proba': {}, 'decision_function': {}, 'score': {}, 'split': {}, 'transform': {}, 'inverse_transform': {}, 'fit_transform': {}, 'fit_predict': {}}}

<<LLM_RESPONSE>>

[THOUGHT]
Let me trace through the execution of `_get_empty_routing()` to determine what input would produce the given output.

The method calls:
```python
return Bunch(**{name: Bunch(**{method: {} for method in METHODS}) for name, step, _, _ in self._iter(fitted=False, column_as_labels=False, skip_drop=True, skip_empty_columns=True)})
```

The output shows:
```json
{
    "trans": { "fit": {}, "partial_fit": {}, ... }
}
```

This means `_iter()` yielded exactly one tuple with `name="trans"`.

Looking at `_iter()` with `fitted=False`:
```python
transformers = [(name, trans, column) for (name, trans, _), column in zip(self.transformers, self._columns)]
if self._remainder[2]:
    transformers = chain(transformers, [self._remainder])
```

For `_iter` to yield only "trans":
1. We need exactly one transformer tuple: `("trans", <non-drop-transformer>, <non-empty-columns>)`
2. `self._remainder[2]` must be falsy so remainder is not added
3. The skip_drop and skip_empty_columns checks must not filter it out

Tracing through with candidate values:
- `transformers = [("trans", "passthrough", [0])]`
- `_columns = [[0]]`
- This creates `transformers_list = [("trans", "passthrough", [0])]`
- `_remainder[2] = False`, so remainder is not chained
- Loop iteration:
  - name="trans", trans="passthrough", columns=[0]
  - Not skipped (trans != 'drop' and columns not empty)
  - Yields: ("trans", "passthrough", [0], weight)
- Result: dict comprehension creates `{"trans": Bunch({method: {} for method in METHODS})}`

This matches the expected output structure!
</THOUGHT]

[INPUT]
```
{
    "self": {
        "transformers": [
            ["trans", "passthrough", [0]]
        ],
        "remainder": "drop",
        "sparse_threshold": 0.3,
        "n_jobs": null,
        "transformer_weights": null,
        "verbose": false,
        "verbose_feature_names_out": true,
        "force_int_remainder_cols": "deprecated",
        "n_features_in_": 1,
        "_columns": [[0]],
        "_transformer_to_input_indices": {
            "trans": [0],
            "remainder": []
        },
        "_remainder": ["remainder", "drop", false]
    },
    "args": {},
    "kwargs": {}
}
```
[/INPUT]