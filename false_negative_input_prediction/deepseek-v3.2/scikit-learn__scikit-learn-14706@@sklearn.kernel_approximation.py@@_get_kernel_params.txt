<<FUNCTION_NAME>>

_get_kernel_params

<<CODE>>

import warnings
import numpy as np
import scipy.sparse as sp
from scipy.linalg import svd
from .base import BaseEstimator
from .base import TransformerMixin
from .utils import check_array, check_random_state, as_float_array
from .utils.extmath import safe_sparse_dot
from .utils.validation import check_is_fitted
from .metrics.pairwise import pairwise_kernels, KERNEL_PARAMS



class Nystroem(BaseEstimator, TransformerMixin):
    """Approximate a kernel map using a subset of the training data.

    Constructs an approximate feature map for an arbitrary kernel
    using a subset of the data as basis.

    Read more in the :ref:`User Guide <nystroem_kernel_approx>`.

    Parameters
    ----------
    kernel : string or callable, default="rbf"
        Kernel map to be approximated. A callable should accept two arguments
        and the keyword arguments passed to this object as kernel_params, and
        should return a floating point number.

    gamma : float, default=None
        Gamma parameter for the RBF, laplacian, polynomial, exponential chi2
        and sigmoid kernels. Interpretation of the default value is left to
        the kernel; see the documentation for sklearn.metrics.pairwise.
        Ignored by other kernels.

    coef0 : float, default=None
        Zero coefficient for polynomial and sigmoid kernels.
        Ignored by other kernels.

    degree : float, default=None
        Degree of the polynomial kernel. Ignored by other kernels.

    kernel_params : mapping of string to any, optional
        Additional parameters (keyword arguments) for kernel function passed
        as callable object.

    n_components : int
        Number of features to construct.
        How many data points will be used to construct the mapping.

    random_state : int, RandomState instance or None, optional (default=None)
        If int, random_state is the seed used by the random number generator;
        If RandomState instance, random_state is the random number generator;
        If None, the random number generator is the RandomState instance used
        by `np.random`.

    Attributes
    ----------
    components_ : array, shape (n_components, n_features)
        Subset of training points used to construct the feature map.

    component_indices_ : array, shape (n_components)
        Indices of ``components_`` in the training set.

    normalization_ : array, shape (n_components, n_components)
        Normalization matrix needed for embedding.
        Square root of the kernel matrix on ``components_``.

    Examples
    --------
    >>> from sklearn import datasets, svm
    >>> from sklearn.kernel_approximation import Nystroem
    >>> X, y = datasets.load_digits(n_class=9, return_X_y=True)
    >>> data = X / 16.
    >>> clf = svm.LinearSVC()
    >>> feature_map_nystroem = Nystroem(gamma=.2,
    ...                                 random_state=1,
    ...                                 n_components=300)
    >>> data_transformed = feature_map_nystroem.fit_transform(data)
    >>> clf.fit(data_transformed, y)
    LinearSVC()
    >>> clf.score(data_transformed, y)
    0.9987...

    References
    ----------
    * Williams, C.K.I. and Seeger, M.
      "Using the Nystroem method to speed up kernel machines",
      Advances in neural information processing systems 2001

    * T. Yang, Y. Li, M. Mahdavi, R. Jin and Z. Zhou
      "Nystroem Method vs Random Fourier Features: A Theoretical and Empirical
      Comparison",
      Advances in Neural Information Processing Systems 2012


    See also
    --------
    RBFSampler : An approximation to the RBF kernel using random Fourier
                 features.

    sklearn.metrics.pairwise.kernel_metrics : List of built-in kernels.
    """

    def __init__(self, kernel="rbf", gamma=None, coef0=None, degree=None,
                 kernel_params=None, n_components=100, random_state=None):
        self.kernel = kernel
        self.gamma = gamma
        self.coef0 = coef0
        self.degree = degree
        self.kernel_params = kernel_params
        self.n_components = n_components
        self.random_state = random_state

    def fit(self, X, y=None):
        """Fit estimator to data.

        Samples a subset of training points, computes kernel
        on these and computes normalization matrix.

        Parameters
        ----------
        X : array-like, shape=(n_samples, n_feature)
            Training data.
        """
        X = check_array(X, accept_sparse='csr')
        rnd = check_random_state(self.random_state)
        n_samples = X.shape[0]

        # get basis vectors
        if self.n_components > n_samples:
            # XXX should we just bail?
            n_components = n_samples
            warnings.warn("n_components > n_samples. This is not possible.\n"
                          "n_components was set to n_samples, which results"
                          " in inefficient evaluation of the full kernel.")

        else:
            n_components = self.n_components
        n_components = min(n_samples, n_components)
        inds = rnd.permutation(n_samples)
        basis_inds = inds[:n_components]
        basis = X[basis_inds]

        basis_kernel = pairwise_kernels(basis, metric=self.kernel,
                                        filter_params=True,
                                        **self._get_kernel_params())

        # sqrt of kernel matrix on basis vectors
        U, S, V = svd(basis_kernel)
        S = np.maximum(S, 1e-12)
        self.normalization_ = np.dot(U / np.sqrt(S), V)
        self.components_ = basis
        self.component_indices_ = inds
        return self

    def transform(self, X):
        """Apply feature map to X.

        Computes an approximate feature map using the kernel
        between some training points and X.

        Parameters
        ----------
        X : array-like, shape=(n_samples, n_features)
            Data to transform.

        Returns
        -------
        X_transformed : array, shape=(n_samples, n_components)
            Transformed data.
        """
        check_is_fitted(self)
        X = check_array(X, accept_sparse='csr')

        kernel_params = self._get_kernel_params()
        embedded = pairwise_kernels(X, self.components_,
                                    metric=self.kernel,
                                    filter_params=True,
                                    **kernel_params)
        return np.dot(embedded, self.normalization_.T)

    def _get_kernel_params(self):
        params = self.kernel_params
        if params is None:
            params = {}
        if not callable(self.kernel) and self.kernel != 'precomputed':
            for param in (KERNEL_PARAMS[self.kernel]):
                if getattr(self, param) is not None:
                    params[param] = getattr(self, param)
        else:
            if (self.gamma is not None or
                    self.coef0 is not None or
                    self.degree is not None):
                raise ValueError("Don't pass gamma, coef0 or degree to "
                                 "Nystroem if using a callable "
                                 "or precomputed kernel")

        return params


<<GROUND_TRUTH_INPUT>>

{'self': {'kernel': 'polynomial', 'gamma': None, 'coef0': 0.1, 'degree': 3.1, 'kernel_params': None, 'n_components': 10, 'random_state': None, 'normalization_': '[[ 30.17354652  -1.35671868  -1.50205958   0.82627223  -6.95460029\n    1.41772554  -1.44371499  -1.50605883   4.49574041  -0.14719941]\n [ -1.35671868   6.20684165   0.69105551  -1.73611448   0.51356651\n   -1.10798135   0.10508688  -1.6259864    1.14171044   0.67861028]\n [ -1.50205958   0.69105551  14.68750245   2.71840442   0.06028339\n   -7.1360436   -5.56257824  -0.16616765  -1.87130863   1.27559974]\n [  0.82627223  -1.73611448   2.71840442   6.81177684  -0.96451827\n   -0.70058553  -5.43115502  -1.41376713  -1.5935794    0.28483002]\n [ -6.95460029   0.51356651   0.06028339  -0.96451827  19.75134411\n   -0.12227175  -0.3435224    3.14156305 -17.40051419   2.54551552]\n [  1.41772554  -1.10798135  -7.1360436   -0.70058553  -0.12227175\n    8.60460385  -0.45270216   0.11249333   2.65873729  -2.9413417 ]\n [ -1.44371499   0.10508688  -5.56257824  -5.43115502  -0.3435224\n   -0.45270216  12.0313862    2.02760042   0.13739215  -0.59148049]\n [ -1.50605883  -1.6259864   -0.16616765  -1.41376713   3.14156305\n    0.11249333   2.02760042   8.37227054  -5.97380761  -1.50790787]\n [  4.49574041   1.14171044  -1.87130863  -1.5935794  -17.40051419\n    2.65873729   0.13739215  -5.97380761  28.11929534  -6.19148412]\n [ -0.14719941   0.67861028   1.27559974   0.28483002   2.54551552\n   -2.9413417   -0.59148049  -1.50790787  -6.19148412   6.80808215]]', 'components_': '[[0.05122983 0.13481199 0.11702851 0.36472476]\n [0.64027138 0.01913701 0.80603837 0.40489265]\n [0.17893745 0.90253449 0.76357569 0.19886053]\n [0.59595113 0.57337695 0.70494935 0.92926202]\n [0.36568617 0.59558227 0.04009427 0.82462798]\n [0.44348884 0.96346535 0.89706655 0.19680429]\n [0.28197907 0.75342459 0.79270563 0.6274006 ]\n [0.9444966  0.46409817 0.19279503 0.58189488]\n [0.62008421 0.68422402 0.10343756 0.74547577]\n [0.80341084 0.97024272 0.33297926 0.47841987]]', 'component_indices_': '[5 9 7 4 8 3 2 0 1 6]'}, 'args': {}, 'kwargs': {}}

<<GROUND_TRUTH_OUTPUT>>

{'coef0': 0.1, 'degree': 3.1}

<<LLM_RESPONSE>>

Let's go step-by-step.

1. Looking at the `_get_kernel_params` method:
   - It first checks if `self.kernel_params` is not None. If it's not None, it starts with that dict.
   - If `self.kernel_params` is None, it starts with an empty dict `{}`.
   - Then, if `self.kernel` is not callable and not 'precomputed', it checks `KERNEL_PARAMS[self.kernel]` for valid parameters (like `gamma`, `coef0`, `degree`, etc.).
   - For each parameter in that list, if `getattr(self, param)` is not None, it adds it to `params`.
   - Finally, returns `params`.

2. In the given output, we have `{"coef0": 0.1, "degree": 3.1}`.  
   This means `params` ends up containing only `coef0` and `degree`.

3. This could happen in two ways:
   - Either `self.kernel_params` already contained exactly `{"coef0": 0.1, "degree": 3.1}`.
   - Or `self.kernel_params` was None or empty, and the kernel type was something like `'poly'` (which uses `coef0` and `degree`), and `gamma` was None, so only `coef0` and `degree` got added.

4. But note: `KERNEL_PARAMS` is imported from `sklearn.metrics.pairwise`. From sklearn documentation, for `'poly'` kernel, valid parameters are `('gamma', 'coef0', 'degree')`.  
   If `self.gamma` is None, it wouldn't be added. So if kernel is `'poly'`, `gamma=None`, `coef0=0.1`, `degree=3.1`, and `kernel_params=None`, then `_get_kernel_params` would return `{"coef0": 0.1, "degree": 3.1}`.

5. Also, the output does not include `gamma`, so either `gamma` is None or kernel_params overrides it. But since kernel_params is initially taken from `self.kernel_params` if not None, and if kernel_params already had `coef0` and `degree`, it wouldn't go into the `if not callable(self.kernel)...` block to add gamma anyway.

6. Let’s test both possibilities:
   - If `kernel_params` already contains exactly `{"coef0": 0.1, "degree": 3.1}` and kernel is `'poly'`, then `gamma` might still be None and not added because `kernel_params` dict is used directly.
   - But the code says: if `kernel_params` is None → start empty dict, then add from attributes.  
     If `kernel_params` is not None → use that dict and **skip** adding from attributes? Wait, no:  
     Looking at the code:  
     ```
     params = self.kernel_params
     if params is None:
         params = {}
     if not callable(self.kernel) and self.kernel != 'precomputed':
         for param in KERNEL_PARAMS[self.kernel]:
             if getattr(self, param) is not None:
                 params[param] = getattr(self, param)
     ```
     So even if `self.kernel_params` is not None, it still goes into the loop and potentially **overwrites** or adds attributes from `self`.  
     So if `self.kernel_params` already has `coef0=0.1`, but `self.coef0` is `0.2`, then `self.coef0` would overwrite `params['coef0']` with `0.2`.  
     So for final `params['coef0']` to be `0.1`, either `self.coef0` is `0.1` and `kernel_params` is None (so `params['coef0']` gets 0.1 from `self.coef0`), or `kernel_params` already has `0.1` and `self.coef0` is None (so it's not added/overwritten).

7. The output is exactly `{"coef0": 0.1, "degree": 3.1}`. So `gamma` key is missing, which means `self.gamma` must be None (otherwise it would be added if kernel supports it). So kernel supports `gamma` but `gamma` is None.

8. The kernel must be one that includes `'coef0'` and `'degree'` in `KERNEL_PARAMS`. That is `'poly'` or maybe `'sigmoid'`? Let's check sklearn source:  
   For `'poly'`: `('gamma', 'coef0', 'degree')`  
   For `'sigmoid'`: `('gamma', 'coef0')` → no `degree`, so can't output degree.  
   So kernel must be `'poly'`.

9. Also, `self.degree` must be `3.1`, `self.coef0` must be `0.1`, `self.gamma` None, `self.kernel_params` None, `kernel='poly'`.

10. Other attributes (`n_components`, `random_state`, `normalization_`, `components_`, `component_indices_`) are irrelevant for `_get_kernel_params`.

Thus the input:

```
{
    "self": {
        "kernel": "poly",
        "gamma": null,
        "coef0": 0.1,
        "degree": 3.1,
        "kernel_params": null,
        "n_components": 100,
        "random_state": null,
        "normalization_": null,
        "components_": null,
        "component_indices_": null
    },
    "args": {},
    "kwargs": {}
}
```

But wait: if `kernel_params` is None, the output would also include `gamma: null` if `gamma` is in `KERNEL_PARAMS['poly']` and `self.gamma` is None?  
No — the code only adds param to `params` if `getattr(self, param) is not None`. Since `self.gamma` is None, it won't add `gamma` to params. So output correctly lacks `gamma`.

Perfect.

[INPUT]
```
{
    "self": {
        "kernel": "poly",
        "gamma": null,
        "coef0": 0.1,
        "degree": 3.1,
        "kernel_params": null,
        "n_components": 100,
        "random_state": null,
        "normalization_": null,
        "components_": null,
        "component_indices_": null
    },
    "args": {},
    "kwargs": {}
}
```
[/INPUT]