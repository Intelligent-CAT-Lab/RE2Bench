[THOUGHT]
1. precision_score calls precision_recall_fscore_support with average='binary' (default). For average='binary' the function computes precision for the positive class pos_label=1.
2. Precision = TP / (TP + FP). To get precision == 1.0 we need at least one predicted positive and zero false positives (all predicted positives must be true positives).
3. Choose simple matching arrays where predicted positives are exactly true positives. For example y_true = [0, 1] and y_pred = [0, 1]:
   - predicted positives = 1 (one '1' in y_pred)
   - true positives = 1 (that predicted '1' matches a '1' in y_true)
   - precision = 1 / 1 = 1.0
4. These arrays are 1D, same length, and produce y_type='binary', so no errors occur in the internal checks.

Therefore the input is y_true=[0,1], y_pred=[0,1].
[/THOUGHT]

[INPUT]
```
{
    "self": {},
    "args": {
        "y_true": [0, 1],
        "y_pred": [0, 1]
    },
    "kwargs": {}
}
```
