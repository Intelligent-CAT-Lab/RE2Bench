[THOUGHT]
We need the input that leads _compute_missing_values_in_feature_mask to return None.

Looking at the code flow:
- The function first sets estimator_name default, builds common_kwargs.
- If not self._support_missing_values(X): it calls assert_all_finite(X, **common_kwargs) and then returns None.
- Otherwise it computes overall_sum = np.sum(X); if overall_sum is finite (not NaN) it returns None.

Easiest guaranteed way to get None without raising is to make _support_missing_values return False, and ensure assert_all_finite does not raise (i.e., X contains only finite values). _support_missing_values returns:
  not issparse(X) and self.__sklearn_tags__().input_tags.allow_nan and (self.monotonic_cst is None)

So setting monotonic_cst to a non-None value forces _support_missing_values to be False. Then provide X as a numeric 2D array with only finite values (e.g., [[1.0, 2.0], [3.0, 4.0]]) so assert_all_finite succeeds and the function returns None.

estimator_name can be left null to allow the function to set the default class name.

All other attributes on self can be reasonable typical values; they are not used by the chosen branch but must be present in the structure.

Therefore I set monotonic_cst to a non-null value (e.g., [0]) and X to a finite numeric array. estimator_name is null. Other parameters are filled with plausible values.
[/THOUGHT]

[INPUT]
```
{
    "self": {
        "criterion": "gini",
        "splitter": "best",
        "max_depth": null,
        "min_samples_split": 2,
        "min_samples_leaf": 1,
        "min_weight_fraction_leaf": 0.0,
        "max_features": null,
        "max_leaf_nodes": null,
        "random_state": 0,
        "min_impurity_decrease": 0.0,
        "class_weight": null,
        "ccp_alpha": 0.0,
        "monotonic_cst": [0],
        "n_features_in_": 2
    },
    "args": {
        "X": [[1.0, 2.0], [3.0, 4.0]],
        "estimator_name": null
    },
    "kwargs": {}
}
```
[/INPUT]