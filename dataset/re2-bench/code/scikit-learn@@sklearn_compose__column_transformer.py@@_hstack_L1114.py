from collections import Counter
from functools import partial
from itertools import chain
from numbers import Integral, Real
import numpy as np
from scipy import sparse
from sklearn.base import TransformerMixin, _fit_context, clone
from sklearn.utils._param_validation import HasMethods, Hidden, Interval, StrOptions
from sklearn.utils._set_output import (
    _get_container_adapter,
    _get_output_config,
    _safe_set_output,
)
from sklearn.utils.metaestimators import _BaseComposition
from sklearn.utils.validation import (
    _check_feature_names_in,
    _check_n_features,
    _get_feature_names,
    _is_pandas_df,
    _num_samples,
    check_array,
    check_is_fitted,
    validate_data,
)

class ColumnTransformer(TransformerMixin, _BaseComposition):
    """Applies transformers to columns of an array or pandas DataFrame.

    This estimator allows different columns or column subsets of the input
    to be transformed separately and the features generated by each transformer
    will be concatenated to form a single feature space.
    This is useful for heterogeneous or columnar data, to combine several
    feature extraction mechanisms or transformations into a single transformer.

    Read more in the :ref:`User Guide <column_transformer>`.

    .. versionadded:: 0.20

    Parameters
    ----------
    transformers : list of tuples
        List of (name, transformer, columns) tuples specifying the
        transformer objects to be applied to subsets of the data.

        name : str
            Like in Pipeline and FeatureUnion, this allows the transformer and
            its parameters to be set using ``set_params`` and searched in grid
            search.
        transformer : {'drop', 'passthrough'} or estimator
            Estimator must support :term:`fit` and :term:`transform`.
            Special-cased strings 'drop' and 'passthrough' are accepted as
            well, to indicate to drop the columns or to pass them through
            untransformed, respectively.
        columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable
            Indexes the data on its second axis. Integers are interpreted as
            positional columns, while strings can reference DataFrame columns
            by name.  A scalar string or int should be used where
            ``transformer`` expects X to be a 1d array-like (vector),
            otherwise a 2d array will be passed to the transformer.
            A callable is passed the input data `X` and can return any of the
            above. To select multiple columns by name or dtype, you can use
            :obj:`make_column_selector`.

    remainder : {'drop', 'passthrough'} or estimator, default='drop'
        By default, only the specified columns in `transformers` are
        transformed and combined in the output, and the non-specified
        columns are dropped. (default of ``'drop'``).
        By specifying ``remainder='passthrough'``, all remaining columns that
        were not specified in `transformers`, but present in the data passed
        to `fit` will be automatically passed through. This subset of columns
        is concatenated with the output of the transformers. For dataframes,
        extra columns not seen during `fit` will be excluded from the output
        of `transform`.
        By setting ``remainder`` to be an estimator, the remaining
        non-specified columns will use the ``remainder`` estimator. The
        estimator must support :term:`fit` and :term:`transform`.
        Note that using this feature requires that the DataFrame columns
        input at :term:`fit` and :term:`transform` have identical order.

    sparse_threshold : float, default=0.3
        If the output of the different transformers contains sparse matrices,
        these will be stacked as a sparse matrix if the overall density is
        lower than this value. Use ``sparse_threshold=0`` to always return
        dense.  When the transformed output consists of all dense data, the
        stacked result will be dense, and this keyword will be ignored.

    n_jobs : int, default=None
        Number of jobs to run in parallel.
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`
        for more details.

    transformer_weights : dict, default=None
        Multiplicative weights for features per transformer. The output of the
        transformer is multiplied by these weights. Keys are transformer names,
        values the weights.

    verbose : bool, default=False
        If True, the time elapsed while fitting each transformer will be
        printed as it is completed.

    verbose_feature_names_out : bool, str or Callable[[str, str], str], default=True

        - If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix
          all feature names with the name of the transformer that generated that
          feature. It is equivalent to setting
          `verbose_feature_names_out="{transformer_name}__{feature_name}"`.
        - If False, :meth:`ColumnTransformer.get_feature_names_out` will not
          prefix any feature names and will error if feature names are not
          unique.
        - If ``Callable[[str, str], str]``,
          :meth:`ColumnTransformer.get_feature_names_out` will rename all the features
          using the name of the transformer. The first argument of the callable is the
          transformer name and the second argument is the feature name. The returned
          string will be the new feature name.
        - If ``str``, it must be a string ready for formatting. The given string will
          be formatted using two field names: ``transformer_name`` and ``feature_name``.
          e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method
          from the standard library for more info.

        .. versionadded:: 1.0

        .. versionchanged:: 1.6
            `verbose_feature_names_out` can be a callable or a string to be formatted.

    force_int_remainder_cols : bool, default=False
        This parameter has no effect.

        .. note::
            If you do not access the list of columns for the remainder columns
            in the `transformers_` fitted attribute, you do not need to set
            this parameter.

        .. versionadded:: 1.5

        .. versionchanged:: 1.7
           The default value for `force_int_remainder_cols` will change from
           `True` to `False` in version 1.7.

        .. deprecated:: 1.7
           `force_int_remainder_cols` is deprecated and will be removed in 1.9.

    Attributes
    ----------
    transformers_ : list
        The collection of fitted transformers as tuples of (name,
        fitted_transformer, column). `fitted_transformer` can be an estimator,
        or `'drop'`; `'passthrough'` is replaced with an equivalent
        :class:`~sklearn.preprocessing.FunctionTransformer`. In case there were
        no columns selected, this will be the unfitted transformer. If there
        are remaining columns, the final element is a tuple of the form:
        ('remainder', transformer, remaining_columns) corresponding to the
        ``remainder`` parameter. If there are remaining columns, then
        ``len(transformers_)==len(transformers)+1``, otherwise
        ``len(transformers_)==len(transformers)``.

        .. versionadded:: 1.7
            The format of the remaining columns now attempts to match that of the other
            transformers: if all columns were provided as column names (`str`), the
            remaining columns are stored as column names; if all columns were provided
            as mask arrays (`bool`), so are the remaining columns; in all other cases
            the remaining columns are stored as indices (`int`).

    named_transformers_ : :class:`~sklearn.utils.Bunch`
        Read-only attribute to access any transformer by given name.
        Keys are transformer names and values are the fitted transformer
        objects.

    sparse_output_ : bool
        Boolean flag indicating whether the output of ``transform`` is a
        sparse matrix or a dense numpy array, which depends on the output
        of the individual transformers and the `sparse_threshold` keyword.

    output_indices_ : dict
        A dictionary from each transformer name to a slice, where the slice
        corresponds to indices in the transformed output. This is useful to
        inspect which transformer is responsible for which transformed
        feature(s).

        .. versionadded:: 1.0

    n_features_in_ : int
        Number of features seen during :term:`fit`. Only defined if the
        underlying transformers expose such an attribute when fit.

        .. versionadded:: 0.24

    feature_names_in_ : ndarray of shape (`n_features_in_`,)
        Names of features seen during :term:`fit`. Defined only when `X`
        has feature names that are all strings.

        .. versionadded:: 1.0

    See Also
    --------
    make_column_transformer : Convenience function for
        combining the outputs of multiple transformer objects applied to
        column subsets of the original feature space.
    make_column_selector : Convenience function for selecting
        columns based on datatype or the columns name with a regex pattern.

    Notes
    -----
    The order of the columns in the transformed feature matrix follows the
    order of how the columns are specified in the `transformers` list.
    Columns of the original feature matrix that are not specified are
    dropped from the resulting transformed feature matrix, unless specified
    in the `passthrough` keyword. Those columns specified with `passthrough`
    are added at the right to the output of the transformers.

    Examples
    --------
    >>> import numpy as np
    >>> from sklearn.compose import ColumnTransformer
    >>> from sklearn.preprocessing import Normalizer
    >>> ct = ColumnTransformer(
    ...     [("norm1", Normalizer(norm='l1'), [0, 1]),
    ...      ("norm2", Normalizer(norm='l1'), slice(2, 4))])
    >>> X = np.array([[0., 1., 2., 2.],
    ...               [1., 1., 0., 1.]])
    >>> # Normalizer scales each row of X to unit norm. A separate scaling
    >>> # is applied for the two first and two last elements of each
    >>> # row independently.
    >>> ct.fit_transform(X)
    array([[0. , 1. , 0.5, 0.5],
           [0.5, 0.5, 0. , 1. ]])

    :class:`ColumnTransformer` can be configured with a transformer that requires
    a 1d array by setting the column to a string:

    >>> from sklearn.feature_extraction.text import CountVectorizer
    >>> from sklearn.preprocessing import MinMaxScaler
    >>> import pandas as pd   # doctest: +SKIP
    >>> X = pd.DataFrame({
    ...     "documents": ["First item", "second one here", "Is this the last?"],
    ...     "width": [3, 4, 5],
    ... })  # doctest: +SKIP
    >>> # "documents" is a string which configures ColumnTransformer to
    >>> # pass the documents column as a 1d array to the CountVectorizer
    >>> ct = ColumnTransformer(
    ...     [("text_preprocess", CountVectorizer(), "documents"),
    ...      ("num_preprocess", MinMaxScaler(), ["width"])])
    >>> X_trans = ct.fit_transform(X)  # doctest: +SKIP

    For a more detailed example of usage, see
    :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py`.
    """
    _parameter_constraints: dict = {'transformers': [list, Hidden(tuple)], 'remainder': [StrOptions({'drop', 'passthrough'}), HasMethods(['fit', 'transform']), HasMethods(['fit_transform', 'transform'])], 'sparse_threshold': [Interval(Real, 0, 1, closed='both')], 'n_jobs': [Integral, None], 'transformer_weights': [dict, None], 'verbose': ['verbose'], 'verbose_feature_names_out': ['boolean', str, callable], 'force_int_remainder_cols': ['boolean', Hidden(StrOptions({'deprecated'}))]}

    def __init__(self, transformers, *, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False, verbose_feature_names_out=True, force_int_remainder_cols='deprecated'):
        self.transformers = transformers
        self.remainder = remainder
        self.sparse_threshold = sparse_threshold
        self.n_jobs = n_jobs
        self.transformer_weights = transformer_weights
        self.verbose = verbose
        self.verbose_feature_names_out = verbose_feature_names_out
        self.force_int_remainder_cols = force_int_remainder_cols

    def _iter(self, fitted, column_as_labels, skip_drop, skip_empty_columns):
        """
        Generate (name, trans, columns, weight) tuples.


        Parameters
        ----------
        fitted : bool
            If True, use the fitted transformers (``self.transformers_``) to
            iterate through transformers, else use the transformers passed by
            the user (``self.transformers``).

        column_as_labels : bool
            If True, columns are returned as string labels. If False, columns
            are returned as they were given by the user. This can only be True
            if the ``ColumnTransformer`` is already fitted.

        skip_drop : bool
            If True, 'drop' transformers are filtered out.

        skip_empty_columns : bool
            If True, transformers with empty selected columns are filtered out.

        Yields
        ------
        A generator of tuples containing:
            - name : the name of the transformer
            - transformer : the transformer object
            - columns : the columns for that transformer
            - weight : the weight of the transformer
        """
        if fitted:
            transformers = self.transformers_
        else:
            transformers = [(name, trans, column) for (name, trans, _), column in zip(self.transformers, self._columns)]
            if self._remainder[2]:
                transformers = chain(transformers, [self._remainder])
        get_weight = (self.transformer_weights or {}).get
        for name, trans, columns in transformers:
            if skip_drop and trans == 'drop':
                continue
            if skip_empty_columns and _is_empty_column_selection(columns):
                continue
            if column_as_labels:
                columns_is_scalar = np.isscalar(columns)
                indices = self._transformer_to_input_indices[name]
                columns = self.feature_names_in_[indices]
                if columns_is_scalar:
                    columns = columns[0]
            yield (name, trans, columns, get_weight(name))

    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):
        """Add prefix for feature names out that includes the transformer names.

        Parameters
        ----------
        transformer_with_feature_names_out : list of tuples of (str, array-like of str)
            The tuple consistent of the transformer's name and its feature names out.

        Returns
        -------
        feature_names_out : ndarray of shape (n_features,), dtype=str
            Transformed feature names.
        """
        feature_names_out_callable = None
        if callable(self.verbose_feature_names_out):
            feature_names_out_callable = self.verbose_feature_names_out
        elif isinstance(self.verbose_feature_names_out, str):
            feature_names_out_callable = partial(_feature_names_out_with_str_format, str_format=self.verbose_feature_names_out)
        elif self.verbose_feature_names_out is True:
            feature_names_out_callable = partial(_feature_names_out_with_str_format, str_format='{transformer_name}__{feature_name}')
        if feature_names_out_callable is not None:
            names = list(chain.from_iterable(((feature_names_out_callable(name, i) for i in feature_names_out) for name, feature_names_out in transformer_with_feature_names_out)))
            return np.asarray(names, dtype=object)
        feature_names_count = Counter(chain.from_iterable((s for _, s in transformer_with_feature_names_out)))
        top_6_overlap = [name for name, count in feature_names_count.most_common(6) if count > 1]
        top_6_overlap.sort()
        if top_6_overlap:
            if len(top_6_overlap) == 6:
                names_repr = str(top_6_overlap[:5])[:-1] + ', ...]'
            else:
                names_repr = str(top_6_overlap)
            raise ValueError(f'Output feature names: {names_repr} are not unique. Please set verbose_feature_names_out=True to add prefixes to feature names')
        return np.concatenate([name for _, name in transformer_with_feature_names_out])

    def _hstack(self, Xs, *, n_samples):
        """Stacks Xs horizontally.

        This allows subclasses to control the stacking behavior, while reusing
        everything else from ColumnTransformer.

        Parameters
        ----------
        Xs : list of {array-like, sparse matrix, dataframe}
            The container to concatenate.
        n_samples : int
            The number of samples in the input data to checking the transformation
            consistency.
        """
        if self.sparse_output_:
            try:
                converted_Xs = [check_array(X, accept_sparse=True, ensure_all_finite=False) for X in Xs]
            except ValueError as e:
                raise ValueError('For a sparse output, all columns should be a numeric or convertible to a numeric.') from e
            return sparse.hstack(converted_Xs).tocsr()
        else:
            Xs = [f.toarray() if sparse.issparse(f) else f for f in Xs]
            adapter = _get_container_adapter('transform', self)
            if adapter and all((adapter.is_supported_container(X) for X in Xs)):
                transformer_names = [t[0] for t in self._iter(fitted=True, column_as_labels=False, skip_drop=True, skip_empty_columns=True)]
                feature_names_outs = [X.columns for X in Xs if X.shape[1] != 0]
                if self.verbose_feature_names_out:
                    feature_names_outs = self._add_prefix_for_feature_names_out(list(zip(transformer_names, feature_names_outs)))
                else:
                    feature_names_outs = list(chain.from_iterable(feature_names_outs))
                    feature_names_count = Counter(feature_names_outs)
                    if any((count > 1 for count in feature_names_count.values())):
                        duplicated_feature_names = sorted((name for name, count in feature_names_count.items() if count > 1))
                        err_msg = f'Duplicated feature names found before concatenating the outputs of the transformers: {duplicated_feature_names}.\n'
                        for transformer_name, X in zip(transformer_names, Xs):
                            if X.shape[1] == 0:
                                continue
                            dup_cols_in_transformer = sorted(set(X.columns).intersection(duplicated_feature_names))
                            if len(dup_cols_in_transformer):
                                err_msg += f'Transformer {transformer_name} has conflicting columns names: {dup_cols_in_transformer}.\n'
                        raise ValueError(err_msg + 'Either make sure that the transformers named above do not generate columns with conflicting names or set verbose_feature_names_out=True to automatically prefix to the output feature names with the name of the transformer to prevent any conflicting names.')
                names_idx = 0
                for X in Xs:
                    if X.shape[1] == 0:
                        continue
                    names_out = feature_names_outs[names_idx:names_idx + X.shape[1]]
                    adapter.rename_columns(X, names_out)
                    names_idx += X.shape[1]
                output = adapter.hstack(Xs)
                output_samples = output.shape[0]
                if output_samples != n_samples:
                    raise ValueError("Concatenating DataFrames from the transformer's output lead to an inconsistent number of samples. The output may have Pandas Indexes that do not match, or that transformers are returning number of samples which are not the same as the number input samples.")
                return output
            return np.hstack(Xs)
