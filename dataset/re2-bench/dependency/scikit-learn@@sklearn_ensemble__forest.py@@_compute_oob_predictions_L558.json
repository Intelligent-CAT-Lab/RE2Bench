{
    "scikit-learn.sklearn.base.is_classifier": "def is_classifier(estimator):\n    \"\"\"Return True if the given estimator is (probably) a classifier.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator object to test.\n\n    Returns\n    -------\n    out : bool\n        True if estimator is a classifier and False otherwise.\n\n    Examples\n    --------\n    >>> from sklearn.base import is_classifier\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_classifier(classifier)\n    True\n    >>> is_classifier(regressor)\n    False\n    >>> is_classifier(kmeans)\n    False\n    \"\"\"\n    return get_tags(estimator).estimator_type == \"classifier\"",
    "scikit-learn.sklearn.ensemble._forest._get_oob_predictions": "@staticmethod\ndef _get_oob_predictions(tree, X):\n    \"\"\"Compute the OOB predictions for an individual tree.\n\n    Parameters\n    ----------\n    tree : DecisionTreeClassifier object\n        A single decision tree classifier.\n    X : ndarray of shape (n_samples, n_features)\n        The OOB samples.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples, n_classes, n_outputs)\n        The OOB associated predictions.\n    \"\"\"\n    y_pred = tree.predict_proba(X, check_input=False)\n    y_pred = np.asarray(y_pred)\n    if y_pred.ndim == 2:\n        # binary and multiclass\n        y_pred = y_pred[..., np.newaxis]\n    else:\n        # Roll the first `n_outputs` axis to the last axis. We will reshape\n        # from a shape of (n_outputs, n_samples, n_classes) to a shape of\n        # (n_samples, n_classes, n_outputs).\n        y_pred = np.rollaxis(y_pred, axis=0, start=3)\n    return y_pred",
    "scikit-learn.sklearn.ensemble._forest._generate_unsampled_indices": "def _generate_unsampled_indices(random_state, n_samples, n_samples_bootstrap):\n    \"\"\"\n    Private function used to forest._set_oob_score function.\"\"\"\n    sample_indices = _generate_sample_indices(\n        random_state, n_samples, n_samples_bootstrap\n    )\n    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n    unsampled_mask = sample_counts == 0\n    indices_range = np.arange(n_samples)\n    unsampled_indices = indices_range[unsampled_mask]\n\n    return unsampled_indices",
    "scikit-learn.sklearn.ensemble._forest._get_n_samples_bootstrap": "def _get_n_samples_bootstrap(n_samples, max_samples):\n    \"\"\"\n    Get the number of samples in a bootstrap sample.\n\n    Parameters\n    ----------\n    n_samples : int\n        Number of samples in the dataset.\n    max_samples : int or float\n        The maximum number of samples to draw from the total available:\n            - if float, this indicates a fraction of the total and should be\n              the interval `(0.0, 1.0]`;\n            - if int, this indicates the exact number of samples;\n            - if None, this indicates the total number of samples.\n\n    Returns\n    -------\n    n_samples_bootstrap : int\n        The total number of samples to draw for the bootstrap sample.\n    \"\"\"\n    if max_samples is None:\n        return n_samples\n\n    if isinstance(max_samples, Integral):\n        if max_samples > n_samples:\n            msg = \"`max_samples` must be <= n_samples={} but got value {}\"\n            raise ValueError(msg.format(n_samples, max_samples))\n        return max_samples\n\n    if isinstance(max_samples, Real):\n        return max(round(n_samples * max_samples), 1)"
}