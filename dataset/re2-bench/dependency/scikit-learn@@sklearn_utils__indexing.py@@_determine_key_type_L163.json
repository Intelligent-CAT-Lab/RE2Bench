{
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant",
    "scikit-learn.sklearn.utils._indexing._determine_key_type": "def _determine_key_type(key, accept_slice=True):\n    \"\"\"Determine the data type of key.\n\n    Parameters\n    ----------\n    key : scalar, slice or array-like\n        The key from which we want to infer the data type.\n\n    accept_slice : bool, default=True\n        Whether or not to raise an error if the key is a slice.\n\n    Returns\n    -------\n    dtype : {'int', 'str', 'bool', None}\n        Returns the data type of key.\n    \"\"\"\n    err_msg = (\n        \"No valid specification of the columns. Only a scalar, list or \"\n        \"slice of all integers or all strings, or boolean mask is \"\n        \"allowed\"\n    )\n\n    dtype_to_str = {int: \"int\", str: \"str\", bool: \"bool\", np.bool_: \"bool\"}\n    array_dtype_to_str = {\n        \"i\": \"int\",\n        \"u\": \"int\",\n        \"b\": \"bool\",\n        \"O\": \"str\",\n        \"U\": \"str\",\n        \"S\": \"str\",\n    }\n\n    if key is None:\n        return None\n    if isinstance(key, tuple(dtype_to_str.keys())):\n        try:\n            return dtype_to_str[type(key)]\n        except KeyError:\n            raise ValueError(err_msg)\n    if isinstance(key, slice):\n        if not accept_slice:\n            raise TypeError(\n                \"Only array-like or scalar are supported. A Python slice was given.\"\n            )\n        if key.start is None and key.stop is None:\n            return None\n        key_start_type = _determine_key_type(key.start)\n        key_stop_type = _determine_key_type(key.stop)\n        if key_start_type is not None and key_stop_type is not None:\n            if key_start_type != key_stop_type:\n                raise ValueError(err_msg)\n        if key_start_type is not None:\n            return key_start_type\n        return key_stop_type\n    # TODO(1.9) remove UserList when the force_int_remainder_cols param\n    # of ColumnTransformer is removed\n    if isinstance(key, (list, tuple, UserList)):\n        unique_key = set(key)\n        key_type = {_determine_key_type(elt) for elt in unique_key}\n        if not key_type:\n            return None\n        if len(key_type) != 1:\n            raise ValueError(err_msg)\n        return key_type.pop()\n    if hasattr(key, \"dtype\"):\n        xp, is_array_api = get_namespace(key)\n        # NumPy arrays are special-cased in their own branch because the Array API\n        # cannot handle object/string-based dtypes that are often used to index\n        # columns of dataframes by names.\n        if is_array_api and not _is_numpy_namespace(xp):\n            if xp.isdtype(key.dtype, \"bool\"):\n                return \"bool\"\n            elif xp.isdtype(key.dtype, \"integral\"):\n                return \"int\"\n            else:\n                raise ValueError(err_msg)\n        else:\n            try:\n                return array_dtype_to_str[key.dtype.kind]\n            except KeyError:\n                raise ValueError(err_msg)\n    raise ValueError(err_msg)",
    "scikit-learn.sklearn.utils._indexing.<setcomp>": "key_type = {_determine_key_type(elt) for elt in unique_key}\n"
}