{
    "pydantic.pydantic._internal._config.__getattr__": "def __getattr__(self, name: str) -> Any:\n    try:\n        return self.config_dict[name]\n    except KeyError:\n        try:\n            return config_defaults[name]\n        except KeyError:\n            raise AttributeError(f'Config has no attribute {name!r}') from None",
    "pydantic.pydantic._internal._config.for_model": "@classmethod\n",
    "pydantic.pydantic._internal._decorators.build": "@classmethod\n",
    "pydantic.pydantic._internal._decorators.update_from_config": "def update_from_config(self, config_wrapper: ConfigWrapper) -> None:\n    \"\"\"Update the decorator infos from the configuration of the class they are attached to.\"\"\"\n    for name, computed_field_dec in self.computed_fields.items():\n        computed_field_dec.info._update_from_config(config_wrapper, name)",
    "pydantic.pydantic._internal._mock_val_ser.set_model_mocks": "def set_model_mocks(cls: type[BaseModel], undefined_name: str = 'all referenced types') -> None:\n    \"\"\"Set `__pydantic_core_schema__`, `__pydantic_validator__` and `__pydantic_serializer__` to mock core types on a model.\n\n    Args:\n        cls: The model class to set the mocks on\n        undefined_name: Name of the undefined thing, used in error messages\n    \"\"\"\n    undefined_type_error_message = (\n        f'`{cls.__name__}` is not fully defined; you should define {undefined_name},'\n        f' then call `{cls.__name__}.model_rebuild()`.'\n    )\n\n    def attempt_rebuild_fn(attr_fn: Callable[[type[BaseModel]], T]) -> Callable[[], T | None]:\n        def handler() -> T | None:\n            if cls.model_rebuild(raise_errors=False, _parent_namespace_depth=5) is not False:\n                return attr_fn(cls)\n            return None\n\n        return handler\n\n    cls.__pydantic_core_schema__ = MockCoreSchema(  # pyright: ignore[reportAttributeAccessIssue]\n        undefined_type_error_message,\n        code='class-not-fully-defined',\n        attempt_rebuild=attempt_rebuild_fn(lambda c: c.__pydantic_core_schema__),\n    )\n    cls.__pydantic_validator__ = MockValSer(  # pyright: ignore[reportAttributeAccessIssue]\n        undefined_type_error_message,\n        code='class-not-fully-defined',\n        val_or_ser='validator',\n        attempt_rebuild=attempt_rebuild_fn(lambda c: c.__pydantic_validator__),\n    )\n    cls.__pydantic_serializer__ = MockValSer(  # pyright: ignore[reportAttributeAccessIssue]\n        undefined_type_error_message,\n        code='class-not-fully-defined',\n        val_or_ser='serializer',\n        attempt_rebuild=attempt_rebuild_fn(lambda c: c.__pydantic_serializer__),\n    )",
    "pydantic.pydantic._internal._model_construction.<genexpr>": "if parameters and parent_parameters and not all(x in parameters for x in parent_parameters):\n    from ..root_model import RootModelRootType\n\n    missing_parameters = tuple(x for x in parameters if x not in parent_parameters)\n    if RootModelRootType in parent_parameters and RootModelRootType not in parameters:\n        # This is a special case where the user has subclassed `RootModel`, but has not parametrized\n        # RootModel with the generic type identifiers being used. Ex:\n        # class MyModel(RootModel, Generic[T]):\n        #    root: T\n        # Should instead just be:\n        # class MyModel(RootModel[T]):\n        #   root: T\n        parameters_str = ', '.join([x.__name__ for x in missing_parameters])\n        error_message = (\n            f'{cls.__name__} is a subclass of `RootModel`, but does not include the generic type identifier(s) '\n            f'{parameters_str} in its parameters. '\n            f'You should parametrize RootModel directly, e.g., `class {cls.__name__}(RootModel[{parameters_str}]): ...`.'\n        )\n    else:\n        combined_parameters = parent_parameters + missing_parameters\n        parameters_str = ', '.join([str(x) for x in combined_parameters])\n        generic_type_label = f'typing.Generic[{parameters_str}]'\n        error_message = (\n            f'All parameters must be present on typing.Generic;'\n            f' you should inherit from {generic_type_label}.'\n        )\n        if Generic not in bases:  # pragma: no cover\n            # We raise an error here not because it is desirable, but because some cases are mishandled.\n            # It would be nice to remove this error and still have things behave as expected, it's just\n            # challenging because we are using a custom `__class_getitem__` to parametrize generic models,\n            # and not returning a typing._GenericAlias from it.\n            bases_str = ', '.join([x.__name__ for x in bases] + [generic_type_label])\n            error_message += (\n                f' Note: `typing.Generic` must go last: `class {cls.__name__}({bases_str}): ...`)'\n            )\n    raise TypeError(error_message)\n\n",
    "pydantic.pydantic._internal._model_construction.__getattr__": "def __getattr__(self, item: str) -> Any:\n    \"\"\"This is necessary to keep attribute access working for class attribute access.\"\"\"\n    private_attributes = self.__dict__.get('__private_attributes__')\n    if private_attributes and item in private_attributes:\n        return private_attributes[item]\n    raise AttributeError(item)",
    "pydantic.pydantic._internal._model_construction._collect_bases_data": "@staticmethod\n",
    "pydantic.pydantic._internal._model_construction.get_model_post_init": "def get_model_post_init(namespace: dict[str, Any], bases: tuple[type[Any], ...]) -> Callable[..., Any] | None:\n    \"\"\"Get the `model_post_init` method from the namespace or the class bases, or `None` if not defined.\"\"\"\n    if 'model_post_init' in namespace:\n        return namespace['model_post_init']\n\n    BaseModel = import_cached_base_model()\n\n    model_post_init = get_attribute_from_bases(bases, 'model_post_init')\n    if model_post_init is not BaseModel.model_post_init:\n        return model_post_init",
    "pydantic.pydantic._internal._model_construction.inspect_namespace": "def inspect_namespace(  # noqa C901\n    namespace: dict[str, Any],\n    raw_annotations: dict[str, Any],\n    ignored_types: tuple[type[Any], ...],\n    base_class_vars: set[str],\n    base_class_fields: set[str],\n) -> dict[str, ModelPrivateAttr]:\n    \"\"\"Iterate over the namespace and:\n    * gather private attributes\n    * check for items which look like fields but are not (e.g. have no annotation) and warn.\n\n    Args:\n        namespace: The attribute dictionary of the class to be created.\n        raw_annotations: The (non-evaluated) annotations of the model.\n        ignored_types: A tuple of ignore types.\n        base_class_vars: A set of base class class variables.\n        base_class_fields: A set of base class fields.\n\n    Returns:\n        A dict contains private attributes info.\n\n    Raises:\n        TypeError: If there is a `__root__` field in model.\n        NameError: If private attribute name is invalid.\n        PydanticUserError:\n            - If a field does not have a type annotation.\n            - If a field on base class was overridden by a non-annotated attribute.\n    \"\"\"\n    from ..fields import ModelPrivateAttr, PrivateAttr\n\n    FieldInfo = import_cached_field_info()\n\n    all_ignored_types = ignored_types + default_ignored_types()\n\n    private_attributes: dict[str, ModelPrivateAttr] = {}\n\n    if '__root__' in raw_annotations or '__root__' in namespace:\n        raise TypeError(\"To define root models, use `pydantic.RootModel` rather than a field called '__root__'\")\n\n    ignored_names: set[str] = set()\n    for var_name, value in list(namespace.items()):\n        if var_name == 'model_config' or var_name == '__pydantic_extra__':\n            continue\n        elif (\n            isinstance(value, type)\n            and value.__module__ == namespace['__module__']\n            and '__qualname__' in namespace\n            and value.__qualname__.startswith(f'{namespace[\"__qualname__\"]}.')\n        ):\n            # `value` is a nested type defined in this namespace; don't error\n            continue\n        elif isinstance(value, all_ignored_types) or value.__class__.__module__ == 'functools':\n            ignored_names.add(var_name)\n            continue\n        elif isinstance(value, ModelPrivateAttr):\n            if var_name.startswith('__'):\n                raise NameError(\n                    'Private attributes must not use dunder names;'\n                    f' use a single underscore prefix instead of {var_name!r}.'\n                )\n            elif is_valid_field_name(var_name):\n                raise NameError(\n                    'Private attributes must not use valid field names;'\n                    f' use sunder names, e.g. {\"_\" + var_name!r} instead of {var_name!r}.'\n                )\n            private_attributes[var_name] = value\n            del namespace[var_name]\n        elif isinstance(value, FieldInfo) and not is_valid_field_name(var_name):\n            suggested_name = var_name.lstrip('_') or 'my_field'  # don't suggest '' for all-underscore name\n            raise NameError(\n                f'Fields must not use names with leading underscores;'\n                f' e.g., use {suggested_name!r} instead of {var_name!r}.'\n            )\n\n        elif var_name.startswith('__'):\n            continue\n        elif is_valid_privateattr_name(var_name):\n            if var_name not in raw_annotations or not is_classvar_annotation(raw_annotations[var_name]):\n                private_attributes[var_name] = cast(ModelPrivateAttr, PrivateAttr(default=value))\n                del namespace[var_name]\n        elif var_name in base_class_vars:\n            continue\n        elif var_name not in raw_annotations:\n            if var_name in base_class_fields:\n                raise PydanticUserError(\n                    f'Field {var_name!r} defined on a base class was overridden by a non-annotated attribute. '\n                    f'All field definitions, including overrides, require a type annotation.',\n                    code='model-field-overridden',\n                )\n            elif isinstance(value, FieldInfo):\n                raise PydanticUserError(\n                    f'Field {var_name!r} requires a type annotation', code='model-field-missing-annotation'\n                )\n            else:\n                raise PydanticUserError(\n                    f'A non-annotated attribute was detected: `{var_name} = {value!r}`. All model fields require a '\n                    f'type annotation; if `{var_name}` is not meant to be a field, you may be able to resolve this '\n                    f\"error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.\",\n                    code='model-field-missing-annotation',\n                )\n\n    for ann_name, ann_type in raw_annotations.items():\n        if (\n            is_valid_privateattr_name(ann_name)\n            and ann_name not in private_attributes\n            and ann_name not in ignored_names\n            # This condition can be a false negative when `ann_type` is stringified,\n            # but it is handled in most cases in `set_model_fields`:\n            and not is_classvar_annotation(ann_type)\n            and ann_type not in all_ignored_types\n            and getattr(ann_type, '__module__', None) != 'functools'\n        ):\n            if isinstance(ann_type, str):\n                # Walking up the frames to get the module namespace where the model is defined\n                # (as the model class wasn't created yet, we unfortunately can't use `cls.__module__`):\n                frame = sys._getframe(2)\n                if frame is not None:\n                    try:\n                        ann_type = eval_type_backport(\n                            _make_forward_ref(ann_type, is_argument=False, is_class=True),\n                            globalns=frame.f_globals,\n                            localns=frame.f_locals,\n                        )\n                    except (NameError, TypeError):\n                        pass\n\n            if typing_objects.is_annotated(get_origin(ann_type)):\n                _, *metadata = get_args(ann_type)\n                private_attr = next((v for v in metadata if isinstance(v, ModelPrivateAttr)), None)\n                if private_attr is not None:\n                    private_attributes[ann_name] = private_attr\n                    continue\n            private_attributes[ann_name] = PrivateAttr()\n\n    return private_attributes",
    "pydantic.pydantic._internal._model_construction.set_model_fields": "def set_model_fields(\n    cls: type[BaseModel],\n    config_wrapper: ConfigWrapper,\n    ns_resolver: NsResolver,\n) -> None:\n    \"\"\"Collect and set `cls.__pydantic_fields__` and `cls.__class_vars__`.\n\n    Args:\n        cls: BaseModel or dataclass.\n        config_wrapper: The config wrapper instance.\n        ns_resolver: Namespace resolver to use when getting model annotations.\n    \"\"\"\n    typevars_map = get_model_typevars_map(cls)\n    fields, class_vars = collect_model_fields(cls, config_wrapper, ns_resolver, typevars_map=typevars_map)\n\n    cls.__pydantic_fields__ = fields\n    cls.__class_vars__.update(class_vars)\n\n    for k in class_vars:\n        # Class vars should not be private attributes\n        #     We remove them _here_ and not earlier because we rely on inspecting the class to determine its classvars,\n        #     but private attributes are determined by inspecting the namespace _prior_ to class creation.\n        #     In the case that a classvar with a leading-'_' is defined via a ForwardRef (e.g., when using\n        #     `__future__.annotations`), we want to remove the private attribute which was detected _before_ we knew it\n        #     evaluated to a classvar\n\n        value = cls.__private_attributes__.pop(k, None)\n        if value is not None and value.default is not PydanticUndefined:\n            setattr(cls, k, value.default)",
    "pydantic.pydantic._internal._model_construction.__setitem__": "def __setitem__(self, k: str, v: object) -> None:\n    existing: Any = self.get(k, None)\n    if existing and v is not existing and isinstance(existing, PydanticDescriptorProxy):\n        warnings.warn(\n            f'`{k}` overrides an existing Pydantic `{existing.decorator_info.decorator_repr}` decorator',\n            stacklevel=2,\n        )\n\n    return super().__setitem__(k, v)",
    "pydantic.pydantic._internal._model_construction.complete_model_class": "def complete_model_class(\n    cls: type[BaseModel],\n    config_wrapper: ConfigWrapper,\n    ns_resolver: NsResolver,\n    *,\n    raise_errors: bool = True,\n    call_on_complete_hook: bool = True,\n    create_model_module: str | None = None,\n) -> bool:\n    \"\"\"Finish building a model class.\n\n    This logic must be called after class has been created since validation functions must be bound\n    and `get_type_hints` requires a class object.\n\n    Args:\n        cls: BaseModel or dataclass.\n        config_wrapper: The config wrapper instance.\n        ns_resolver: The namespace resolver instance to use during schema building.\n        raise_errors: Whether to raise errors.\n        call_on_complete_hook: Whether to call the `__pydantic_on_complete__` hook.\n        create_model_module: The module of the class to be created, if created by `create_model`.\n\n    Returns:\n        `True` if the model is successfully completed, else `False`.\n\n    Raises:\n        PydanticUndefinedAnnotation: If `PydanticUndefinedAnnotation` occurs in`__get_pydantic_core_schema__`\n            and `raise_errors=True`.\n    \"\"\"\n    typevars_map = get_model_typevars_map(cls)\n\n    if not cls.__pydantic_fields_complete__:\n        # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.\n        # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.\n        # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete\n        # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the\n        # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`\n        # when `__pydantic_complete__` is `True`, we rebuild here:\n        try:\n            cls.__pydantic_fields__ = rebuild_model_fields(\n                cls,\n                config_wrapper=config_wrapper,\n                ns_resolver=ns_resolver,\n                typevars_map=typevars_map,\n            )\n        except NameError as e:\n            exc = PydanticUndefinedAnnotation.from_name_error(e)\n            set_model_mocks(cls, f'`{exc.name}`')\n            if raise_errors:\n                raise exc from e\n\n        if not raise_errors and not cls.__pydantic_fields_complete__:\n            # No need to continue with schema gen, it is guaranteed to fail\n            return False\n\n        assert cls.__pydantic_fields_complete__\n\n    gen_schema = GenerateSchema(\n        config_wrapper,\n        ns_resolver,\n        typevars_map,\n    )\n\n    try:\n        schema = gen_schema.generate_schema(cls)\n    except PydanticUndefinedAnnotation as e:\n        if raise_errors:\n            raise\n        set_model_mocks(cls, f'`{e.name}`')\n        return False\n\n    core_config = config_wrapper.core_config(title=cls.__name__)\n\n    try:\n        schema = gen_schema.clean_schema(schema)\n    except InvalidSchemaError:\n        set_model_mocks(cls)\n        return False\n\n    # This needs to happen *after* model schema generation, as the return type\n    # of the properties are evaluated and the `ComputedFieldInfo` are recreated:\n    cls.__pydantic_computed_fields__ = {k: v.info for k, v in cls.__pydantic_decorators__.computed_fields.items()}\n\n    set_deprecated_descriptors(cls)\n\n    cls.__pydantic_core_schema__ = schema\n\n    cls.__pydantic_validator__ = create_schema_validator(\n        schema,\n        cls,\n        create_model_module or cls.__module__,\n        cls.__qualname__,\n        'create_model' if create_model_module else 'BaseModel',\n        core_config,\n        config_wrapper.plugin_settings,\n    )\n    cls.__pydantic_serializer__ = SchemaSerializer(schema, core_config)\n\n    # set __signature__ attr only for model class, but not for its instances\n    # (because instances can define `__call__`, and `inspect.signature` shouldn't\n    # use the `__signature__` attribute and instead generate from `__call__`).\n    cls.__signature__ = LazyClassAttribute(\n        '__signature__',\n        partial(\n            generate_pydantic_signature,\n            init=cls.__init__,\n            fields=cls.__pydantic_fields__,\n            validate_by_name=config_wrapper.validate_by_name,\n            extra=config_wrapper.extra,\n        ),\n    )\n\n    cls.__pydantic_complete__ = True\n\n    if call_on_complete_hook:\n        cls.__pydantic_on_complete__()\n\n    return True",
    "pydantic.pydantic._internal._model_construction.build_lenient_weakvaluedict": "def build_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:\n    \"\"\"Takes an input dictionary, and produces a new value that (invertibly) replaces the values with weakrefs.\n\n    We can't just use a WeakValueDictionary because many types (including int, str, etc.) can't be stored as values\n    in a WeakValueDictionary.\n\n    The `unpack_lenient_weakvaluedict` function can be used to reverse this operation.\n    \"\"\"\n    if d is None:\n        return None\n    result = {}\n    for k, v in d.items():\n        try:\n            proxy = _PydanticWeakRef(v)\n        except TypeError:\n            proxy = v\n        result[k] = proxy\n    return result",
    "pydantic.pydantic._internal._model_construction.unpack_lenient_weakvaluedict": "def unpack_lenient_weakvaluedict(d: dict[str, Any] | None) -> dict[str, Any] | None:\n    \"\"\"Inverts the transform performed by `build_lenient_weakvaluedict`.\"\"\"\n    if d is None:\n        return None\n\n    result = {}\n    for k, v in d.items():\n        if isinstance(v, _PydanticWeakRef):\n            v = v()\n            if v is not None:\n                result[k] = v\n        else:\n            result[k] = v\n    return result",
    "pydantic.pydantic._internal._namespace_utils.__init__": "def __init__(\n    self,\n    namespaces_tuple: NamespacesTuple | None = None,\n    parent_namespace: MappingNamespace | None = None,\n) -> None:\n    self._base_ns_tuple = namespaces_tuple or NamespacesTuple({}, {})\n    self._parent_ns = parent_namespace\n    self._types_stack: list[type[Any] | TypeAliasType] = []",
    "pydantic.pydantic._internal._typing_extra.parent_frame_namespace": "def parent_frame_namespace(*, parent_depth: int = 2, force: bool = False) -> dict[str, Any] | None:\n    \"\"\"Fetch the local namespace of the parent frame where this function is called.\n\n    Using this function is mostly useful to resolve forward annotations pointing to members defined in a local namespace,\n    such as assignments inside a function. Using the standard library tools, it is currently not possible to resolve\n    such annotations:\n\n    ```python {lint=\"skip\" test=\"skip\"}\n    from typing import get_type_hints\n\n    def func() -> None:\n        Alias = int\n\n        class C:\n            a: 'Alias'\n\n        # Raises a `NameError: 'Alias' is not defined`\n        get_type_hints(C)\n    ```\n\n    Pydantic uses this function when a Pydantic model is being defined to fetch the parent frame locals. However,\n    this only allows us to fetch the parent frame namespace and not other parents (e.g. a model defined in a function,\n    itself defined in another function). Inspecting the next outer frames (using `f_back`) is not reliable enough\n    (see https://discuss.python.org/t/20659).\n\n    Because this function is mostly used to better resolve forward annotations, nothing is returned if the parent frame's\n    code object is defined at the module level. In this case, the locals of the frame will be the same as the module\n    globals where the class is defined (see `_namespace_utils.get_module_ns_of`). However, if you still want to fetch\n    the module globals (e.g. when rebuilding a model, where the frame where the rebuild call is performed might contain\n    members that you want to use for forward annotations evaluation), you can use the `force` parameter.\n\n    Args:\n        parent_depth: The depth at which to get the frame. Defaults to 2, meaning the parent frame where this function\n            is called will be used.\n        force: Whether to always return the frame locals, even if the frame's code object is defined at the module level.\n\n    Returns:\n        The locals of the namespace, or `None` if it was skipped as per the described logic.\n    \"\"\"\n    frame = sys._getframe(parent_depth)\n\n    if frame.f_code.co_name.startswith('<generic parameters of'):\n        # As `parent_frame_namespace` is mostly called in `ModelMetaclass.__new__`,\n        # the parent frame can be the annotation scope if the PEP 695 generic syntax is used.\n        # (see https://docs.python.org/3/reference/executionmodel.html#annotation-scopes,\n        # https://docs.python.org/3/reference/compound_stmts.html#generic-classes).\n        # In this case, the code name is set to `<generic parameters of MyClass>`,\n        # and we need to skip this frame as it is irrelevant.\n        frame = cast(types.FrameType, frame.f_back)  # guaranteed to not be `None`\n\n    # note, we don't copy frame.f_locals here (or during the last return call), because we don't expect the namespace to be\n    # modified down the line if this becomes a problem, we could implement some sort of frozen mapping structure to enforce this.\n    if force:\n        return frame.f_locals\n\n    # If either of the following conditions are true, the class is defined at the top module level.\n    # To better understand why we need both of these checks, see\n    # https://github.com/pydantic/pydantic/pull/10113#discussion_r1714981531.\n    if frame.f_back is None or frame.f_code.co_name == '<module>':\n        return None\n\n    return frame.f_locals",
    "pydantic.pydantic.fields.__set_name__": "def __set_name__(self, cls: type[Any], name: str) -> None:\n    \"\"\"Preserve `__set_name__` protocol defined in https://peps.python.org/pep-0487.\"\"\"\n    default = self.default\n    if default is PydanticUndefined:\n        return\n    set_name = getattr(default, '__set_name__', None)\n    if callable(set_name):\n        set_name(cls, name)",
    "pydantic.pydantic.main.__pydantic_init_subclass__": "@classmethod\n"
}