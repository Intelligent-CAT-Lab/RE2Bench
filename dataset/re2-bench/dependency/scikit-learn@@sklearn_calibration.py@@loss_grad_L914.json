{
    "scikit-learn.sklearn._loss.loss.loss_gradient": "def loss_gradient(\n    self,\n    y_true,\n    raw_prediction,\n    sample_weight=None,\n    loss_out=None,\n    gradient_out=None,\n    n_threads=1,\n):\n    \"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\n\n    Parameters\n    ----------\n    y_true : C-contiguous array of shape (n_samples,)\n        Observed, true target values.\n    raw_prediction : C-contiguous array of shape (n_samples,) or array of \\\n        shape (n_samples, n_classes)\n        Raw prediction values (in link space).\n    sample_weight : None or C-contiguous array of shape (n_samples,)\n        Sample weights.\n    loss_out : None or C-contiguous array of shape (n_samples,)\n        A location into which the loss is stored. If None, a new array\n        might be created.\n    gradient_out : None or C-contiguous array of shape (n_samples,) or array \\\n        of shape (n_samples, n_classes)\n        A location into which the gradient is stored. If None, a new array\n        might be created.\n    n_threads : int, default=1\n        Might use openmp thread parallelism.\n\n    Returns\n    -------\n    loss : array of shape (n_samples,)\n        Element-wise loss function.\n\n    gradient : array of shape (n_samples,) or (n_samples, n_classes)\n        Element-wise gradients.\n    \"\"\"\n    if loss_out is None:\n        if gradient_out is None:\n            loss_out = np.empty_like(y_true)\n            gradient_out = np.empty_like(raw_prediction)\n        else:\n            loss_out = np.empty_like(y_true, dtype=gradient_out.dtype)\n    elif gradient_out is None:\n        gradient_out = np.empty_like(raw_prediction, dtype=loss_out.dtype)\n\n    # Be graceful to shape (n_samples, 1) -> (n_samples,)\n    if raw_prediction.ndim == 2 and raw_prediction.shape[1] == 1:\n        raw_prediction = raw_prediction.squeeze(1)\n    if gradient_out.ndim == 2 and gradient_out.shape[1] == 1:\n        gradient_out = gradient_out.squeeze(1)\n\n    self.closs.loss_gradient(\n        y_true=y_true,\n        raw_prediction=raw_prediction,\n        sample_weight=sample_weight,\n        loss_out=loss_out,\n        gradient_out=gradient_out,\n        n_threads=n_threads,\n    )\n    return loss_out, gradient_out"
}