{
    "scikit-learn.sklearn.pipeline._validate_transformers": "def _validate_transformers(self):\n    names, transformers = zip(*self.transformer_list)\n\n    # validate names\n    self._validate_names(names)\n\n    # validate estimators\n    for t in transformers:\n        if t in (\"drop\", \"passthrough\"):\n            continue\n        if not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not hasattr(\n            t, \"transform\"\n        ):\n            raise TypeError(\n                \"All estimators should implement fit and \"\n                \"transform. '%s' (type %s) doesn't\" % (t, type(t))\n            )",
    "scikit-learn.sklearn.pipeline._validate_transformer_weights": "def _validate_transformer_weights(self):\n    if not self.transformer_weights:\n        return\n\n    transformer_names = set(name for name, _ in self.transformer_list)\n    for name in self.transformer_weights:\n        if name not in transformer_names:\n            raise ValueError(\n                f'Attempting to weight transformer \"{name}\", '\n                \"but it is not present in transformer_list.\"\n            )",
    "scikit-learn.sklearn.pipeline._iter": "def _iter(self):\n    \"\"\"\n    Generate (name, trans, weight) tuples excluding None and\n    'drop' transformers.\n    \"\"\"\n\n    get_weight = (self.transformer_weights or {}).get\n\n    for name, trans in self.transformer_list:\n        if trans == \"drop\":\n            continue\n        if trans == \"passthrough\":\n            trans = FunctionTransformer(feature_names_out=\"one-to-one\")\n        yield (name, trans, get_weight(name))",
    "scikit-learn.sklearn.utils.parallel.__call__": "def __call__(self, iterable):\n    \"\"\"Dispatch the tasks and return the results.\n\n    Parameters\n    ----------\n    iterable : iterable\n        Iterable containing tuples of (delayed_function, args, kwargs) that should\n        be consumed.\n\n    Returns\n    -------\n    results : list\n        List of results of the tasks.\n    \"\"\"\n    # Capture the thread-local scikit-learn configuration at the time\n    # Parallel.__call__ is issued since the tasks can be dispatched\n    # in a different thread depending on the backend and on the value of\n    # pre_dispatch and n_jobs.\n    config = get_config()\n    # In free-threading Python >= 3.14, warnings filters are managed through a\n    # ContextVar and warnings.filters is not modified inside a\n    # warnings.catch_warnings context. You need to use warnings._get_filters().\n    # For more details, see\n    # https://docs.python.org/3.14/whatsnew/3.14.html#concurrent-safe-warnings-control\n    filters_func = getattr(warnings, \"_get_filters\", None)\n    warning_filters = (\n        filters_func() if filters_func is not None else warnings.filters\n    )\n\n    iterable_with_config_and_warning_filters = (\n        (\n            _with_config_and_warning_filters(delayed_func, config, warning_filters),\n            args,\n            kwargs,\n        )\n        for delayed_func, args, kwargs in iterable\n    )\n    return super().__call__(iterable_with_config_and_warning_filters)"
}