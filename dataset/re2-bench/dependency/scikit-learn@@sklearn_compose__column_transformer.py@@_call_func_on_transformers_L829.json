{
    "scikit-learn.sklearn.base.clone": "def clone(estimator, *, safe=True):\n    \"\"\"Construct a new unfitted estimator with the same parameters.\n\n    Clone does a deep copy of the model in an estimator\n    without actually copying attached data. It returns a new estimator\n    with the same parameters that has not been fitted on any data.\n\n    .. versionchanged:: 1.3\n        Delegates to `estimator.__sklearn_clone__` if the method exists.\n\n    Parameters\n    ----------\n    estimator : {list, tuple, set} of estimator instance or a single \\\n            estimator instance\n        The estimator or group of estimators to be cloned.\n    safe : bool, default=True\n        If safe is False, clone will fall back to a deep copy on objects\n        that are not estimators. Ignored if `estimator.__sklearn_clone__`\n        exists.\n\n    Returns\n    -------\n    estimator : object\n        The deep copy of the input, an estimator if input is an estimator.\n\n    Notes\n    -----\n    If the estimator's `random_state` parameter is an integer (or if the\n    estimator doesn't have a `random_state` parameter), an *exact clone* is\n    returned: the clone and the original estimator will give the exact same\n    results. Otherwise, *statistical clone* is returned: the clone might\n    return different results from the original estimator. More details can be\n    found in :ref:`randomness`.\n\n    Examples\n    --------\n    >>> from sklearn.base import clone\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n    >>> y = [0, 0, 1, 1]\n    >>> classifier = LogisticRegression().fit(X, y)\n    >>> cloned_classifier = clone(classifier)\n    >>> hasattr(classifier, \"classes_\")\n    True\n    >>> hasattr(cloned_classifier, \"classes_\")\n    False\n    >>> classifier is cloned_classifier\n    False\n    \"\"\"\n    if hasattr(estimator, \"__sklearn_clone__\") and not inspect.isclass(estimator):\n        return estimator.__sklearn_clone__()\n    return _clone_parametrized(estimator, safe=safe)",
    "scikit-learn.sklearn.compose._column_transformer._iter": "def _iter(self, fitted, column_as_labels, skip_drop, skip_empty_columns):\n    \"\"\"\n    Generate (name, trans, columns, weight) tuples.\n\n\n    Parameters\n    ----------\n    fitted : bool\n        If True, use the fitted transformers (``self.transformers_``) to\n        iterate through transformers, else use the transformers passed by\n        the user (``self.transformers``).\n\n    column_as_labels : bool\n        If True, columns are returned as string labels. If False, columns\n        are returned as they were given by the user. This can only be True\n        if the ``ColumnTransformer`` is already fitted.\n\n    skip_drop : bool\n        If True, 'drop' transformers are filtered out.\n\n    skip_empty_columns : bool\n        If True, transformers with empty selected columns are filtered out.\n\n    Yields\n    ------\n    A generator of tuples containing:\n        - name : the name of the transformer\n        - transformer : the transformer object\n        - columns : the columns for that transformer\n        - weight : the weight of the transformer\n    \"\"\"\n    if fitted:\n        transformers = self.transformers_\n    else:\n        # interleave the validated column specifiers\n        transformers = [\n            (name, trans, column)\n            for (name, trans, _), column in zip(self.transformers, self._columns)\n        ]\n        # add transformer tuple for remainder\n        if self._remainder[2]:\n            transformers = chain(transformers, [self._remainder])\n\n    get_weight = (self.transformer_weights or {}).get\n\n    for name, trans, columns in transformers:\n        if skip_drop and trans == \"drop\":\n            continue\n        if skip_empty_columns and _is_empty_column_selection(columns):\n            continue\n\n        if column_as_labels:\n            # Convert all columns to using their string labels\n            columns_is_scalar = np.isscalar(columns)\n\n            indices = self._transformer_to_input_indices[name]\n            columns = self.feature_names_in_[indices]\n\n            if columns_is_scalar:\n                # selection is done with one dimension\n                columns = columns[0]\n\n        yield (name, trans, columns, get_weight(name))",
    "scikit-learn.sklearn.compose._column_transformer._log_message": "def _log_message(self, name, idx, total):\n    if not self.verbose:\n        return None\n    return \"(%d of %d) Processing %s\" % (idx, total, name)",
    "scikit-learn.sklearn.preprocessing._function_transformer.__init__": "def __init__(\n    self,\n    func=None,\n    inverse_func=None,\n    *,\n    validate=False,\n    accept_sparse=False,\n    check_inverse=True,\n    feature_names_out=None,\n    kw_args=None,\n    inv_kw_args=None,\n):\n    self.func = func\n    self.inverse_func = inverse_func\n    self.validate = validate\n    self.accept_sparse = accept_sparse\n    self.check_inverse = check_inverse\n    self.feature_names_out = feature_names_out\n    self.kw_args = kw_args\n    self.inv_kw_args = inv_kw_args",
    "scikit-learn.sklearn.preprocessing._function_transformer.set_output": "def set_output(self, *, transform=None):\n    \"\"\"Set output container.\n\n    See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n    for an example on how to use the API.\n\n    Parameters\n    ----------\n    transform : {\"default\", \"pandas\", \"polars\"}, default=None\n        Configure output of `transform` and `fit_transform`.\n\n        - `\"default\"`: Default output format of a transformer\n        - `\"pandas\"`: DataFrame output\n        - `\"polars\"`: Polars output\n        - `None`: Transform configuration is unchanged\n\n        .. versionadded:: 1.4\n            `\"polars\"` option was added.\n\n    Returns\n    -------\n    self : estimator instance\n        Estimator instance.\n    \"\"\"\n    if not hasattr(self, \"_sklearn_output_config\"):\n        self._sklearn_output_config = {}\n\n    self._sklearn_output_config[\"transform\"] = transform\n    return self",
    "scikit-learn.sklearn.utils._bunch.__getitem__": "def __getitem__(self, key):\n    if key in self.__dict__.get(\"_deprecated_key_to_warnings\", {}):\n        warnings.warn(\n            self._deprecated_key_to_warnings[key],\n            FutureWarning,\n        )\n    return super().__getitem__(key)",
    "scikit-learn.sklearn.utils._indexing._safe_indexing": "def _safe_indexing(X, indices, *, axis=0):\n    \"\"\"Return rows, items or columns of X using indices.\n\n    .. warning::\n\n        This utility is documented, but **private**. This means that\n        backward compatibility might be broken without any deprecation\n        cycle.\n\n    Parameters\n    ----------\n    X : array-like, sparse-matrix, list, pandas.DataFrame, pandas.Series\n        Data from which to sample rows, items or columns. `list` are only\n        supported when `axis=0`.\n    indices : bool, int, str, slice, array-like\n        - If `axis=0`, boolean and integer array-like, integer slice,\n          and scalar integer are supported.\n        - If `axis=1`:\n            - to select a single column, `indices` can be of `int` type for\n              all `X` types and `str` only for dataframe. The selected subset\n              will be 1D, unless `X` is a sparse matrix in which case it will\n              be 2D.\n            - to select multiples columns, `indices` can be one of the\n              following: `list`, `array`, `slice`. The type used in\n              these containers can be one of the following: `int`, 'bool' and\n              `str`. However, `str` is only supported when `X` is a dataframe.\n              The selected subset will be 2D.\n    axis : int, default=0\n        The axis along which `X` will be subsampled. `axis=0` will select\n        rows while `axis=1` will select columns.\n\n    Returns\n    -------\n    subset\n        Subset of X on axis 0 or 1.\n\n    Notes\n    -----\n    CSR, CSC, and LIL sparse matrices are supported. COO sparse matrices are\n    not supported.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.utils import _safe_indexing\n    >>> data = np.array([[1, 2], [3, 4], [5, 6]])\n    >>> _safe_indexing(data, 0, axis=0)  # select the first row\n    array([1, 2])\n    >>> _safe_indexing(data, 0, axis=1)  # select the first column\n    array([1, 3, 5])\n    \"\"\"\n    if indices is None:\n        return X\n\n    if axis not in (0, 1):\n        raise ValueError(\n            \"'axis' should be either 0 (to index rows) or 1 (to index \"\n            \" column). Got {} instead.\".format(axis)\n        )\n\n    indices_dtype = _determine_key_type(indices)\n\n    if axis == 0 and indices_dtype == \"str\":\n        raise ValueError(\n            f\"String indexing (indices={indices}) is not supported with 'axis=0'. \"\n            \"Did you mean to use axis=1 for column selection?\"\n        )\n\n    if axis == 1 and isinstance(X, list):\n        raise ValueError(\"axis=1 is not supported for lists\")\n\n    if axis == 1 and (ndim := len(getattr(X, \"shape\", [0]))) != 2:\n        raise ValueError(\n            \"'X' should be a 2D NumPy array, 2D sparse matrix or \"\n            \"dataframe when indexing the columns (i.e. 'axis=1'). \"\n            f\"Got {type(X)} instead with {ndim} dimension(s).\"\n        )\n\n    if (\n        axis == 1\n        and indices_dtype == \"str\"\n        and not (_is_pandas_df(X) or _use_interchange_protocol(X))\n    ):\n        raise ValueError(\n            \"Specifying the columns using strings is only supported for dataframes.\"\n        )\n\n    if hasattr(X, \"iloc\"):\n        # TODO: we should probably use _is_pandas_df_or_series(X) instead but:\n        # 1) Currently, it (probably) works for dataframes compliant to pandas' API.\n        # 2) Updating would require updating some tests such as\n        #    test_train_test_split_mock_pandas.\n        return _pandas_indexing(X, indices, indices_dtype, axis=axis)\n    elif _is_polars_df_or_series(X):\n        return _polars_indexing(X, indices, indices_dtype, axis=axis)\n    elif _is_pyarrow_data(X):\n        return _pyarrow_indexing(X, indices, indices_dtype, axis=axis)\n    elif _use_interchange_protocol(X):  # pragma: no cover\n        # Once the dataframe X is converted into its dataframe interchange protocol\n        # version by calling X.__dataframe__(), it becomes very hard to turn it back\n        # into its original type, e.g., a pyarrow.Table, see\n        # https://github.com/data-apis/dataframe-api/issues/85.\n        raise warnings.warn(\n            message=\"A data object with support for the dataframe interchange protocol\"\n            \"was passed, but scikit-learn does currently not know how to handle this \"\n            \"kind of data. Some array/list indexing will be tried.\",\n            category=UserWarning,\n        )\n\n    if hasattr(X, \"shape\"):\n        return _array_indexing(X, indices, indices_dtype, axis=axis)\n    else:\n        return _list_indexing(X, indices, indices_dtype)",
    "scikit-learn.sklearn.utils._metadata_requests.__getitem__": "def __getitem__(self, name):\n    return Bunch(**{method: dict() for method in METHODS})",
    "scikit-learn.sklearn.utils._set_output._get_output_config": "def _get_output_config(method, estimator=None):\n    \"\"\"Get output config based on estimator and global configuration.\n\n    Parameters\n    ----------\n    method : {\"transform\"}\n        Estimator's method for which the output container is looked up.\n\n    estimator : estimator instance or None\n        Estimator to get the output configuration from. If `None`, check global\n        configuration is used.\n\n    Returns\n    -------\n    config : dict\n        Dictionary with keys:\n\n        - \"dense\": specifies the dense container for `method`. This can be\n          `\"default\"` or `\"pandas\"`.\n    \"\"\"\n    est_sklearn_output_config = getattr(estimator, \"_sklearn_output_config\", {})\n    if method in est_sklearn_output_config:\n        dense_config = est_sklearn_output_config[method]\n    else:\n        dense_config = get_config()[f\"{method}_output\"]\n\n    supported_outputs = ADAPTERS_MANAGER.supported_outputs\n    if dense_config not in supported_outputs:\n        raise ValueError(\n            f\"output config must be in {sorted(supported_outputs)}, got {dense_config}\"\n        )\n\n    return {\"dense\": dense_config}",
    "scikit-learn.sklearn.utils.parallel.delayed_function": "@functools.wraps(function)\ndef delayed_function(*args, **kwargs):\n    return _FuncWrapper(function), args, kwargs",
    "scikit-learn.sklearn.utils.parallel.__call__": "def __call__(self, iterable):\n    \"\"\"Dispatch the tasks and return the results.\n\n    Parameters\n    ----------\n    iterable : iterable\n        Iterable containing tuples of (delayed_function, args, kwargs) that should\n        be consumed.\n\n    Returns\n    -------\n    results : list\n        List of results of the tasks.\n    \"\"\"\n    # Capture the thread-local scikit-learn configuration at the time\n    # Parallel.__call__ is issued since the tasks can be dispatched\n    # in a different thread depending on the backend and on the value of\n    # pre_dispatch and n_jobs.\n    config = get_config()\n    # In free-threading Python >= 3.14, warnings filters are managed through a\n    # ContextVar and warnings.filters is not modified inside a\n    # warnings.catch_warnings context. You need to use warnings._get_filters().\n    # For more details, see\n    # https://docs.python.org/3.14/whatsnew/3.14.html#concurrent-safe-warnings-control\n    filters_func = getattr(warnings, \"_get_filters\", None)\n    warning_filters = (\n        filters_func() if filters_func is not None else warnings.filters\n    )\n\n    iterable_with_config_and_warning_filters = (\n        (\n            _with_config_and_warning_filters(delayed_func, config, warning_filters),\n            args,\n            kwargs,\n        )\n        for delayed_func, args, kwargs in iterable\n    )\n    return super().__call__(iterable_with_config_and_warning_filters)",
    "scikit-learn.sklearn.utils.parallel.delayed": "def delayed(function):\n    \"\"\"Decorator used to capture the arguments of a function.\n\n    This alternative to `joblib.delayed` is meant to be used in conjunction\n    with `sklearn.utils.parallel.Parallel`. The latter captures the scikit-\n    learn configuration by calling `sklearn.get_config()` in the current\n    thread, prior to dispatching the first task. The captured configuration is\n    then propagated and enabled for the duration of the execution of the\n    delayed function in the joblib workers.\n\n    .. versionchanged:: 1.3\n       `delayed` was moved from `sklearn.utils.fixes` to `sklearn.utils.parallel`\n       in scikit-learn 1.3.\n\n    Parameters\n    ----------\n    function : callable\n        The function to be delayed.\n\n    Returns\n    -------\n    output: tuple\n        Tuple containing the delayed function, the positional arguments, and the\n        keyword arguments.\n    \"\"\"\n\n    @functools.wraps(function)\n    def delayed_function(*args, **kwargs):\n        return _FuncWrapper(function), args, kwargs\n\n    return delayed_function"
}