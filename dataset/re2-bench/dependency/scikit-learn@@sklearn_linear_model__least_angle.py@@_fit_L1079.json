{
    "scikit-learn.sklearn.linear_model._base._preprocess_data": "def _preprocess_data(\n    X,\n    y,\n    *,\n    fit_intercept,\n    copy=True,\n    copy_y=True,\n    sample_weight=None,\n    check_input=True,\n    rescale_with_sw=True,\n):\n    \"\"\"Common data preprocessing for fitting linear models.\n\n    This helper is in charge of the following steps:\n\n    - `sample_weight` is assumed to be `None` or a validated array with same dtype as\n      `X`.\n    - If `check_input=True`, perform standard input validation of `X`, `y`.\n    - Perform copies if requested to avoid side-effects in case of inplace\n      modifications of the input.\n\n    Then, if `fit_intercept=True` this preprocessing centers both `X` and `y` as\n    follows:\n        - if `X` is dense, center the data and\n        store the mean vector in `X_offset`.\n        - if `X` is sparse, store the mean in `X_offset`\n        without centering `X`. The centering is expected to be handled by the\n        linear solver where appropriate.\n        - in either case, always center `y` and store the mean in `y_offset`.\n        - both `X_offset` and `y_offset` are always weighted by `sample_weight`\n          if not set to `None`.\n\n    If `fit_intercept=False`, no centering is performed and `X_offset`, `y_offset`\n    are set to zero.\n\n    If `rescale_with_sw` is True, then X and y are rescaled with the square root of\n    sample weights.\n\n    Returns\n    -------\n    X_out : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        If copy=True a copy of the input X is triggered, otherwise operations are\n        inplace.\n        If input X is dense, then X_out is centered.\n    y_out : {ndarray, sparse matrix} of shape (n_samples,) or (n_samples, n_targets)\n        Centered version of y. Possibly performed inplace on input y depending\n        on the copy_y parameter.\n    X_offset : ndarray of shape (n_features,)\n        The mean per column of input X.\n    y_offset : float or ndarray of shape (n_features,)\n    X_scale : ndarray of shape (n_features,)\n        Always an array of ones. TODO: refactor the code base to make it\n        possible to remove this unused variable.\n    sample_weight_sqrt : ndarray of shape (n_samples, ) or None\n        `np.sqrt(sample_weight)`\n    \"\"\"\n    xp, _, device_ = get_namespace_and_device(X, y, sample_weight)\n    n_samples, n_features = X.shape\n    X_is_sparse = sp.issparse(X)\n\n    if check_input:\n        X = check_array(\n            X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=supported_float_dtypes(xp)\n        )\n        y = check_array(y, dtype=X.dtype, copy=copy_y, ensure_2d=False)\n    else:\n        y = xp.astype(y, X.dtype, copy=copy_y)\n        if copy:\n            if X_is_sparse:\n                X = X.copy()\n            else:\n                X = _asarray_with_order(X, order=\"K\", copy=True, xp=xp)\n\n    dtype_ = X.dtype\n\n    if fit_intercept:\n        if X_is_sparse:\n            X_offset, X_var = mean_variance_axis(X, axis=0, weights=sample_weight)\n        else:\n            X_offset = _average(X, axis=0, weights=sample_weight, xp=xp)\n\n            X_offset = xp.astype(X_offset, X.dtype, copy=False)\n            X -= X_offset\n\n        y_offset = _average(y, axis=0, weights=sample_weight, xp=xp)\n        y -= y_offset\n    else:\n        X_offset = xp.zeros(n_features, dtype=X.dtype, device=device_)\n        if y.ndim == 1:\n            y_offset = xp.asarray(0.0, dtype=dtype_, device=device_)\n        else:\n            y_offset = xp.zeros(y.shape[1], dtype=dtype_, device=device_)\n\n    # X_scale is no longer needed. It is a historic artifact from the\n    # time where linear model exposed the normalize parameter.\n    X_scale = xp.ones(n_features, dtype=X.dtype, device=device_)\n\n    if sample_weight is not None and rescale_with_sw:\n        # Sample weight can be implemented via a simple rescaling.\n        # For sparse X and y, it triggers copies anyway.\n        # For dense X and y that already have been copied, we safely do inplace\n        # rescaling.\n        X, y, sample_weight_sqrt = _rescale_data(X, y, sample_weight, inplace=copy)\n    else:\n        sample_weight_sqrt = None\n    return X, y, X_offset, y_offset, X_scale, sample_weight_sqrt",
    "scikit-learn.sklearn.linear_model._base._set_intercept": "def _set_intercept(self, X_offset, y_offset, X_scale=None):\n    \"\"\"Set the intercept_\"\"\"\n    xp, _ = get_namespace(X_offset, y_offset, X_scale)\n\n    if self.fit_intercept:\n        # We always want coef_.dtype=X.dtype. For instance, X.dtype can differ from\n        # coef_.dtype if warm_start=True.\n        self.coef_ = xp.astype(self.coef_, X_offset.dtype, copy=False)\n        if X_scale is not None:\n            self.coef_ = xp.divide(self.coef_, X_scale)\n\n        if self.coef_.ndim == 1:\n            self.intercept_ = y_offset - X_offset @ self.coef_\n        else:\n            self.intercept_ = y_offset - X_offset @ self.coef_.T\n\n    else:\n        self.intercept_ = 0.0",
    "scikit-learn.sklearn.linear_model._least_angle._get_gram": "@staticmethod\ndef _get_gram(precompute, X, y):\n    if (not hasattr(precompute, \"__array__\")) and (\n        (precompute is True)\n        or (precompute == \"auto\" and X.shape[0] > X.shape[1])\n        or (precompute == \"auto\" and y.shape[1] > 1)\n    ):\n        precompute = np.dot(X.T, X)\n\n    return precompute",
    "scikit-learn.sklearn.linear_model._least_angle.<listcomp>": "self.alphas_, self.active_, self.coef_path_, self.coef_ = [\n    a[0]\n    for a in (self.alphas_, self.active_, self.coef_path_, self.coef_)\n",
    "scikit-learn.sklearn.utils._param_validation.wrapper": "@functools.wraps(func)\ndef wrapper(*args, **kwargs):\n    global_skip_validation = get_config()[\"skip_parameter_validation\"]\n    if global_skip_validation:\n        return func(*args, **kwargs)\n\n    func_sig = signature(func)\n\n    # Map *args/**kwargs to the function signature\n    params = func_sig.bind(*args, **kwargs)\n    params.apply_defaults()\n\n    # ignore self/cls and positional/keyword markers\n    to_ignore = [\n        p.name\n        for p in func_sig.parameters.values()\n        if p.kind in (p.VAR_POSITIONAL, p.VAR_KEYWORD)\n    ]\n    to_ignore += [\"self\", \"cls\"]\n    params = {k: v for k, v in params.arguments.items() if k not in to_ignore}\n\n    validate_parameter_constraints(\n        parameter_constraints, params, caller_name=func.__qualname__\n    )\n\n    try:\n        with config_context(\n            skip_parameter_validation=(\n                prefer_skip_nested_validation or global_skip_validation\n            )\n        ):\n            return func(*args, **kwargs)\n    except InvalidParameterError as e:\n        # When the function is just a wrapper around an estimator, we allow\n        # the function to delegate validation to the estimator, but we replace\n        # the name of the estimator by the name of the function in the error\n        # message to avoid confusion.\n        msg = re.sub(\n            r\"parameter of \\w+ must be\",\n            f\"parameter of {func.__qualname__} must be\",\n            str(e),\n        )\n        raise InvalidParameterError(msg) from e"
}