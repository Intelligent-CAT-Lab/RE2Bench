{
    "scikit-learn.sklearn.base.wrapper": "@functools.wraps(fit_method)\ndef wrapper(estimator, *args, **kwargs):\n    global_skip_validation = get_config()[\"skip_parameter_validation\"]\n\n    # we don't want to validate again for each call to partial_fit\n    partial_fit_and_fitted = (\n        fit_method.__name__ == \"partial_fit\" and _is_fitted(estimator)\n    )\n\n    if not global_skip_validation and not partial_fit_and_fitted:\n        estimator._validate_params()\n\n    with config_context(\n        skip_parameter_validation=(\n            prefer_skip_nested_validation or global_skip_validation\n        )\n    ):\n        return fit_method(estimator, *args, **kwargs)",
    "scikit-learn.sklearn.cluster._kmeans.predict": "def predict(self, X):\n    \"\"\"Predict the closest cluster each sample in X belongs to.\n\n    In the vector quantization literature, `cluster_centers_` is called\n    the code book and each value returned by `predict` is the index of\n    the closest code in the code book.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        New data to predict.\n\n    Returns\n    -------\n    labels : ndarray of shape (n_samples,)\n        Index of the cluster each sample belongs to.\n    \"\"\"\n    check_is_fitted(self)\n\n    X = self._check_test_data(X)\n\n    # sample weights are not used by predict but cython helpers expect an array\n    sample_weight = np.ones(X.shape[0], dtype=X.dtype)\n\n    labels = _labels_inertia_threadpool_limit(\n        X,\n        sample_weight,\n        self.cluster_centers_,\n        n_threads=self._n_threads,\n        return_inertia=False,\n    )\n\n    return labels",
    "scikit-learn.sklearn.ensemble._forest.predict": "def predict(self, X):\n    \"\"\"\n    Predict class for X.\n\n    The predicted class of an input sample is a vote by the trees in\n    the forest, weighted by their probability estimates. That is,\n    the predicted class is the one with highest mean probability\n    estimate across the trees.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples. Internally, its dtype will be converted to\n        ``dtype=np.float32``. If a sparse matrix is provided, it will be\n        converted into a sparse ``csr_matrix``.\n\n    Returns\n    -------\n    y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n        The predicted classes.\n    \"\"\"\n    proba = self.predict_proba(X)\n\n    if self.n_outputs_ == 1:\n        return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n\n    else:\n        n_samples = proba[0].shape[0]\n        # all dtypes should be the same, so just take the first\n        class_type = self.classes_[0].dtype\n        predictions = np.empty((n_samples, self.n_outputs_), dtype=class_type)\n\n        for k in range(self.n_outputs_):\n            predictions[:, k] = self.classes_[k].take(\n                np.argmax(proba[k], axis=1), axis=0\n            )\n\n        return predictions",
    "scikit-learn.sklearn.ensemble._forest.predict_proba": "def predict_proba(self, X):\n    \"\"\"\n    Predict class probabilities for X.\n\n    The predicted class probabilities of an input sample are computed as\n    the mean predicted class probabilities of the trees in the forest.\n    The class probability of a single tree is the fraction of samples of\n    the same class in a leaf.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples. Internally, its dtype will be converted to\n        ``dtype=np.float32``. If a sparse matrix is provided, it will be\n        converted into a sparse ``csr_matrix``.\n\n    Returns\n    -------\n    p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n        The class probabilities of the input samples. The order of the\n        classes corresponds to that in the attribute :term:`classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    # Check data\n    X = self._validate_X_predict(X)\n\n    # Assign chunk of trees to jobs\n    n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n\n    # avoid storing the output of every estimator by summing them here\n    all_proba = [\n        np.zeros((X.shape[0], j), dtype=np.float64)\n        for j in np.atleast_1d(self.n_classes_)\n    ]\n    lock = threading.Lock()\n    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n        delayed(_accumulate_prediction)(e.predict_proba, X, all_proba, lock)\n        for e in self.estimators_\n    )\n\n    for proba in all_proba:\n        proba /= len(self.estimators_)\n\n    if len(all_proba) == 1:\n        return all_proba[0]\n    else:\n        return all_proba",
    "scikit-learn.sklearn.ensemble._forest.predict_log_proba": "def predict_log_proba(self, X):\n    \"\"\"\n    Predict class log-probabilities for X.\n\n    The predicted class log-probabilities of an input sample is computed as\n    the log of the mean predicted class probabilities of the trees in the\n    forest.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples. Internally, its dtype will be converted to\n        ``dtype=np.float32``. If a sparse matrix is provided, it will be\n        converted into a sparse ``csr_matrix``.\n\n    Returns\n    -------\n    p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n        The class probabilities of the input samples. The order of the\n        classes corresponds to that in the attribute :term:`classes_`.\n    \"\"\"\n    proba = self.predict_proba(X)\n\n    if self.n_outputs_ == 1:\n        return np.log(proba)\n\n    else:\n        for k in range(self.n_outputs_):\n            proba[k] = np.log(proba[k])\n\n        return proba",
    "scikit-learn.sklearn.ensemble._voting.predict_proba": "@available_if(_check_voting)\ndef predict_proba(self, X):\n    \"\"\"Compute probabilities of possible outcomes for samples in X.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples.\n\n    Returns\n    -------\n    avg : array-like of shape (n_samples, n_classes)\n        Weighted average probability for each class per sample.\n    \"\"\"\n    check_is_fitted(self)\n    avg = np.average(\n        self._collect_probas(X), axis=0, weights=self._weights_not_none\n    )\n    return avg",
    "scikit-learn.sklearn.frozen._frozen.__getattr__": "def __getattr__(self, name):\n    # `estimator`'s attributes are now accessible except `fit_predict` and\n    # `fit_transform`\n    if name in [\"fit_predict\", \"fit_transform\"]:\n        raise AttributeError(f\"{name} is not available for frozen estimators.\")\n    return getattr(self.estimator, name)",
    "scikit-learn.sklearn.frozen._frozen.fit": "def fit(self, X, y, *args, **kwargs):\n    \"\"\"No-op.\n\n    As a frozen estimator, calling `fit` has no effect.\n\n    Parameters\n    ----------\n    X : object\n        Ignored.\n\n    y : object\n        Ignored.\n\n    *args : tuple\n        Additional positional arguments. Ignored, but present for API compatibility\n        with `self.estimator`.\n\n    **kwargs : dict\n        Additional keyword arguments. Ignored, but present for API compatibility\n        with `self.estimator`.\n\n    Returns\n    -------\n    self : object\n        Returns the instance itself.\n    \"\"\"\n    check_is_fitted(self.estimator)\n    return self",
    "scikit-learn.sklearn.linear_model._base.predict": "def predict(self, X):\n    \"\"\"\n    Predict class labels for samples in X.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix for which we want to get the predictions.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,)\n        Vector containing the class labels for each sample.\n    \"\"\"\n    xp, _ = get_namespace(X)\n    scores = self.decision_function(X)\n    if len(scores.shape) == 1:\n        indices = xp.astype(scores > 0, indexing_dtype(xp))\n    else:\n        indices = xp.argmax(scores, axis=1)\n\n    return xp.take(self.classes_, indices, axis=0)",
    "scikit-learn.sklearn.linear_model._base.decision_function": "def decision_function(self, X):\n    \"\"\"\n    Predict confidence scores for samples.\n\n    The confidence score for a sample is proportional to the signed\n    distance of that sample to the hyperplane.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix for which we want to get the confidence scores.\n\n    Returns\n    -------\n    scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n        Confidence scores per `(n_samples, n_classes)` combination. In the\n        binary case, confidence score for `self.classes_[1]` where >0 means\n        this class would be predicted.\n    \"\"\"\n    check_is_fitted(self)\n    xp, _ = get_namespace(X)\n\n    X = validate_data(self, X, accept_sparse=\"csr\", reset=False)\n    coef_T = self.coef_.T if self.coef_.ndim == 2 else self.coef_\n    scores = safe_sparse_dot(X, coef_T, dense_output=True) + self.intercept_\n    return (\n        xp.reshape(scores, (-1,))\n        if (scores.ndim > 1 and scores.shape[1] == 1)\n        else scores\n    )",
    "scikit-learn.sklearn.linear_model._logistic.predict_proba": "# Could not extract code for scikit-learn.sklearn.linear_model._logistic.predict_proba",
    "scikit-learn.sklearn.linear_model._logistic.predict_log_proba": "# Could not extract code for scikit-learn.sklearn.linear_model._logistic.predict_log_proba",
    "scikit-learn.sklearn.linear_model._ridge.predict": "def predict(self, X):\n    \"\"\"Predict class labels for samples in `X`.\n\n    Parameters\n    ----------\n    X : {array-like, spare matrix} of shape (n_samples, n_features)\n        The data matrix for which we want to predict the targets.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n        Vector or matrix containing the predictions. In binary and\n        multiclass problems, this is a vector containing `n_samples`. In\n        a multilabel problem, it returns a matrix of shape\n        `(n_samples, n_outputs)`.\n    \"\"\"\n    check_is_fitted(self, attributes=[\"_label_binarizer\"])\n    if self._label_binarizer.y_type_.startswith(\"multilabel\"):\n        # Threshold such that the negative label is -1 and positive label\n        # is 1 to use the inverse transform of the label binarizer fitted\n        # during fit.\n        decision = self.decision_function(X)\n        xp, _ = get_namespace(decision)\n        scores = 2.0 * xp.astype(decision > 0, decision.dtype) - 1.0\n        return self._label_binarizer.inverse_transform(scores)\n    return super().predict(X)",
    "scikit-learn.sklearn.linear_model._stochastic_gradient.predict_proba": "@available_if(_check_proba)\ndef predict_proba(self, X):\n    \"\"\"Probability estimates.\n\n    This method is only available for log loss and modified Huber loss.\n\n    Multiclass probability estimates are derived from binary (one-vs.-rest)\n    estimates by simple normalization, as recommended by Zadrozny and\n    Elkan.\n\n    Binary probability estimates for loss=\"modified_huber\" are given by\n    (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions\n    it is necessary to perform proper probability calibration by wrapping\n    the classifier with\n    :class:`~sklearn.calibration.CalibratedClassifierCV` instead.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        Input data for prediction.\n\n    Returns\n    -------\n    ndarray of shape (n_samples, n_classes)\n        Returns the probability of the sample for each class in the model,\n        where classes are ordered as they are in `self.classes_`.\n\n    References\n    ----------\n    Zadrozny and Elkan, \"Transforming classifier scores into multiclass\n    probability estimates\", SIGKDD'02,\n    https://dl.acm.org/doi/pdf/10.1145/775047.775151\n\n    The justification for the formula in the loss=\"modified_huber\"\n    case is in the appendix B in:\n    http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf\n    \"\"\"\n    check_is_fitted(self)\n\n    if self.loss == \"log_loss\":\n        return self._predict_proba_lr(X)\n\n    elif self.loss == \"modified_huber\":\n        binary = len(self.classes_) == 2\n        scores = self.decision_function(X)\n\n        if binary:\n            prob2 = np.ones((scores.shape[0], 2))\n            prob = prob2[:, 1]\n        else:\n            prob = scores\n\n        np.clip(scores, -1, 1, prob)\n        prob += 1.0\n        prob /= 2.0\n\n        if binary:\n            prob2[:, 0] -= prob\n            prob = prob2\n        else:\n            # the above might assign zero to all classes, which doesn't\n            # normalize neatly; work around this to produce uniform\n            # probabilities\n            prob_sum = prob.sum(axis=1)\n            all_zero = prob_sum == 0\n            if np.any(all_zero):\n                prob[all_zero, :] = 1\n                prob_sum[all_zero] = len(self.classes_)\n\n            # normalize\n            prob /= prob_sum.reshape((prob.shape[0], -1))\n\n        return prob\n\n    else:\n        raise NotImplementedError(\n            \"predict_(log_)proba only supported when\"\n            \" loss='log_loss' or loss='modified_huber' \"\n            \"(%r given)\" % self.loss\n        )",
    "scikit-learn.sklearn.linear_model._stochastic_gradient.predict_log_proba": "@available_if(_check_proba)\ndef predict_log_proba(self, X):\n    \"\"\"Log of probability estimates.\n\n    This method is only available for log loss and modified Huber loss.\n\n    When loss=\"modified_huber\", probability estimates may be hard zeros\n    and ones, so taking the logarithm is not possible.\n\n    See ``predict_proba`` for details.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input data for prediction.\n\n    Returns\n    -------\n    T : array-like, shape (n_samples, n_classes)\n        Returns the log-probability of the sample for each class in the\n        model, where classes are ordered as they are in\n        `self.classes_`.\n    \"\"\"\n    return np.log(self.predict_proba(X))",
    "scikit-learn.sklearn.linear_model._stochastic_gradient.predict": "def predict(self, X):\n    \"\"\"Predict using the linear model.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}, shape (n_samples, n_features)\n        Input data.\n\n    Returns\n    -------\n    ndarray of shape (n_samples,)\n       Predicted target values per element in X.\n    \"\"\"\n    return self._decision_function(X)",
    "scikit-learn.sklearn.model_selection._search.predict_proba": "@available_if(_search_estimator_has(\"predict_proba\"))\ndef predict_proba(self, X):\n    \"\"\"Call predict_proba on the estimator with the best found parameters.\n\n    Only available if ``refit=True`` and the underlying estimator supports\n    ``predict_proba``.\n\n    Parameters\n    ----------\n    X : indexable, length n_samples\n        Must fulfill the input assumptions of the\n        underlying estimator.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n        Predicted class probabilities for `X` based on the estimator with\n        the best found parameters. The order of the classes corresponds\n        to that in the fitted attribute :term:`classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    return self.best_estimator_.predict_proba(X)",
    "scikit-learn.sklearn.model_selection._search.predict_log_proba": "@available_if(_search_estimator_has(\"predict_log_proba\"))\ndef predict_log_proba(self, X):\n    \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n\n    Only available if ``refit=True`` and the underlying estimator supports\n    ``predict_log_proba``.\n\n    Parameters\n    ----------\n    X : indexable, length n_samples\n        Must fulfill the input assumptions of the\n        underlying estimator.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n        Predicted class log-probabilities for `X` based on the estimator\n        with the best found parameters. The order of the classes\n        corresponds to that in the fitted attribute :term:`classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    return self.best_estimator_.predict_log_proba(X)",
    "scikit-learn.sklearn.model_selection._search.decision_function": "@available_if(_search_estimator_has(\"decision_function\"))\ndef decision_function(self, X):\n    \"\"\"Call decision_function on the estimator with the best found parameters.\n\n    Only available if ``refit=True`` and the underlying estimator supports\n    ``decision_function``.\n\n    Parameters\n    ----------\n    X : indexable, length n_samples\n        Must fulfill the input assumptions of the\n        underlying estimator.\n\n    Returns\n    -------\n    y_score : ndarray of shape (n_samples,) or (n_samples, n_classes) \\\n            or (n_samples, n_classes * (n_classes-1) / 2)\n        Result of the decision function for `X` based on the estimator with\n        the best found parameters.\n    \"\"\"\n    check_is_fitted(self)\n    return self.best_estimator_.decision_function(X)",
    "scikit-learn.sklearn.model_selection._search.classes_": "@property\ndef classes_(self):\n    \"\"\"Class labels.\n\n    Only available when `refit=True` and the estimator is a classifier.\n    \"\"\"\n    _search_estimator_has(\"classes_\")(self)\n    return self.best_estimator_.classes_",
    "scikit-learn.sklearn.model_selection._validation.<listcomp>": "predictions = [\n    _enforce_prediction_order(\n        estimator.classes_[i_label],\n        predictions[i_label],\n        n_classes=len(set(y[:, i_label])),\n        method=method,\n    )\n    for i_label in range(len(predictions))\n",
    "scikit-learn.sklearn.model_selection._validation._enforce_prediction_order": "def _enforce_prediction_order(classes, predictions, n_classes, method):\n    \"\"\"Ensure that prediction arrays have correct column order\n\n    When doing cross-validation, if one or more classes are\n    not present in the subset of data used for training,\n    then the output prediction array might not have the same\n    columns as other folds. Use the list of class names\n    (assumed to be ints) to enforce the correct column order.\n\n    Note that `classes` is the list of classes in this fold\n    (a subset of the classes in the full training set)\n    and `n_classes` is the number of classes in the full training set.\n    \"\"\"\n    xp, _ = get_namespace(predictions, classes)\n    classes_length = classes.shape[0]\n    if n_classes != classes_length:\n        recommendation = (\n            \"To fix this, use a cross-validation \"\n            \"technique resulting in properly \"\n            \"stratified folds\"\n        )\n        warnings.warn(\n            \"Number of classes in training fold ({}) does \"\n            \"not match total number of classes ({}). \"\n            \"Results may not be appropriate for your use case. \"\n            \"{}\".format(classes_length, n_classes, recommendation),\n            RuntimeWarning,\n        )\n        if method == \"decision_function\":\n            if predictions.ndim == 2 and predictions.shape[1] != classes_length:\n                # This handles the case when the shape of predictions\n                # does not match the number of classes used to train\n                # it with. This case is found when sklearn.svm.SVC is\n                # set to `decision_function_shape='ovo'`.\n                raise ValueError(\n                    \"Output shape {} of {} does not match \"\n                    \"number of classes ({}) in fold. \"\n                    \"Irregular decision_function outputs \"\n                    \"are not currently supported by \"\n                    \"cross_val_predict\".format(\n                        predictions.shape, method, classes_length\n                    )\n                )\n            if classes_length <= 2:\n                # In this special case, `predictions` contains a 1D array.\n                raise ValueError(\n                    \"Only {} class/es in training fold, but {} \"\n                    \"in overall dataset. This \"\n                    \"is not supported for decision_function \"\n                    \"with imbalanced folds. {}\".format(\n                        classes_length, n_classes, recommendation\n                    )\n                )\n\n        float_min = xp.finfo(predictions.dtype).min\n        default_values = {\n            \"decision_function\": float_min,\n            \"predict_log_proba\": float_min,\n            \"predict_proba\": 0,\n        }\n        predictions_for_all_classes = xp.full(\n            (_num_samples(predictions), n_classes),\n            default_values[method],\n            dtype=predictions.dtype,\n        )\n        predictions_for_all_classes[:, classes] = predictions\n        predictions = predictions_for_all_classes\n    return predictions",
    "scikit-learn.sklearn.multiclass.predict": "def predict(self, X):\n    \"\"\"Predict multi-class targets using underlying estimators.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Data.\n\n    Returns\n    -------\n    y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_classes)\n        Predicted multi-class targets.\n    \"\"\"\n    check_is_fitted(self)\n\n    n_samples = _num_samples(X)\n    if self.label_binarizer_.y_type_ == \"multiclass\":\n        maxima = np.empty(n_samples, dtype=float)\n        maxima.fill(-np.inf)\n        argmaxima = np.zeros(n_samples, dtype=int)\n        n_classes = len(self.estimators_)\n        # Iterate in reverse order to match np.argmax tie-breaking behavior\n        for i, e in enumerate(reversed(self.estimators_)):\n            pred = _predict_binary(e, X)\n            np.maximum(maxima, pred, out=maxima)\n            argmaxima[maxima == pred] = n_classes - i - 1\n        return self.classes_[argmaxima]\n    else:\n        thresh = _threshold_for_binary_predict(self.estimators_[0])\n        indices = array.array(\"i\")\n        indptr = array.array(\"i\", [0])\n        for e in self.estimators_:\n            indices.extend(np.where(_predict_binary(e, X) > thresh)[0])\n            indptr.append(len(indices))\n        data = np.ones(len(indices), dtype=int)\n        indicator = sp.csc_matrix(\n            (data, indices, indptr), shape=(n_samples, len(self.estimators_))\n        )\n        return self.label_binarizer_.inverse_transform(indicator)",
    "scikit-learn.sklearn.multiclass.predict_proba": "@available_if(_estimators_has(\"predict_proba\"))\ndef predict_proba(self, X):\n    \"\"\"Probability estimates.\n\n    The returned estimates for all classes are ordered by label of classes.\n\n    Note that in the multilabel case, each sample can have any number of\n    labels. This returns the marginal probability that the given sample has\n    the label in question. For example, it is entirely consistent that two\n    labels both have a 90% probability of applying to a given sample.\n\n    In the single label multiclass case, the rows of the returned matrix\n    sum to 1.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Input data.\n\n    Returns\n    -------\n    T : array-like of shape (n_samples, n_classes)\n        Returns the probability of the sample for each class in the model,\n        where classes are ordered as they are in `self.classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    # Y[i, j] gives the probability that sample i has the label j.\n    # In the multi-label case, these are not disjoint.\n    Y = np.array([e.predict_proba(X)[:, 1] for e in self.estimators_]).T\n\n    if len(self.estimators_) == 1:\n        # Only one estimator, but we still want to return probabilities\n        # for two classes.\n        Y = np.concatenate(((1 - Y), Y), axis=1)\n\n    if not self.multilabel_:\n        # Then, (nonzero) sample probability distributions should be normalized.\n        row_sums = np.sum(Y, axis=1)[:, np.newaxis]\n        np.divide(Y, row_sums, out=Y, where=row_sums != 0)\n\n    return Y",
    "scikit-learn.sklearn.multiclass.decision_function": "@available_if(_estimators_has(\"decision_function\"))\ndef decision_function(self, X):\n    \"\"\"Decision function for the OneVsRestClassifier.\n\n    Return the distance of each sample from the decision boundary for each\n    class. This can only be used with estimators which implement the\n    `decision_function` method.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Input data.\n\n    Returns\n    -------\n    T : array-like of shape (n_samples, n_classes) or (n_samples,) for \\\n        binary classification.\n        Result of calling `decision_function` on the final estimator.\n\n        .. versionchanged:: 0.19\n            output shape changed to ``(n_samples,)`` to conform to\n            scikit-learn conventions for binary classification.\n    \"\"\"\n    check_is_fitted(self)\n    if len(self.estimators_) == 1:\n        return self.estimators_[0].decision_function(X)\n    return np.array(\n        [est.decision_function(X).ravel() for est in self.estimators_]\n    ).T",
    "scikit-learn.sklearn.naive_bayes.predict_proba": "def predict_proba(self, X):\n    \"\"\"\n    Return probability estimates for the test vector X.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        The input samples.\n\n    Returns\n    -------\n    C : array-like of shape (n_samples, n_classes)\n        Returns the probability of the samples for each class in\n        the model. The columns correspond to the classes in sorted\n        order, as they appear in the attribute :term:`classes_`.\n    \"\"\"\n    xp, _ = get_namespace(X)\n    return xp.exp(self.predict_log_proba(X))",
    "scikit-learn.sklearn.neighbors._regression.predict": "def predict(self, X):\n    \"\"\"Predict the target for the provided data.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_queries, n_features), \\\n            or (n_queries, n_indexed) if metric == 'precomputed', or None\n        Test samples. If `None`, predictions for all indexed points are\n        returned; in this case, points are not considered their own\n        neighbors.\n\n    Returns\n    -------\n    y : ndarray of shape (n_queries,) or (n_queries, n_outputs), \\\n            dtype=double\n        Target values.\n    \"\"\"\n    neigh_dist, neigh_ind = self.radius_neighbors(X)\n\n    weights = _get_weights(neigh_dist, self.weights)\n\n    _y = self._y\n    if _y.ndim == 1:\n        _y = _y.reshape((-1, 1))\n\n    empty_obs = np.full_like(_y[0], np.nan)\n\n    if weights is None:\n        y_pred = np.array(\n            [\n                np.mean(_y[ind, :], axis=0) if len(ind) else empty_obs\n                for (i, ind) in enumerate(neigh_ind)\n            ]\n        )\n\n    else:\n        y_pred = np.array(\n            [\n                (\n                    np.average(_y[ind, :], axis=0, weights=weights[i])\n                    if len(ind)\n                    else empty_obs\n                )\n                for (i, ind) in enumerate(neigh_ind)\n            ]\n        )\n\n    if np.any(np.isnan(y_pred)):\n        empty_warning_msg = (\n            \"One or more samples have no neighbors \"\n            \"within specified radius; predicting NaN.\"\n        )\n        warnings.warn(empty_warning_msg)\n\n    if self._y.ndim == 1:\n        y_pred = y_pred.ravel()\n\n    return y_pred",
    "scikit-learn.sklearn.neural_network._multilayer_perceptron.predict": "def predict(self, X):\n    \"\"\"Predict using the multi-layer perceptron classifier.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input data.\n\n    Returns\n    -------\n    y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n        The predicted classes.\n    \"\"\"\n    check_is_fitted(self)\n    return self._predict(X)",
    "scikit-learn.sklearn.neural_network._multilayer_perceptron.predict_proba": "def predict_proba(self, X):\n    \"\"\"Probability estimates.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input data.\n\n    Returns\n    -------\n    y_prob : ndarray of shape (n_samples, n_classes)\n        The predicted probability of the sample for each class in the\n        model, where classes are ordered as they are in `self.classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    y_pred = self._forward_pass_fast(X)\n\n    if self.n_outputs_ == 1:\n        y_pred = y_pred.ravel()\n\n    if y_pred.ndim == 1:\n        return np.vstack([1 - y_pred, y_pred]).T\n    else:\n        return y_pred",
    "scikit-learn.sklearn.pipeline.classes_": "@property\ndef classes_(self):\n    \"\"\"The classes labels. Only exist if the last step is a classifier.\"\"\"\n    return self.steps[-1][1].classes_",
    "scikit-learn.sklearn.pipeline.predict": "@available_if(_final_estimator_has(\"predict\"))\ndef predict(self, X, **params):\n    \"\"\"Transform the data, and apply `predict` with the final estimator.\n\n    Call `transform` of each transformer in the pipeline. The transformed\n    data are finally passed to the final estimator that calls `predict`\n    method. Only valid if the final estimator implements `predict`.\n\n    Parameters\n    ----------\n    X : iterable\n        Data to predict on. Must fulfill input requirements of first step\n        of the pipeline.\n\n    **params : dict of str -> object\n        - If `enable_metadata_routing=False` (default): Parameters to the\n          ``predict`` called at the end of all transformations in the pipeline.\n\n        - If `enable_metadata_routing=True`: Parameters requested and accepted by\n          steps. Each step must have requested certain metadata for these parameters\n          to be forwarded to them.\n\n        .. versionadded:: 0.20\n\n        .. versionchanged:: 1.4\n            Parameters are now passed to the ``transform`` method of the\n            intermediate steps as well, if requested, and if\n            `enable_metadata_routing=True` is set via\n            :func:`~sklearn.set_config`.\n\n        See :ref:`Metadata Routing User Guide <metadata_routing>` for more\n        details.\n\n        Note that while this may be used to return uncertainties from some\n        models with ``return_std`` or ``return_cov``, uncertainties that are\n        generated by the transformations in the pipeline are not propagated\n        to the final estimator.\n\n    Returns\n    -------\n    y_pred : ndarray\n        Result of calling `predict` on the final estimator.\n    \"\"\"\n    check_is_fitted(self)\n    Xt = X\n\n    if not _routing_enabled():\n        for _, name, transform in self._iter(with_final=False):\n            Xt = transform.transform(Xt)\n        return self.steps[-1][1].predict(Xt, **params)\n\n    # metadata routing enabled\n    routed_params = process_routing(self, \"predict\", **params)\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **routed_params[name].transform)\n    return self.steps[-1][1].predict(Xt, **routed_params[self.steps[-1][0]].predict)",
    "scikit-learn.sklearn.pipeline.predict_proba": "@available_if(_final_estimator_has(\"predict_proba\"))\ndef predict_proba(self, X, **params):\n    \"\"\"Transform the data, and apply `predict_proba` with the final estimator.\n\n    Call `transform` of each transformer in the pipeline. The transformed\n    data are finally passed to the final estimator that calls\n    `predict_proba` method. Only valid if the final estimator implements\n    `predict_proba`.\n\n    Parameters\n    ----------\n    X : iterable\n        Data to predict on. Must fulfill input requirements of first step\n        of the pipeline.\n\n    **params : dict of str -> object\n        - If `enable_metadata_routing=False` (default): Parameters to the\n          `predict_proba` called at the end of all transformations in the pipeline.\n\n        - If `enable_metadata_routing=True`: Parameters requested and accepted by\n          steps. Each step must have requested certain metadata for these parameters\n          to be forwarded to them.\n\n        .. versionadded:: 0.20\n\n        .. versionchanged:: 1.4\n            Parameters are now passed to the ``transform`` method of the\n            intermediate steps as well, if requested, and if\n            `enable_metadata_routing=True`.\n\n        See :ref:`Metadata Routing User Guide <metadata_routing>` for more\n        details.\n\n    Returns\n    -------\n    y_proba : ndarray of shape (n_samples, n_classes)\n        Result of calling `predict_proba` on the final estimator.\n    \"\"\"\n    check_is_fitted(self)\n    Xt = X\n\n    if not _routing_enabled():\n        for _, name, transform in self._iter(with_final=False):\n            Xt = transform.transform(Xt)\n        return self.steps[-1][1].predict_proba(Xt, **params)\n\n    # metadata routing enabled\n    routed_params = process_routing(self, \"predict_proba\", **params)\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **routed_params[name].transform)\n    return self.steps[-1][1].predict_proba(\n        Xt, **routed_params[self.steps[-1][0]].predict_proba\n    )",
    "scikit-learn.sklearn.pipeline.decision_function": "@available_if(_final_estimator_has(\"decision_function\"))\ndef decision_function(self, X, **params):\n    \"\"\"Transform the data, and apply `decision_function` with the final estimator.\n\n    Call `transform` of each transformer in the pipeline. The transformed\n    data are finally passed to the final estimator that calls\n    `decision_function` method. Only valid if the final estimator\n    implements `decision_function`.\n\n    Parameters\n    ----------\n    X : iterable\n        Data to predict on. Must fulfill input requirements of first step\n        of the pipeline.\n\n    **params : dict of string -> object\n        Parameters requested and accepted by steps. Each step must have\n        requested certain metadata for these parameters to be forwarded to\n        them.\n\n        .. versionadded:: 1.4\n            Only available if `enable_metadata_routing=True`. See\n            :ref:`Metadata Routing User Guide <metadata_routing>` for more\n            details.\n\n    Returns\n    -------\n    y_score : ndarray of shape (n_samples, n_classes)\n        Result of calling `decision_function` on the final estimator.\n    \"\"\"\n    check_is_fitted(self)\n    _raise_for_params(params, self, \"decision_function\")\n\n    # not branching here since params is only available if\n    # enable_metadata_routing=True\n    routed_params = process_routing(self, \"decision_function\", **params)\n\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(\n            Xt, **routed_params.get(name, {}).get(\"transform\", {})\n        )\n    return self.steps[-1][1].decision_function(\n        Xt,\n        **routed_params.get(self.steps[-1][0], {}).get(\"decision_function\", {}),\n    )",
    "scikit-learn.sklearn.svm._base.predict": "def predict(self, X):\n    \"\"\"Perform regression on samples in X.\n\n    For a one-class model, +1 (inlier) or -1 (outlier) is returned.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        For kernel=\"precomputed\", the expected shape of X is\n        (n_samples_test, n_samples_train).\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,)\n        The predicted values.\n    \"\"\"\n    X = self._validate_for_predict(X)\n    predict = self._sparse_predict if self._sparse else self._dense_predict\n    return predict(X)",
    "scikit-learn.sklearn.svm._base.decision_function": "def decision_function(self, X):\n    \"\"\"Evaluate the decision function for the samples in X.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        The input samples.\n\n    Returns\n    -------\n    X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n        Returns the decision function of the sample for each class\n        in the model.\n        If decision_function_shape='ovr', the shape is (n_samples,\n        n_classes).\n\n    Notes\n    -----\n    If decision_function_shape='ovo', the function values are proportional\n    to the distance of the samples X to the separating hyperplane. If the\n    exact distances are required, divide the function values by the norm of\n    the weight vector (``coef_``). See also `this question\n    <https://stats.stackexchange.com/questions/14876/\n    interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n    If decision_function_shape='ovr', the decision function is a monotonic\n    transformation of ovo decision function.\n    \"\"\"\n    dec = self._decision_function(X)\n    if self.decision_function_shape == \"ovr\" and len(self.classes_) > 2:\n        return _ovr_decision_function(dec < 0, -dec, len(self.classes_))\n    return dec",
    "scikit-learn.sklearn.svm._base.predict_proba": "@available_if(_check_proba)\ndef predict_proba(self, X):\n    \"\"\"Compute probabilities of possible outcomes for samples in X.\n\n    The model needs to have probability information computed at training\n    time: fit with attribute `probability` set to True.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        For kernel=\"precomputed\", the expected shape of X is\n        (n_samples_test, n_samples_train).\n\n    Returns\n    -------\n    T : ndarray of shape (n_samples, n_classes)\n        Returns the probability of the sample for each class in\n        the model. The columns correspond to the classes in sorted\n        order, as they appear in the attribute :term:`classes_`.\n\n    Notes\n    -----\n    The probability model is created using cross validation, so\n    the results can be slightly different than those obtained by\n    predict. Also, it will produce meaningless results on very small\n    datasets.\n    \"\"\"\n    X = self._validate_for_predict(X)\n    if self.probA_.size == 0 or self.probB_.size == 0:\n        raise NotFittedError(\n            \"predict_proba is not available when fitted with probability=False\"\n        )\n    pred_proba = (\n        self._sparse_predict_proba if self._sparse else self._dense_predict_proba\n    )\n    return pred_proba(X)",
    "scikit-learn.sklearn.tree._classes.predict_proba": "def predict_proba(self, X, check_input=True):\n    \"\"\"Predict class probabilities of the input samples X.\n\n    The predicted class probability is the fraction of samples of the same\n    class in a leaf.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples. Internally, it will be converted to\n        ``dtype=np.float32`` and if a sparse matrix is provided\n        to a sparse ``csr_matrix``.\n\n    check_input : bool, default=True\n        Allow to bypass several input checking.\n        Don't use this parameter unless you know what you're doing.\n\n    Returns\n    -------\n    proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n        such arrays if n_outputs > 1\n        The class probabilities of the input samples. The order of the\n        classes corresponds to that in the attribute :term:`classes_`.\n    \"\"\"\n    check_is_fitted(self)\n    X = self._validate_X_predict(X, check_input)\n    proba = self.tree_.predict(X)\n\n    if self.n_outputs_ == 1:\n        return proba[:, : self.n_classes_]\n    else:\n        all_proba = []\n        for k in range(self.n_outputs_):\n            proba_k = proba[:, k, : self.n_classes_[k]]\n            all_proba.append(proba_k)\n        return all_proba",
    "scikit-learn.sklearn.tree._classes.predict": "def predict(self, X, check_input=True):\n    \"\"\"Predict class or regression value for X.\n\n    For a classification model, the predicted class for each sample in X is\n    returned. For a regression model, the predicted value based on X is\n    returned.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples. Internally, it will be converted to\n        ``dtype=np.float32`` and if a sparse matrix is provided\n        to a sparse ``csr_matrix``.\n\n    check_input : bool, default=True\n        Allow to bypass several input checking.\n        Don't use this parameter unless you know what you're doing.\n\n    Returns\n    -------\n    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        The predicted classes, or the predict values.\n    \"\"\"\n    check_is_fitted(self)\n    X = self._validate_X_predict(X, check_input)\n    proba = self.tree_.predict(X)\n    n_samples = X.shape[0]\n\n    # Classification\n    if is_classifier(self):\n        if self.n_outputs_ == 1:\n            return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n\n        else:\n            class_type = self.classes_[0].dtype\n            predictions = np.zeros((n_samples, self.n_outputs_), dtype=class_type)\n            for k in range(self.n_outputs_):\n                predictions[:, k] = self.classes_[k].take(\n                    np.argmax(proba[:, k], axis=1), axis=0\n                )\n\n            return predictions\n\n    # Regression\n    else:\n        if self.n_outputs_ == 1:\n            return proba[:, 0]\n\n        else:\n            return proba[:, :, 0]",
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant",
    "scikit-learn.sklearn.utils._array_api._convert_to_numpy": "def _convert_to_numpy(array, xp):\n    \"\"\"Convert X into a NumPy ndarray on the CPU.\"\"\"\n    if _is_xp_namespace(xp, \"torch\"):\n        return array.cpu().numpy()\n    elif _is_xp_namespace(xp, \"cupy\"):  # pragma: nocover\n        return array.get()\n    elif _is_xp_namespace(xp, \"array_api_strict\"):\n        return numpy.asarray(xp.asarray(array, device=xp.Device(\"CPU_DEVICE\")))\n\n    return numpy.asarray(array)",
    "scikit-learn.sklearn.utils._available_if.__get__": "def __get__(self, obj, owner=None):\n    if obj is not None:\n        # delegate only on instances, not the classes.\n        # this is to allow access to the docstrings.\n        self._check(obj, owner=owner)\n        out = MethodType(self.fn, obj)\n\n    else:\n        # This makes it possible to use the decorated method as an unbound method,\n        # for instance when monkeypatching.\n        @wraps(self.fn)\n        def out(*args, **kwargs):\n            self._check(args[0], owner=owner)\n            return self.fn(*args, **kwargs)\n\n    return out",
    "scikit-learn.sklearn.utils._mocking.fit": "def fit(self, X, y, sample_weight=None, **fit_params):\n    \"\"\"Fit classifier.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Training vector, where `n_samples` is the number of samples and\n        `n_features` is the number of features.\n\n    y : array-like of shape (n_samples, n_outputs) or (n_samples,), \\\n            default=None\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Sample weights. If None, then samples are equally weighted.\n\n    **fit_params : dict of string -> object\n        Parameters passed to the ``fit`` method of the estimator\n\n    Returns\n    -------\n    self\n    \"\"\"\n    assert _num_samples(X) == _num_samples(y)\n    if self.methods_to_check == \"all\" or \"fit\" in self.methods_to_check:\n        X, y = self._check_X_y(X, y, should_be_fitted=False)\n    self.n_features_in_ = np.shape(X)[1]\n    self.classes_ = np.unique(check_array(y, ensure_2d=False, allow_nd=True))\n    if self.expected_fit_params:\n        missing = set(self.expected_fit_params) - set(fit_params)\n        if missing:\n            raise AssertionError(\n                f\"Expected fit parameter(s) {list(missing)} not seen.\"\n            )\n        for key, value in fit_params.items():\n            if _num_samples(value) != _num_samples(X):\n                raise AssertionError(\n                    f\"Fit parameter {key} has length {_num_samples(value)}\"\n                    f\"; expected {_num_samples(X)}.\"\n                )\n    if self.expected_sample_weight:\n        if sample_weight is None:\n            raise AssertionError(\"Expected sample_weight to be passed\")\n        _check_sample_weight(sample_weight, X)\n\n    return self",
    "scikit-learn.sklearn.utils._mocking.predict": "def predict(self, X):\n    \"\"\"Predict the first class seen in `classes_`.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        The input data.\n\n    Returns\n    -------\n    preds : ndarray of shape (n_samples,)\n        Predictions of the first class seen in `classes_`.\n    \"\"\"\n    if self.methods_to_check == \"all\" or \"predict\" in self.methods_to_check:\n        X, y = self._check_X_y(X)\n    rng = check_random_state(self.random_state)\n    return rng.choice(self.classes_, size=_num_samples(X))",
    "scikit-learn.sklearn.utils._mocking.predict_proba": "def predict_proba(self, X):\n    \"\"\"Predict probabilities for each class.\n\n    Here, the dummy classifier will provide a probability of 1 for the\n    first class of `classes_` and 0 otherwise.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        The input data.\n\n    Returns\n    -------\n    proba : ndarray of shape (n_samples, n_classes)\n        The probabilities for each sample and class.\n    \"\"\"\n    if self.methods_to_check == \"all\" or \"predict_proba\" in self.methods_to_check:\n        X, y = self._check_X_y(X)\n    rng = check_random_state(self.random_state)\n    proba = rng.randn(_num_samples(X), len(self.classes_))\n    proba = np.abs(proba, out=proba)\n    proba /= np.sum(proba, axis=1)[:, np.newaxis]\n    return proba",
    "scikit-learn.sklearn.utils.metaestimators._safe_split": "def _safe_split(estimator, X, y, indices, train_indices=None):\n    \"\"\"Create subset of dataset and properly handle kernels.\n\n    Slice X, y according to indices for cross-validation, but take care of\n    precomputed kernel-matrices or pairwise affinities / distances.\n\n    If ``estimator._pairwise is True``, X needs to be square and\n    we slice rows and columns. If ``train_indices`` is not None,\n    we slice rows using ``indices`` (assumed the test set) and columns\n    using ``train_indices``, indicating the training set.\n\n    Labels y will always be indexed only along the first axis.\n\n    Parameters\n    ----------\n    estimator : object\n        Estimator to determine whether we should slice only rows or rows and\n        columns.\n\n    X : array-like, sparse matrix or iterable\n        Data to be indexed. If ``estimator._pairwise is True``,\n        this needs to be a square array-like or sparse matrix.\n\n    y : array-like, sparse matrix or iterable\n        Targets to be indexed.\n\n    indices : array of int\n        Rows to select from X and y.\n        If ``estimator._pairwise is True`` and ``train_indices is None``\n        then ``indices`` will also be used to slice columns.\n\n    train_indices : array of int or None, default=None\n        If ``estimator._pairwise is True`` and ``train_indices is not None``,\n        then ``train_indices`` will be use to slice the columns of X.\n\n    Returns\n    -------\n    X_subset : array-like, sparse matrix or list\n        Indexed data.\n\n    y_subset : array-like, sparse matrix or list\n        Indexed targets.\n\n    \"\"\"\n    if get_tags(estimator).input_tags.pairwise:\n        if not hasattr(X, \"shape\"):\n            raise ValueError(\n                \"Precomputed kernels or affinity matrices have \"\n                \"to be passed as arrays or sparse matrices.\"\n            )\n        # X is a precomputed square kernel matrix\n        if X.shape[0] != X.shape[1]:\n            raise ValueError(\"X should be a square kernel matrix\")\n        if train_indices is None:\n            X_subset = X[np.ix_(indices, indices)]\n        else:\n            X_subset = X[np.ix_(indices, train_indices)]\n    else:\n        X_subset = _safe_indexing(X, indices)\n\n    if y is not None:\n        y_subset = _safe_indexing(y, indices)\n    else:\n        y_subset = None\n\n    return X_subset, y_subset",
    "scikit-learn.sklearn.utils.validation._check_method_params": "def _check_method_params(X, params, indices=None):\n    \"\"\"Check and validate the parameters passed to a specific\n    method like `fit`.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        Data array.\n\n    params : dict\n        Dictionary containing the parameters passed to the method.\n\n    indices : array-like of shape (n_samples,), default=None\n        Indices to be selected if the parameter has the same size as `X`.\n\n    Returns\n    -------\n    method_params_validated : dict\n        Validated parameters. We ensure that the values support indexing.\n    \"\"\"\n    from sklearn.utils import _safe_indexing\n\n    method_params_validated = {}\n    for param_key, param_value in params.items():\n        if (\n            not _is_arraylike(param_value) and not sp.issparse(param_value)\n        ) or _num_samples(param_value) != _num_samples(X):\n            # Non-indexable pass-through (for now for backward-compatibility).\n            # https://github.com/scikit-learn/scikit-learn/issues/15805\n            method_params_validated[param_key] = param_value\n        else:\n            # Any other method_params should support indexing\n            # (e.g. for cross-validation).\n            method_params_validated[param_key] = _make_indexable(param_value)\n            method_params_validated[param_key] = _safe_indexing(\n                method_params_validated[param_key], indices\n            )\n\n    return method_params_validated"
}