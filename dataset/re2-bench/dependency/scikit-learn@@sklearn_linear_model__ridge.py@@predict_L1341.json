{
    "scikit-learn.sklearn.externals.array_api_compat.numpy._aliases.astype": "def astype(\n    x: Array,\n    dtype: DType,\n    /,\n    *,\n    copy: py_bool = True,\n    device: Device | None = None,\n) -> Array:\n    _helpers._check_device(np, device)\n    return x.astype(dtype=dtype, copy=copy)",
    "scikit-learn.sklearn.linear_model._base.decision_function": "def decision_function(self, X):\n    \"\"\"\n    Predict confidence scores for samples.\n\n    The confidence score for a sample is proportional to the signed\n    distance of that sample to the hyperplane.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix for which we want to get the confidence scores.\n\n    Returns\n    -------\n    scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n        Confidence scores per `(n_samples, n_classes)` combination. In the\n        binary case, confidence score for `self.classes_[1]` where >0 means\n        this class would be predicted.\n    \"\"\"\n    check_is_fitted(self)\n    xp, _ = get_namespace(X)\n\n    X = validate_data(self, X, accept_sparse=\"csr\", reset=False)\n    coef_T = self.coef_.T if self.coef_.ndim == 2 else self.coef_\n    scores = safe_sparse_dot(X, coef_T, dense_output=True) + self.intercept_\n    return (\n        xp.reshape(scores, (-1,))\n        if (scores.ndim > 1 and scores.shape[1] == 1)\n        else scores\n    )",
    "scikit-learn.sklearn.linear_model._base.predict": "def predict(self, X):\n    \"\"\"\n    Predict class labels for samples in X.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix for which we want to get the predictions.\n\n    Returns\n    -------\n    y_pred : ndarray of shape (n_samples,)\n        Vector containing the class labels for each sample.\n    \"\"\"\n    xp, _ = get_namespace(X)\n    scores = self.decision_function(X)\n    if len(scores.shape) == 1:\n        indices = xp.astype(scores > 0, indexing_dtype(xp))\n    else:\n        indices = xp.argmax(scores, axis=1)\n\n    return xp.take(self.classes_, indices, axis=0)",
    "scikit-learn.sklearn.preprocessing._label.inverse_transform": "def inverse_transform(self, Y, threshold=None):\n    \"\"\"Transform binary labels back to multi-class labels.\n\n    Parameters\n    ----------\n    Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n        Target values. All sparse matrices are converted to CSR before\n        inverse transformation.\n\n    threshold : float, default=None\n        Threshold used in the binary and multi-label cases.\n\n        Use 0 when ``Y`` contains the output of :term:`decision_function`\n        (classifier).\n        Use 0.5 when ``Y`` contains the output of :term:`predict_proba`.\n\n        If None, the threshold is assumed to be half way between\n        neg_label and pos_label.\n\n    Returns\n    -------\n    y_original : {ndarray, sparse matrix} of shape (n_samples,)\n        Target values. Sparse matrix will be of CSR format.\n\n    Notes\n    -----\n    In the case when the binary labels are fractional\n    (probabilistic), :meth:`inverse_transform` chooses the class with the\n    greatest value. Typically, this allows to use the output of a\n    linear model's :term:`decision_function` method directly as the input\n    of :meth:`inverse_transform`.\n    \"\"\"\n    check_is_fitted(self)\n\n    xp, is_array_api = get_namespace(Y)\n\n    if is_array_api and self.sparse_input_ and not _is_numpy_namespace(xp):\n        raise ValueError(\n            \"`LabelBinarizer` was fitted on a sparse matrix, and therefore cannot \"\n            f\"inverse transform a {xp.__name__} array back to a sparse matrix.\"\n        )\n\n    if threshold is None:\n        threshold = (self.pos_label + self.neg_label) / 2.0\n\n    if self.y_type_ == \"multiclass\":\n        y_inv = _inverse_binarize_multiclass(Y, self.classes_, xp=xp)\n    else:\n        y_inv = _inverse_binarize_thresholding(\n            Y, self.y_type_, self.classes_, threshold, xp=xp\n        )\n\n    if self.sparse_input_:\n        y_inv = sp.csr_matrix(y_inv)\n    elif sp.issparse(y_inv):\n        y_inv = y_inv.toarray()\n\n    return y_inv",
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant",
    "scikit-learn.sklearn.utils.validation.check_is_fitted": "def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n    \"\"\"Perform is_fitted validation for estimator.\n\n    Checks if the estimator is fitted by verifying the presence of\n    fitted attributes (ending with a trailing underscore) and otherwise\n    raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this function will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.\n\n    Raises\n    ------\n    TypeError\n        If the estimator is a class or not an estimator instance\n\n    NotFittedError\n        If the attributes are not found.\n\n    Examples\n    --------\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.utils.validation import check_is_fitted\n    >>> from sklearn.exceptions import NotFittedError\n    >>> lr = LogisticRegression()\n    >>> try:\n    ...     check_is_fitted(lr)\n    ... except NotFittedError as exc:\n    ...     print(f\"Model is not fitted yet.\")\n    Model is not fitted yet.\n    >>> lr.fit([[1, 2], [1, 3]], [1, 0])\n    LogisticRegression()\n    >>> check_is_fitted(lr)\n    \"\"\"\n    if isclass(estimator):\n        raise TypeError(\"{} is a class, not an instance.\".format(estimator))\n    if msg is None:\n        msg = (\n            \"This %(name)s instance is not fitted yet. Call 'fit' with \"\n            \"appropriate arguments before using this estimator.\"\n        )\n\n    if not hasattr(estimator, \"fit\"):\n        raise TypeError(\"%s is not an estimator instance.\" % (estimator))\n\n    tags = get_tags(estimator)\n\n    if not tags.requires_fit and attributes is None:\n        return\n\n    if not _is_fitted(estimator, attributes, all_or_any):\n        raise NotFittedError(msg % {\"name\": type(estimator).__name__})"
}