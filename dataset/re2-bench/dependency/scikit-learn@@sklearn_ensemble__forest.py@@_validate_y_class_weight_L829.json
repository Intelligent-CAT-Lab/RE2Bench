{
    "scikit-learn.sklearn.utils._param_validation.wrapper": "@functools.wraps(func)\ndef wrapper(*args, **kwargs):\n    global_skip_validation = get_config()[\"skip_parameter_validation\"]\n    if global_skip_validation:\n        return func(*args, **kwargs)\n\n    func_sig = signature(func)\n\n    # Map *args/**kwargs to the function signature\n    params = func_sig.bind(*args, **kwargs)\n    params.apply_defaults()\n\n    # ignore self/cls and positional/keyword markers\n    to_ignore = [\n        p.name\n        for p in func_sig.parameters.values()\n        if p.kind in (p.VAR_POSITIONAL, p.VAR_KEYWORD)\n    ]\n    to_ignore += [\"self\", \"cls\"]\n    params = {k: v for k, v in params.arguments.items() if k not in to_ignore}\n\n    validate_parameter_constraints(\n        parameter_constraints, params, caller_name=func.__qualname__\n    )\n\n    try:\n        with config_context(\n            skip_parameter_validation=(\n                prefer_skip_nested_validation or global_skip_validation\n            )\n        ):\n            return func(*args, **kwargs)\n    except InvalidParameterError as e:\n        # When the function is just a wrapper around an estimator, we allow\n        # the function to delegate validation to the estimator, but we replace\n        # the name of the estimator by the name of the function in the error\n        # message to avoid confusion.\n        msg = re.sub(\n            r\"parameter of \\w+ must be\",\n            f\"parameter of {func.__qualname__} must be\",\n            str(e),\n        )\n        raise InvalidParameterError(msg) from e",
    "scikit-learn.sklearn.utils.multiclass.check_classification_targets": "def check_classification_targets(y):\n    \"\"\"Ensure that target y is of a non-regression type.\n\n    Only the following target types (as defined in type_of_target) are allowed:\n        'binary', 'multiclass', 'multiclass-multioutput',\n        'multilabel-indicator', 'multilabel-sequences'\n\n    Parameters\n    ----------\n    y : array-like\n        Target values.\n    \"\"\"\n    y_type = type_of_target(y, input_name=\"y\")\n    if y_type not in [\n        \"binary\",\n        \"multiclass\",\n        \"multiclass-multioutput\",\n        \"multilabel-indicator\",\n        \"multilabel-sequences\",\n    ]:\n        raise ValueError(\n            f\"Unknown label type: {y_type}. Maybe you are trying to fit a \"\n            \"classifier, which expects discrete classes on a \"\n            \"regression target with continuous values.\"\n        )\n\n    if \"multiclass\" in y_type:\n        n_samples = _num_samples(y)\n        if n_samples > 20 and cached_unique(y).shape[0] > round(0.5 * n_samples):\n            # Only raise the warning when we have at least 20 samples.\n            warnings.warn(\n                \"The number of unique classes is greater than 50% of the number \"\n                \"of samples. `y` could represent a regression problem, not a \"\n                \"classification problem.\",\n                UserWarning,\n                stacklevel=2,\n            )"
}