{
    "scikit-learn.sklearn.model_selection._search._store": "def _store(key_name, array, weights=None, splits=False, rank=False):\n    \"\"\"A small helper to store the scores/times to the cv_results_\"\"\"\n    # When iterated first by splits, then by parameters\n    # We want `array` to have `n_candidates` rows and `n_splits` cols.\n    array = np.array(array, dtype=np.float64).reshape(n_candidates, n_splits)\n    if splits:\n        for split_idx in range(n_splits):\n            # Uses closure to alter the results\n            results[\"split%d_%s\" % (split_idx, key_name)] = array[:, split_idx]\n\n    array_means = np.average(array, axis=1, weights=weights)\n    results[\"mean_%s\" % key_name] = array_means\n\n    if key_name.startswith((\"train_\", \"test_\")) and np.any(\n        ~np.isfinite(array_means)\n    ):\n        warnings.warn(\n            (\n                f\"One or more of the {key_name.split('_')[0]} scores \"\n                f\"are non-finite: {array_means}\"\n            ),\n            category=UserWarning,\n        )\n\n    # Weighted std is not directly available in numpy\n    array_stds = np.sqrt(\n        np.average(\n            (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n        )\n    )\n    results[\"std_%s\" % key_name] = array_stds\n\n    if rank:\n        # When the fit/scoring fails `array_means` contains NaNs, we\n        # will exclude them from the ranking process and consider them\n        # as tied with the worst performers.\n        if np.isnan(array_means).all():\n            # All fit/scoring routines failed.\n            rank_result = np.ones_like(array_means, dtype=np.int32)\n        else:\n            min_array_means = np.nanmin(array_means) - 1\n            array_means = xpx.nan_to_num(\n                array_means, fill_value=min_array_means\n            )\n            rank_result = rankdata(-array_means, method=\"min\").astype(\n                np.int32, copy=False\n            )\n        results[\"rank_%s\" % key_name] = rank_result",
    "scikit-learn.sklearn.model_selection._search._yield_masked_array_for_each_param": "def _yield_masked_array_for_each_param(candidate_params):\n    \"\"\"\n    Yield a masked array for each candidate param.\n\n    `candidate_params` is a sequence of params which were used in\n    a `GridSearchCV`. We use masked arrays for the results, as not\n    all params are necessarily present in each element of\n    `candidate_params`. For example, if using `GridSearchCV` with\n    a `SVC` model, then one might search over params like:\n\n        - kernel=[\"rbf\"], gamma=[0.1, 1]\n        - kernel=[\"poly\"], degree=[1, 2]\n\n    and then param `'gamma'` would not be present in entries of\n    `candidate_params` corresponding to `kernel='poly'`.\n    \"\"\"\n    n_candidates = len(candidate_params)\n    param_results = defaultdict(dict)\n\n    for cand_idx, params in enumerate(candidate_params):\n        for name, value in params.items():\n            param_results[\"param_%s\" % name][cand_idx] = value\n\n    for key, param_result in param_results.items():\n        param_list = list(param_result.values())\n        try:\n            arr = np.array(param_list)\n        except ValueError:\n            # This can happen when param_list contains lists of different\n            # lengths, for example:\n            # param_list=[[1], [2, 3]]\n            arr_dtype = np.dtype(object)\n        else:\n            # There are two cases when we don't use the automatically inferred\n            # dtype when creating the array and we use object instead:\n            # - string dtype\n            # - when array.ndim > 1, that means that param_list was something\n            #   like a list of same-size sequences, which gets turned into a\n            #   multi-dimensional array but we want a 1d array\n            arr_dtype = arr.dtype if arr.dtype.kind != \"U\" and arr.ndim == 1 else object\n\n        # Use one MaskedArray and mask all the places where the param is not\n        # applicable for that candidate (which may not contain all the params).\n        ma = MaskedArray(np.empty(n_candidates, dtype=arr_dtype), mask=True)\n        for index, value in param_result.items():\n            # Setting the value at an index unmasks that index\n            ma[index] = value\n        yield (key, ma)",
    "scikit-learn.sklearn.model_selection._validation._aggregate_score_dicts": "def _aggregate_score_dicts(scores):\n    \"\"\"Aggregate the list of dict to dict of np ndarray\n\n    The aggregated output of _aggregate_score_dicts will be a list of dict\n    of form [{'prec': 0.1, 'acc':1.0}, {'prec': 0.1, 'acc':1.0}, ...]\n    Convert it to a dict of array {'prec': np.array([0.1 ...]), ...}\n\n    Parameters\n    ----------\n\n    scores : list of dict\n        List of dicts of the scores for all scorers. This is a flat list,\n        assumed originally to be of row major order.\n\n    Example\n    -------\n\n    >>> scores = [{'a': 1, 'b':10}, {'a': 2, 'b':2}, {'a': 3, 'b':3},\n    ...           {'a': 10, 'b': 10}]                         # doctest: +SKIP\n    >>> _aggregate_score_dicts(scores)                        # doctest: +SKIP\n    {'a': array([1, 2, 3, 10]),\n     'b': array([10, 2, 3, 10])}\n    \"\"\"\n    return {\n        key: (\n            np.asarray([score[key] for score in scores])\n            if isinstance(scores[0][key], numbers.Number)\n            else [score[key] for score in scores]\n        )\n        for key in scores[0]\n    }",
    "scikit-learn.sklearn.model_selection._validation._normalize_score_results": "def _normalize_score_results(scores, scaler_score_key=\"score\"):\n    \"\"\"Creates a scoring dictionary based on the type of `scores`\"\"\"\n    if isinstance(scores[0], dict):\n        # multimetric scoring\n        return _aggregate_score_dicts(scores)\n    # scaler\n    return {scaler_score_key: scores}"
}