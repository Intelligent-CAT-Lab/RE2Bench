{
    "scikit-learn.sklearn.impute._base._get_missing_features_info": "def _get_missing_features_info(self, X):\n    \"\"\"Compute the imputer mask and the indices of the features\n    containing missing values.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The input data with missing values. Note that `X` has been\n        checked in :meth:`fit` and :meth:`transform` before to call this\n        function.\n\n    Returns\n    -------\n    imputer_mask : {ndarray, sparse matrix} of shape \\\n    (n_samples, n_features)\n        The imputer mask of the original data.\n\n    features_with_missing : ndarray of shape (n_features_with_missing)\n        The features containing missing values.\n    \"\"\"\n    if not self._precomputed:\n        imputer_mask = _get_mask(X, self.missing_values)\n    else:\n        imputer_mask = X\n\n    if sp.issparse(X):\n        imputer_mask.eliminate_zeros()\n\n        if self.features == \"missing-only\":\n            # count number of True values in each row.\n            n_missing = imputer_mask.sum(axis=0)\n\n        if self.sparse is False:\n            imputer_mask = imputer_mask.toarray()\n        elif imputer_mask.format == \"csr\":\n            imputer_mask = imputer_mask.tocsc()\n    else:\n        if not self._precomputed:\n            imputer_mask = _get_mask(X, self.missing_values)\n        else:\n            imputer_mask = X\n\n        if self.features == \"missing-only\":\n            n_missing = imputer_mask.sum(axis=0)\n\n        if self.sparse is True:\n            imputer_mask = sp.csc_matrix(imputer_mask)\n\n    if self.features == \"all\":\n        features_indices = np.arange(X.shape[1])\n    else:\n        features_indices = np.flatnonzero(n_missing)\n\n    return imputer_mask, features_indices",
    "scikit-learn.sklearn.impute._base._validate_input": "def _validate_input(self, X, in_fit):\n    if not is_scalar_nan(self.missing_values):\n        ensure_all_finite = True\n    else:\n        ensure_all_finite = \"allow-nan\"\n    X = validate_data(\n        self,\n        X,\n        reset=in_fit,\n        accept_sparse=(\"csc\", \"csr\"),\n        dtype=None,\n        ensure_all_finite=ensure_all_finite,\n    )\n    _check_inputs_dtype(X, self.missing_values)\n    if X.dtype.kind not in (\"i\", \"u\", \"f\", \"O\"):\n        raise ValueError(\n            \"MissingIndicator does not support data with \"\n            \"dtype {0}. Please provide either a numeric array\"\n            \" (with a floating point or integer dtype) or \"\n            \"categorical data represented either as an array \"\n            \"with integer dtype or an array of string values \"\n            \"with an object dtype.\".format(X.dtype)\n        )\n\n    if sp.issparse(X) and self.missing_values == 0:\n        # missing_values = 0 not allowed with sparse data as it would\n        # force densification\n        raise ValueError(\n            \"Sparse input with missing_values=0 is \"\n            \"not supported. Provide a dense \"\n            \"array instead.\"\n        )\n\n    return X",
    "scikit-learn.sklearn.utils.validation._check_n_features": "def _check_n_features(estimator, X, reset):\n    \"\"\"Set the `n_features_in_` attribute, or check against it on an estimator.\n\n    .. note::\n        To only check n_features without conducting a full data validation, prefer\n        using `validate_data(..., skip_check_array=True)` if possible.\n\n    .. versionchanged:: 1.6\n        Moved from :class:`~sklearn.base.BaseEstimator` to\n        :mod:`~sklearn.utils.validation`.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        The estimator to validate the input for.\n\n    X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The input samples.\n\n    reset : bool\n        Whether to reset the `n_features_in_` attribute.\n        If True, the `n_features_in_` attribute is set to `X.shape[1]`.\n        If False and the attribute exists, then check that it is equal to\n        `X.shape[1]`. If False and the attribute does *not* exist, then\n        the check is skipped.\n\n        .. note::\n           It is recommended to call `reset=True` in `fit` and in the first\n           call to `partial_fit`. All other methods that validate `X`\n           should set `reset=False`.\n    \"\"\"\n    try:\n        n_features = _num_features(X)\n    except TypeError as e:\n        if not reset and hasattr(estimator, \"n_features_in_\"):\n            raise ValueError(\n                \"X does not contain any features, but \"\n                f\"{estimator.__class__.__name__} is expecting \"\n                f\"{estimator.n_features_in_} features\"\n            ) from e\n        # If the number of features is not defined and reset=True,\n        # then we skip this check\n        return\n\n    if reset:\n        estimator.n_features_in_ = n_features\n        return\n\n    if not hasattr(estimator, \"n_features_in_\"):\n        # Skip this check if the expected number of expected input features\n        # was not recorded by calling fit first. This is typically the case\n        # for stateless transformers.\n        return\n\n    if n_features != estimator.n_features_in_:\n        raise ValueError(\n            f\"X has {n_features} features, but {estimator.__class__.__name__} \"\n            f\"is expecting {estimator.n_features_in_} features as input.\"\n        )"
}