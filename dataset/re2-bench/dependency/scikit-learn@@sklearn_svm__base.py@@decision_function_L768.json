{
    "scikit-learn.sklearn.svm._base._decision_function": "def _decision_function(self, X):\n    \"\"\"Evaluates the decision function for the samples in X.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n\n    Returns\n    -------\n    X : array-like of shape (n_samples, n_class * (n_class-1) / 2)\n        Returns the decision function of the sample for each class\n        in the model.\n    \"\"\"\n    # NOTE: _validate_for_predict contains check for is_fitted\n    # hence must be placed before any other attributes are used.\n    X = self._validate_for_predict(X)\n    X = self._compute_kernel(X)\n\n    if self._sparse:\n        dec_func = self._sparse_decision_function(X)\n    else:\n        dec_func = self._dense_decision_function(X)\n\n    # In binary case, we need to flip the sign of coef, intercept and\n    # decision function.\n    if self._impl in [\"c_svc\", \"nu_svc\"] and len(self.classes_) == 2:\n        return -dec_func.ravel()\n\n    return dec_func",
    "scikit-learn.sklearn.utils.multiclass._ovr_decision_function": "def _ovr_decision_function(predictions, confidences, n_classes):\n    \"\"\"Compute a continuous, tie-breaking OvR decision function from OvO.\n\n    It is important to include a continuous value, not only votes,\n    to make computing AUC or calibration meaningful.\n\n    Parameters\n    ----------\n    predictions : array-like of shape (n_samples, n_classifiers)\n        Predicted classes for each binary classifier.\n\n    confidences : array-like of shape (n_samples, n_classifiers)\n        Decision functions or predicted probabilities for positive class\n        for each binary classifier.\n\n    n_classes : int\n        Number of classes. n_classifiers must be\n        ``n_classes * (n_classes - 1 ) / 2``.\n    \"\"\"\n    n_samples = predictions.shape[0]\n    votes = np.zeros((n_samples, n_classes))\n    sum_of_confidences = np.zeros((n_samples, n_classes))\n\n    k = 0\n    for i in range(n_classes):\n        for j in range(i + 1, n_classes):\n            sum_of_confidences[:, i] -= confidences[:, k]\n            sum_of_confidences[:, j] += confidences[:, k]\n            votes[predictions[:, k] == 0, i] += 1\n            votes[predictions[:, k] == 1, j] += 1\n            k += 1\n\n    # Monotonically transform the sum_of_confidences to (-1/3, 1/3)\n    # and add it with votes. The monotonic transformation  is\n    # f: x -> x / (3 * (|x| + 1)), it uses 1/3 instead of 1/2\n    # to ensure that we won't reach the limits and change vote order.\n    # The motivation is to use confidence levels as a way to break ties in\n    # the votes without switching any decision made based on a difference\n    # of 1 vote.\n    transformed_confidences = sum_of_confidences / (\n        3 * (np.abs(sum_of_confidences) + 1)\n    )\n    return votes + transformed_confidences"
}