{
    "scikit-learn.sklearn.utils.extmath._randomized_svd": "def _randomized_svd(\n    M,\n    n_components,\n    *,\n    n_oversamples=10,\n    n_iter=\"auto\",\n    power_iteration_normalizer=\"auto\",\n    transpose=\"auto\",\n    flip_sign=True,\n    random_state=None,\n    svd_lapack_driver=\"gesdd\",\n):\n    \"\"\"Body of randomized_svd without input validation.\"\"\"\n    xp, is_array_api_compliant = get_namespace(M)\n\n    if sparse.issparse(M) and M.format in (\"lil\", \"dok\"):\n        warnings.warn(\n            \"Calculating SVD of a {} is expensive. \"\n            \"csr_matrix is more efficient.\".format(type(M).__name__),\n            sparse.SparseEfficiencyWarning,\n        )\n\n    random_state = check_random_state(random_state)\n    n_random = n_components + n_oversamples\n    n_samples, n_features = M.shape\n\n    if n_iter == \"auto\":\n        # Checks if the number of iterations is explicitly specified\n        # Adjust n_iter. 7 was found a good compromise for PCA. See #5299\n        n_iter = 7 if n_components < 0.1 * min(M.shape) else 4\n\n    if transpose == \"auto\":\n        transpose = n_samples < n_features\n    if transpose:\n        # this implementation is a bit faster with smaller shape[1]\n        M = M.T\n\n    Q = _randomized_range_finder(\n        M,\n        size=n_random,\n        n_iter=n_iter,\n        power_iteration_normalizer=power_iteration_normalizer,\n        random_state=random_state,\n    )\n\n    # project M to the (k + p) dimensional space using the basis vectors\n    B = Q.T @ M\n\n    # compute the SVD on the thin matrix: (k + p) wide\n    if is_array_api_compliant:\n        Uhat, s, Vt = xp.linalg.svd(B, full_matrices=False)\n    else:\n        # When array_api_dispatch is disabled, rely on scipy.linalg\n        # instead of numpy.linalg to avoid introducing a behavior change w.r.t.\n        # previous versions of scikit-learn.\n        Uhat, s, Vt = linalg.svd(\n            B, full_matrices=False, lapack_driver=svd_lapack_driver\n        )\n    del B\n    U = Q @ Uhat\n\n    if flip_sign:\n        if not transpose:\n            U, Vt = svd_flip(U, Vt)\n        else:\n            # In case of transpose u_based_decision=false\n            # to actually flip based on u and not v.\n            U, Vt = svd_flip(U, Vt, u_based_decision=False)\n\n    if transpose:\n        # transpose back the results according to the input convention\n        return Vt[:n_components, :].T, s[:n_components], U[:, :n_components].T\n    else:\n        return U[:, :n_components], s[:n_components], Vt[:n_components, :]",
    "scikit-learn.sklearn.utils.validation.assert_all_finite": "def assert_all_finite(\n    X,\n    *,\n    allow_nan=False,\n    estimator_name=None,\n    input_name=\"\",\n):\n    \"\"\"Throw a ValueError if X contains NaN or infinity.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix}\n        The input data.\n\n    allow_nan : bool, default=False\n        If True, do not throw error when `X` contains NaN.\n\n    estimator_name : str, default=None\n        The estimator name, used to construct the error message.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n\n    Examples\n    --------\n    >>> from sklearn.utils import assert_all_finite\n    >>> import numpy as np\n    >>> array = np.array([1, np.inf, np.nan, 4])\n    >>> try:\n    ...     assert_all_finite(array)\n    ...     print(\"Test passed: Array contains only finite values.\")\n    ... except ValueError:\n    ...     print(\"Test failed: Array contains non-finite values.\")\n    Test failed: Array contains non-finite values.\n    \"\"\"\n    _assert_all_finite(\n        X.data if sp.issparse(X) else X,\n        allow_nan=allow_nan,\n        estimator_name=estimator_name,\n        input_name=input_name,\n    )"
}