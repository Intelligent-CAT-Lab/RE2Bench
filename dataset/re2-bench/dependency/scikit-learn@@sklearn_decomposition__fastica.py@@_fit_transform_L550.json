{
    "scikit-learn.sklearn.decomposition._fastica._ica_par": "def _ica_par(X, tol, g, fun_args, max_iter, w_init):\n    \"\"\"Parallel FastICA.\n\n    Used internally by FastICA --main loop\n\n    \"\"\"\n    W = _sym_decorrelation(w_init)\n    del w_init\n    p_ = float(X.shape[1])\n    for ii in range(max_iter):\n        gwtx, g_wtx = g(np.dot(W, X), fun_args)\n        W1 = _sym_decorrelation(np.dot(gwtx, X.T) / p_ - g_wtx[:, np.newaxis] * W)\n        del gwtx, g_wtx\n        # builtin max, abs are faster than numpy counter parts.\n        # np.einsum allows having the lowest memory footprint.\n        # It is faster than np.diag(np.dot(W1, W.T)).\n        lim = max(abs(abs(np.einsum(\"ij,ij->i\", W1, W)) - 1))\n        W = W1\n        if lim < tol:\n            break\n    else:\n        warnings.warn(\n            (\n                \"FastICA did not converge. Consider increasing \"\n                \"tolerance or the maximum number of iterations.\"\n            ),\n            ConvergenceWarning,\n        )\n\n    return W, ii + 1",
    "scikit-learn.sklearn.decomposition._fastica._ica_def": "def _ica_def(X, tol, g, fun_args, max_iter, w_init):\n    \"\"\"Deflationary FastICA using fun approx to neg-entropy function\n\n    Used internally by FastICA.\n    \"\"\"\n\n    n_components = w_init.shape[0]\n    W = np.zeros((n_components, n_components), dtype=X.dtype)\n    n_iter = []\n\n    # j is the index of the extracted component\n    for j in range(n_components):\n        w = w_init[j, :].copy()\n        w /= np.sqrt((w**2).sum())\n\n        for i in range(max_iter):\n            gwtx, g_wtx = g(np.dot(w.T, X), fun_args)\n\n            w1 = (X * gwtx).mean(axis=1) - g_wtx.mean() * w\n\n            _gs_decorrelation(w1, W, j)\n\n            w1 /= np.sqrt((w1**2).sum())\n\n            lim = np.abs(np.abs((w1 * w).sum()) - 1)\n            w = w1\n            if lim < tol:\n                break\n\n        n_iter.append(i + 1)\n        W[j, :] = w\n\n    return W, max(n_iter)",
    "scikit-learn.sklearn.utils.validation.check_random_state": "def check_random_state(seed):\n    \"\"\"Turn seed into an np.random.RandomState instance.\n\n    Parameters\n    ----------\n    seed : None, int or instance of RandomState\n        If seed is None, return the RandomState singleton used by np.random.\n        If seed is an int, return a new RandomState instance seeded with seed.\n        If seed is already a RandomState instance, return it.\n        Otherwise raise ValueError.\n\n    Returns\n    -------\n    :class:`numpy:numpy.random.RandomState`\n        The random state object based on `seed` parameter.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_random_state\n    >>> check_random_state(42)\n    RandomState(MT19937) at 0x...\n    \"\"\"\n    if seed is None or seed is np.random:\n        return np.random.mtrand._rand\n    if isinstance(seed, numbers.Integral):\n        return np.random.RandomState(seed)\n    if isinstance(seed, np.random.RandomState):\n        return seed\n    raise ValueError(\n        \"%r cannot be used to seed a numpy.random.RandomState instance\" % seed\n    )",
    "scikit-learn.sklearn.utils.validation.as_float_array": "def as_float_array(X, *, copy=True, ensure_all_finite=True):\n    \"\"\"Convert an array-like to an array of floats.\n\n    The new dtype will be np.float32 or np.float64, depending on the original\n    type. The function can create a copy or modify the argument depending\n    on the argument copy.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}\n        The input data.\n\n    copy : bool, default=True\n        If True, a copy of X will be created. If False, a copy may still be\n        returned if X's dtype is not a floating point type.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in X. The\n        possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan and pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    Returns\n    -------\n    XT : {ndarray, sparse matrix}\n        An array of type float.\n\n    Examples\n    --------\n    >>> from sklearn.utils import as_float_array\n    >>> import numpy as np\n    >>> array = np.array([0, 0, 1, 2, 2], dtype=np.int64)\n    >>> as_float_array(array)\n    array([0., 0., 1., 2., 2.])\n    \"\"\"\n    if isinstance(X, np.matrix) or (\n        not isinstance(X, np.ndarray) and not sp.issparse(X)\n    ):\n        return check_array(\n            X,\n            accept_sparse=[\"csr\", \"csc\", \"coo\"],\n            dtype=np.float64,\n            copy=copy,\n            ensure_all_finite=ensure_all_finite,\n            ensure_2d=False,\n        )\n    elif sp.issparse(X) and X.dtype in [np.float32, np.float64]:\n        return X.copy() if copy else X\n    elif X.dtype in [np.float32, np.float64]:  # is numpy array\n        return X.copy(\"F\" if X.flags[\"F_CONTIGUOUS\"] else \"C\") if copy else X\n    else:\n        if X.dtype.kind in \"uib\" and X.dtype.itemsize <= 4:\n            return_dtype = np.float32\n        else:\n            return_dtype = np.float64\n        return X.astype(return_dtype)",
    "scikit-learn.sklearn.utils.validation.validate_data": "def validate_data(\n    _estimator,\n    /,\n    X=\"no_validation\",\n    y=\"no_validation\",\n    reset=True,\n    validate_separately=False,\n    skip_check_array=False,\n    **check_params,\n):\n    \"\"\"Validate input data and set or check feature names and counts of the input.\n\n    This helper function should be used in an estimator that requires input\n    validation. This mutates the estimator and sets the `n_features_in_` and\n    `feature_names_in_` attributes if `reset=True`.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    _estimator : estimator instance\n        The estimator to validate the input for.\n\n    X : {array-like, sparse matrix, dataframe} of shape \\\n            (n_samples, n_features), default='no validation'\n        The input samples.\n        If `'no_validation'`, no validation is performed on `X`. This is\n        useful for meta-estimator which can delegate input validation to\n        their underlying estimator(s). In that case `y` must be passed and\n        the only accepted `check_params` are `multi_output` and\n        `y_numeric`.\n\n    y : array-like of shape (n_samples,), default='no_validation'\n        The targets.\n\n        - If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If\n          the estimator's `requires_y` tag is True, then an error will be raised.\n        - If `'no_validation'`, :func:`~sklearn.utils.check_array` is called\n          on `X` and the estimator's `requires_y` tag is ignored. This is a default\n          placeholder and is never meant to be explicitly set. In that case `X` must be\n          passed.\n        - Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with\n          either :func:`~sklearn.utils.check_array` or\n          :func:`~sklearn.utils.check_X_y` depending on `validate_separately`.\n\n    reset : bool, default=True\n        Whether to reset the `n_features_in_` attribute.\n        If False, the input will be checked for consistency with data\n        provided when reset was last True.\n\n        .. note::\n\n           It is recommended to call `reset=True` in `fit` and in the first\n           call to `partial_fit`. All other methods that validate `X`\n           should set `reset=False`.\n\n    validate_separately : False or tuple of dicts, default=False\n        Only used if `y` is not `None`.\n        If `False`, call :func:`~sklearn.utils.check_X_y`. Else, it must be a tuple of\n        kwargs to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`\n        respectively.\n\n        `estimator=self` is automatically added to these dicts to generate\n        more informative error message in case of invalid input data.\n\n    skip_check_array : bool, default=False\n        If `True`, `X` and `y` are unchanged and only `feature_names_in_` and\n        `n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`\n        is called on `X` and `y`.\n\n    **check_params : kwargs\n        Parameters passed to :func:`~sklearn.utils.check_array` or\n        :func:`~sklearn.utils.check_X_y`. Ignored if validate_separately\n        is not False.\n\n        `estimator=self` is automatically added to these params to generate\n        more informative error message in case of invalid input data.\n\n    Returns\n    -------\n    out : {ndarray, sparse matrix} or tuple of these\n        The validated input. A tuple is returned if both `X` and `y` are\n        validated.\n    \"\"\"\n    _check_feature_names(_estimator, X, reset=reset)\n    tags = get_tags(_estimator)\n    if y is None and tags.target_tags.required:\n        raise ValueError(\n            f\"This {_estimator.__class__.__name__} estimator \"\n            \"requires y to be passed, but the target y is None.\"\n        )\n\n    no_val_X = isinstance(X, str) and X == \"no_validation\"\n    no_val_y = y is None or (isinstance(y, str) and y == \"no_validation\")\n\n    if no_val_X and no_val_y:\n        raise ValueError(\"Validation should be done on X, y or both.\")\n\n    default_check_params = {\"estimator\": _estimator}\n    check_params = {**default_check_params, **check_params}\n\n    if skip_check_array:\n        if not no_val_X and no_val_y:\n            out = X\n        elif no_val_X and not no_val_y:\n            out = y\n        else:\n            out = X, y\n    elif not no_val_X and no_val_y:\n        out = check_array(X, input_name=\"X\", **check_params)\n    elif no_val_X and not no_val_y:\n        out = _check_y(y, **check_params)\n    else:\n        if validate_separately:\n            # We need this because some estimators validate X and y\n            # separately, and in general, separately calling check_array()\n            # on X and y isn't equivalent to just calling check_X_y()\n            # :(\n            check_X_params, check_y_params = validate_separately\n            if \"estimator\" not in check_X_params:\n                check_X_params = {**default_check_params, **check_X_params}\n            X = check_array(X, input_name=\"X\", **check_X_params)\n            if \"estimator\" not in check_y_params:\n                check_y_params = {**default_check_params, **check_y_params}\n            y = check_array(y, input_name=\"y\", **check_y_params)\n        else:\n            X, y = check_X_y(X, y, **check_params)\n        out = X, y\n\n    if not no_val_X and check_params.get(\"ensure_2d\", True):\n        _check_n_features(_estimator, X, reset=reset)\n\n    return out"
}