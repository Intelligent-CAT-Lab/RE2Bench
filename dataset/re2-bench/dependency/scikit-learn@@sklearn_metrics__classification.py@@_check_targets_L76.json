{
    "scikit-learn.sklearn.utils._array_api._is_numpy_namespace": "def _is_numpy_namespace(xp):\n    \"\"\"Return True if xp is backed by NumPy.\"\"\"\n    return xp.__name__ in _NUMPY_NAMESPACE_NAMES",
    "scikit-learn.sklearn.utils._array_api._union1d": "def _union1d(a, b, xp):\n    if _is_numpy_namespace(xp):\n        # avoid circular import\n        from sklearn.utils._unique import cached_unique\n\n        a_unique, b_unique = cached_unique(a, b, xp=xp)\n        return xp.asarray(numpy.union1d(a_unique, b_unique))\n    assert a.ndim == b.ndim == 1\n    return xp.unique_values(xp.concat([xp.unique_values(a), xp.unique_values(b)]))",
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant",
    "scikit-learn.sklearn.utils.multiclass.type_of_target": "def type_of_target(y, input_name=\"\", raise_unknown=False):\n    \"\"\"Determine the type of data indicated by the target.\n\n    Note that this type is the most specific type that can be inferred.\n    For example:\n\n    * ``binary`` is more specific but compatible with ``multiclass``.\n    * ``multiclass`` of integers is more specific but compatible with ``continuous``.\n    * ``multilabel-indicator`` is more specific but compatible with\n      ``multiclass-multioutput``.\n\n    Parameters\n    ----------\n    y : {array-like, sparse matrix}\n        Target values. If a sparse matrix, `y` is expected to be a\n        CSR/CSC matrix.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message.\n\n        .. versionadded:: 1.1.0\n\n    raise_unknown : bool, default=False\n        If `True`, raise an error when the type of target returned by\n        :func:`~sklearn.utils.multiclass.type_of_target` is `\"unknown\"`.\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    target_type : str\n        One of:\n\n        * 'continuous': `y` is an array-like of floats that are not all\n          integers, and is 1d or a column vector.\n        * 'continuous-multioutput': `y` is a 2d array of floats that are\n          not all integers, and both dimensions are of size > 1.\n        * 'binary': `y` contains <= 2 discrete values and is 1d or a column\n          vector.\n        * 'multiclass': `y` contains more than two discrete values, is not a\n          sequence of sequences, and is 1d or a column vector.\n        * 'multiclass-multioutput': `y` is a 2d array that contains more\n          than two discrete values, is not a sequence of sequences, and both\n          dimensions are of size > 1.\n        * 'multilabel-indicator': `y` is a label indicator matrix, an array\n          of two dimensions with at least two columns, and at most 2 unique\n          values.\n        * 'unknown': `y` is array-like but none of the above, such as a 3d\n          array, sequence of sequences, or an array of non-sequence objects.\n\n    Examples\n    --------\n    >>> from sklearn.utils.multiclass import type_of_target\n    >>> import numpy as np\n    >>> type_of_target([0.1, 0.6])\n    'continuous'\n    >>> type_of_target([1, -1, -1, 1])\n    'binary'\n    >>> type_of_target(['a', 'b', 'a'])\n    'binary'\n    >>> type_of_target([1.0, 2.0])\n    'binary'\n    >>> type_of_target([1, 0, 2])\n    'multiclass'\n    >>> type_of_target([1.0, 0.0, 3.0])\n    'multiclass'\n    >>> type_of_target(['a', 'b', 'c'])\n    'multiclass'\n    >>> type_of_target(np.array([[1, 2], [3, 1]]))\n    'multiclass-multioutput'\n    >>> type_of_target([[1, 2]])\n    'multilabel-indicator'\n    >>> type_of_target(np.array([[1.5, 2.0], [3.0, 1.6]]))\n    'continuous-multioutput'\n    >>> type_of_target(np.array([[0, 1], [1, 1]]))\n    'multilabel-indicator'\n    \"\"\"\n    xp, is_array_api_compliant = get_namespace(y)\n\n    def _raise_or_return():\n        \"\"\"Depending on the value of raise_unknown, either raise an error or return\n        'unknown'.\n        \"\"\"\n        if raise_unknown:\n            input = input_name if input_name else \"data\"\n            raise ValueError(f\"Unknown label type for {input}: {y!r}\")\n        else:\n            return \"unknown\"\n\n    valid = (\n        (isinstance(y, Sequence) or issparse(y) or hasattr(y, \"__array__\"))\n        and not isinstance(y, str)\n    ) or is_array_api_compliant\n\n    if not valid:\n        raise ValueError(\n            \"Expected array-like (array or non-string sequence), got %r\" % y\n        )\n\n    sparse_pandas = y.__class__.__name__ in [\"SparseSeries\", \"SparseArray\"]\n    if sparse_pandas:\n        raise ValueError(\"y cannot be class 'SparseSeries' or 'SparseArray'\")\n\n    if is_multilabel(y):\n        return \"multilabel-indicator\"\n\n    # DeprecationWarning will be replaced by ValueError, see NEP 34\n    # https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\n    # We therefore catch both deprecation (NumPy < 1.24) warning and\n    # value error (NumPy >= 1.24).\n    check_y_kwargs = dict(\n        accept_sparse=True,\n        allow_nd=True,\n        ensure_all_finite=False,\n        ensure_2d=False,\n        ensure_min_samples=0,\n        ensure_min_features=0,\n    )\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"error\", VisibleDeprecationWarning)\n        if not issparse(y):\n            try:\n                y = check_array(y, dtype=None, **check_y_kwargs)\n            except (VisibleDeprecationWarning, ValueError) as e:\n                if str(e).startswith(\"Complex data not supported\"):\n                    raise\n\n                # dtype=object should be provided explicitly for ragged arrays,\n                # see NEP 34\n                y = check_array(y, dtype=object, **check_y_kwargs)\n\n    try:\n        first_row_or_val = y[[0], :] if issparse(y) else y[0]\n        # labels in bytes format\n        if isinstance(first_row_or_val, bytes):\n            raise TypeError(\n                \"Support for labels represented as bytes is not supported. Convert \"\n                \"the labels to a string or integer format.\"\n            )\n        # The old sequence of sequences format\n        if (\n            not hasattr(first_row_or_val, \"__array__\")\n            and isinstance(first_row_or_val, Sequence)\n            and not isinstance(first_row_or_val, str)\n        ):\n            raise ValueError(\n                \"You appear to be using a legacy multi-label data\"\n                \" representation. Sequence of sequences are no\"\n                \" longer supported; use a binary array or sparse\"\n                \" matrix instead - the MultiLabelBinarizer\"\n                \" transformer can convert to this format.\"\n            )\n    except IndexError:\n        pass\n\n    # Invalid inputs\n    if y.ndim not in (1, 2):\n        # Number of dimension greater than 2: [[[1, 2]]]\n        return _raise_or_return()\n    if not min(y.shape):\n        # Empty ndarray: []/[[]]\n        if y.ndim == 1:\n            # 1-D empty array: []\n            return \"binary\"  # []\n        # 2-D empty array: [[]]\n        return _raise_or_return()\n    if not issparse(y) and y.dtype == object and not isinstance(y.flat[0], str):\n        # [obj_1] and not [\"label_1\"]\n        return _raise_or_return()\n\n    # Check if multioutput\n    if y.ndim == 2 and y.shape[1] > 1:\n        suffix = \"-multioutput\"  # [[1, 2], [1, 2]]\n    else:\n        suffix = \"\"  # [1, 2, 3] or [[1], [2], [3]]\n\n    # Check float and contains non-integer float values\n    if xp.isdtype(y.dtype, \"real floating\"):\n        # [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\n        data = y.data if issparse(y) else y\n        integral_data = xp.astype(data, xp.int64)\n        # conversion back to the original float dtype of y is required to\n        # satisfy array-api-strict which does not allow a comparison between\n        # arrays having different dtypes.\n        if xp.any(data != xp.astype(integral_data, y.dtype)):\n            _assert_all_finite(data, input_name=input_name)\n            return \"continuous\" + suffix\n\n    # Check multiclass\n    if issparse(first_row_or_val):\n        first_row_or_val = first_row_or_val.data\n    if cached_unique(y).shape[0] > 2 or (y.ndim == 2 and len(first_row_or_val) > 1):\n        # [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\n        return \"multiclass\" + suffix\n    else:\n        return \"binary\"  # [1, 2] or [[\"a\"], [\"b\"]]",
    "scikit-learn.sklearn.utils.validation.column_or_1d": "def column_or_1d(y, *, dtype=None, input_name=\"y\", warn=False, device=None):\n    \"\"\"Ravel column or 1d numpy array, else raises an error.\n\n    Parameters\n    ----------\n    y : array-like\n       Input data.\n\n    dtype : data-type, default=None\n        Data type for `y`.\n\n        .. versionadded:: 1.2\n\n    input_name : str, default=\"y\"\n        The data name used to construct the error message.\n\n        .. versionadded:: 1.8\n\n    warn : bool, default=False\n       To control display of warnings.\n\n    device : device, default=None\n        `device` object.\n        See the :ref:`Array API User Guide <array_api>` for more details.\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    y : ndarray\n       Output data.\n\n    Raises\n    ------\n    ValueError\n        If `y` is not a 1D array or a 2D array with a single row or column.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import column_or_1d\n    >>> column_or_1d([1, 1])\n    array([1, 1])\n    \"\"\"\n    xp, _ = get_namespace(y)\n    y = check_array(\n        y,\n        ensure_2d=False,\n        dtype=dtype,\n        input_name=input_name,\n        ensure_all_finite=False,\n        ensure_min_samples=0,\n    )\n\n    shape = y.shape\n    if len(shape) == 1:\n        return _asarray_with_order(\n            xp.reshape(y, (-1,)), order=\"C\", xp=xp, device=device\n        )\n    if len(shape) == 2 and shape[1] == 1:\n        if warn:\n            warnings.warn(\n                (\n                    \"A column-vector y was passed when a 1d array was\"\n                    \" expected. Please change the shape of y to \"\n                    \"(n_samples, ), for example using ravel().\"\n                ),\n                DataConversionWarning,\n                stacklevel=2,\n            )\n        return _asarray_with_order(\n            xp.reshape(y, (-1,)), order=\"C\", xp=xp, device=device\n        )\n\n    raise ValueError(\n        \"y should be a 1d array, got an array of shape {} instead.\".format(shape)\n    )",
    "scikit-learn.sklearn.utils.validation._check_sample_weight": "def _check_sample_weight(\n    sample_weight,\n    X,\n    *,\n    dtype=None,\n    force_float_dtype=True,\n    ensure_non_negative=False,\n    ensure_same_device=True,\n    copy=False,\n):\n    \"\"\"Validate sample weights.\n\n    Note that passing sample_weight=None will output an array of ones.\n    Therefore, in some cases, you may want to protect the call with:\n    if sample_weight is not None:\n        sample_weight = _check_sample_weight(...)\n\n    Parameters\n    ----------\n    sample_weight : {ndarray, Number or None}, shape (n_samples,)\n        Input sample weights.\n\n    X : {ndarray, list, sparse matrix}\n        Input data.\n\n    dtype : dtype, default=None\n        dtype of the validated `sample_weight`.\n        If None, and `sample_weight` is an array:\n\n            - If `sample_weight.dtype` is one of `{np.float64, np.float32}`,\n              then the dtype is preserved.\n            - Else the output has NumPy's default dtype: `np.float64`.\n\n        If `dtype` is not `{np.float32, np.float64, None}`, then output will\n        be `np.float64`.\n\n    force_float_dtype : bool, default=True\n        Whether `X` should be forced to be float dtype, when `dtype` is a non-float\n        dtype or None.\n\n    ensure_non_negative : bool, default=False,\n        Whether or not the weights are expected to be non-negative.\n\n        .. versionadded:: 1.0\n\n    ensure_same_device : bool, default=True\n        Whether `sample_weight` should be forced to be on the same device as `X`.\n\n    copy : bool, default=False\n        If True, a copy of sample_weight will be created.\n\n    Returns\n    -------\n    sample_weight : ndarray of shape (n_samples,)\n        Validated sample weight. It is guaranteed to be \"C\" contiguous.\n    \"\"\"\n    xp, is_array_api, device = get_namespace_and_device(X, remove_types=(int, float))\n\n    n_samples = _num_samples(X)\n\n    max_float_type = _max_precision_float_dtype(xp, device)\n    float_dtypes = (\n        [xp.float32] if max_float_type == xp.float32 else [xp.float64, xp.float32]\n    )\n    if force_float_dtype and dtype is not None and dtype not in float_dtypes:\n        dtype = max_float_type\n\n    if sample_weight is None:\n        sample_weight = xp.ones(n_samples, dtype=dtype, device=device)\n    elif isinstance(sample_weight, numbers.Number):\n        sample_weight = xp.full(n_samples, sample_weight, dtype=dtype, device=device)\n    else:\n        if force_float_dtype and dtype is None:\n            dtype = float_dtypes\n        if is_array_api and ensure_same_device:\n            sample_weight = xp.asarray(sample_weight, device=device)\n        sample_weight = check_array(\n            sample_weight,\n            accept_sparse=False,\n            ensure_2d=False,\n            dtype=dtype,\n            order=\"C\",\n            copy=copy,\n            input_name=\"sample_weight\",\n        )\n        if sample_weight.ndim != 1:\n            raise ValueError(\n                f\"Sample weights must be 1D array or scalar, got \"\n                f\"{sample_weight.ndim}D array. Expected either a scalar value \"\n                f\"or a 1D array of length {n_samples}.\"\n            )\n\n        if sample_weight.shape != (n_samples,):\n            raise ValueError(\n                \"sample_weight.shape == {}, expected {}!\".format(\n                    sample_weight.shape, (n_samples,)\n                )\n            )\n\n    if ensure_non_negative:\n        check_non_negative(sample_weight, \"`sample_weight`\")\n\n    return sample_weight",
    "scikit-learn.sklearn.utils.validation._num_samples": "def _num_samples(x):\n    \"\"\"Return number of samples in array-like x.\"\"\"\n    message = \"Expected sequence or array-like, got %s\" % type(x)\n    if hasattr(x, \"fit\") and callable(x.fit):\n        # Don't get num_samples from an ensembles length!\n        raise TypeError(message)\n\n    if _use_interchange_protocol(x):\n        return x.__dataframe__().num_rows()\n\n    if not hasattr(x, \"__len__\") and not hasattr(x, \"shape\"):\n        if hasattr(x, \"__array__\"):\n            xp, _ = get_namespace(x)\n            x = xp.asarray(x)\n        else:\n            raise TypeError(message)\n\n    if hasattr(x, \"shape\") and x.shape is not None:\n        if len(x.shape) == 0:\n            raise TypeError(\n                \"Input should have at least 1 dimension i.e. satisfy \"\n                f\"`len(x.shape) > 0`, got scalar `{x!r}` instead.\"\n            )\n        # Check that shape is returning an integer or default to len\n        # Dask dataframes may not return numeric shape[0] value\n        if isinstance(x.shape[0], numbers.Integral):\n            return x.shape[0]\n\n    try:\n        return len(x)\n    except TypeError as type_error:\n        raise TypeError(message) from type_error",
    "scikit-learn.sklearn.utils.validation.check_consistent_length": "def check_consistent_length(*arrays):\n    \"\"\"Check that all arrays have consistent first dimensions.\n\n    Checks whether all objects in arrays have the same shape or length.\n\n    Parameters\n    ----------\n    *arrays : list or tuple of input objects.\n        Objects that will be checked for consistent length.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_consistent_length\n    >>> a = [1, 2, 3]\n    >>> b = [2, 3, 4]\n    >>> check_consistent_length(a, b)\n    \"\"\"\n    lengths = [_num_samples(X) for X in arrays if X is not None]\n    if len(set(lengths)) > 1:\n        raise ValueError(\n            \"Found input variables with inconsistent numbers of samples: %r\"\n            % [int(l) for l in lengths]\n        )"
}