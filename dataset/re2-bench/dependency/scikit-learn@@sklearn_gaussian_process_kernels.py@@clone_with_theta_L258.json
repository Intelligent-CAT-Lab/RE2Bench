{
    "scikit-learn.sklearn.base.clone": "def clone(estimator, *, safe=True):\n    \"\"\"Construct a new unfitted estimator with the same parameters.\n\n    Clone does a deep copy of the model in an estimator\n    without actually copying attached data. It returns a new estimator\n    with the same parameters that has not been fitted on any data.\n\n    .. versionchanged:: 1.3\n        Delegates to `estimator.__sklearn_clone__` if the method exists.\n\n    Parameters\n    ----------\n    estimator : {list, tuple, set} of estimator instance or a single \\\n            estimator instance\n        The estimator or group of estimators to be cloned.\n    safe : bool, default=True\n        If safe is False, clone will fall back to a deep copy on objects\n        that are not estimators. Ignored if `estimator.__sklearn_clone__`\n        exists.\n\n    Returns\n    -------\n    estimator : object\n        The deep copy of the input, an estimator if input is an estimator.\n\n    Notes\n    -----\n    If the estimator's `random_state` parameter is an integer (or if the\n    estimator doesn't have a `random_state` parameter), an *exact clone* is\n    returned: the clone and the original estimator will give the exact same\n    results. Otherwise, *statistical clone* is returned: the clone might\n    return different results from the original estimator. More details can be\n    found in :ref:`randomness`.\n\n    Examples\n    --------\n    >>> from sklearn.base import clone\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n    >>> y = [0, 0, 1, 1]\n    >>> classifier = LogisticRegression().fit(X, y)\n    >>> cloned_classifier = clone(classifier)\n    >>> hasattr(classifier, \"classes_\")\n    True\n    >>> hasattr(cloned_classifier, \"classes_\")\n    False\n    >>> classifier is cloned_classifier\n    False\n    \"\"\"\n    if hasattr(estimator, \"__sklearn_clone__\") and not inspect.isclass(estimator):\n        return estimator.__sklearn_clone__()\n    return _clone_parametrized(estimator, safe=safe)",
    "scikit-learn.sklearn.gaussian_process.kernels.theta": "@theta.setter\ndef theta(self, theta):\n    \"\"\"Sets the (flattened, log-transformed) non-fixed hyperparameters.\n\n    Parameters\n    ----------\n    theta : ndarray of shape (n_dims,)\n        The non-fixed, log-transformed hyperparameters of the kernel\n    \"\"\"\n    k1_dims = self.k1.n_dims\n    self.k1.theta = theta[:k1_dims]\n    self.k2.theta = theta[k1_dims:]"
}