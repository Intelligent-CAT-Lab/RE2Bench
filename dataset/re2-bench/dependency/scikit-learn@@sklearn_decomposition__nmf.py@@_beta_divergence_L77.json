{
    "scikit-learn.sklearn.decomposition._nmf._special_sparse_dot": "def _special_sparse_dot(W, H, X):\n    \"\"\"Computes np.dot(W, H), only where X is non zero.\"\"\"\n    if sp.issparse(X):\n        ii, jj = X.nonzero()\n        n_vals = ii.shape[0]\n        dot_vals = np.empty(n_vals)\n        n_components = W.shape[1]\n\n        batch_size = max(n_components, n_vals // n_components)\n        for start in range(0, n_vals, batch_size):\n            batch = slice(start, start + batch_size)\n            dot_vals[batch] = np.multiply(W[ii[batch], :], H.T[jj[batch], :]).sum(\n                axis=1\n            )\n\n        WH = sp.coo_matrix((dot_vals, (ii, jj)), shape=X.shape)\n        return WH.tocsr()\n    else:\n        return np.dot(W, H)",
    "scikit-learn.sklearn.decomposition._nmf._beta_loss_to_float": "def _beta_loss_to_float(beta_loss):\n    \"\"\"Convert string beta_loss to float.\"\"\"\n    beta_loss_map = {\"frobenius\": 2, \"kullback-leibler\": 1, \"itakura-saito\": 0}\n    if isinstance(beta_loss, str):\n        beta_loss = beta_loss_map[beta_loss]\n    return beta_loss",
    "scikit-learn.sklearn.decomposition._nmf.trace_dot": "def trace_dot(X, Y):\n    \"\"\"Trace of np.dot(X, Y.T).\n\n    Parameters\n    ----------\n    X : array-like\n        First matrix.\n    Y : array-like\n        Second matrix.\n    \"\"\"\n    return np.dot(X.ravel(), Y.ravel())",
    "scikit-learn.sklearn.utils.extmath.squared_norm": "def squared_norm(x):\n    \"\"\"Squared Euclidean or Frobenius norm of x.\n\n    Faster than norm(x) ** 2.\n\n    Parameters\n    ----------\n    x : array-like\n        The input array which could be either be a vector or a 2 dimensional array.\n\n    Returns\n    -------\n    float\n        The Euclidean norm when x is a vector, the Frobenius norm when x\n        is a matrix (2-d array).\n    \"\"\"\n    x = np.ravel(x, order=\"K\")\n    if np.issubdtype(x.dtype, np.integer):\n        warnings.warn(\n            (\n                \"Array type is integer, np.dot may overflow. \"\n                \"Data should be float type to avoid this issue\"\n            ),\n            UserWarning,\n        )\n    return np.dot(x, x)"
}