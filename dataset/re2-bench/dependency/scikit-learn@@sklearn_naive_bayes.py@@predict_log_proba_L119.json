{
    "scikit-learn.sklearn.externals.array_api_extra._lib._funcs.atleast_nd": "def atleast_nd(x: Array, /, *, ndim: int, xp: ModuleType | None = None) -> Array:\n    \"\"\"\n    Recursively expand the dimension of an array to at least `ndim`.\n\n    Parameters\n    ----------\n    x : array\n        Input array.\n    ndim : int\n        The minimum number of dimensions for the result.\n    xp : array_namespace, optional\n        The standard-compatible namespace for `x`. Default: infer.\n\n    Returns\n    -------\n    array\n        An array with ``res.ndim`` >= `ndim`.\n        If ``x.ndim`` >= `ndim`, `x` is returned.\n        If ``x.ndim`` < `ndim`, `x` is expanded by prepending new axes\n        until ``res.ndim`` equals `ndim`.\n\n    Examples\n    --------\n    >>> import array_api_strict as xp\n    >>> import array_api_extra as xpx\n    >>> x = xp.asarray([1])\n    >>> xpx.atleast_nd(x, ndim=3, xp=xp)\n    Array([[[1]]], dtype=array_api_strict.int64)\n\n    >>> x = xp.asarray([[[1, 2],\n    ...                  [3, 4]]])\n    >>> xpx.atleast_nd(x, ndim=1, xp=xp) is x\n    True\n    \"\"\"\n    if xp is None:\n        xp = array_namespace(x)\n\n    if x.ndim < ndim:\n        x = xp.expand_dims(x, axis=0)\n        x = atleast_nd(x, ndim=ndim, xp=xp)\n    return x",
    "scikit-learn.sklearn.naive_bayes._joint_log_likelihood": "def _joint_log_likelihood(self, X):\n    \"\"\"Calculate the posterior log probability of the samples X\"\"\"\n    return safe_sparse_dot(X, self.feature_log_prob_.T) + self.class_log_prior_",
    "scikit-learn.sklearn.naive_bayes._check_X": "def _check_X(self, X):\n    \"\"\"Validate X, used only in predict* methods.\"\"\"\n    return validate_data(self, X, accept_sparse=\"csr\", reset=False)",
    "scikit-learn.sklearn.utils._array_api._logsumexp": "def _logsumexp(array, axis=None, xp=None):\n    # TODO replace by scipy.special.logsumexp when\n    # https://github.com/scipy/scipy/pull/22683 is part of a release.\n    # The following code is strongly inspired and simplified from\n    # scipy.special._logsumexp.logsumexp\n    xp, _, device = get_namespace_and_device(array, xp=xp)\n    axis = tuple(range(array.ndim)) if axis is None else axis\n\n    supported_dtypes = supported_float_dtypes(xp)\n    if array.dtype not in supported_dtypes:\n        array = xp.asarray(array, dtype=supported_dtypes[0])\n\n    array_max = xp.max(array, axis=axis, keepdims=True)\n    index_max = array == array_max\n\n    array = xp.asarray(array, copy=True)\n    array[index_max] = -xp.inf\n    i_max_dt = xp.astype(index_max, array.dtype)\n    m = xp.sum(i_max_dt, axis=axis, keepdims=True, dtype=array.dtype)\n    # Specifying device explicitly is the fix for https://github.com/scipy/scipy/issues/22680\n    shift = xp.where(\n        xp.isfinite(array_max),\n        array_max,\n        xp.asarray(0, dtype=array_max.dtype, device=device),\n    )\n    exp = xp.exp(array - shift)\n    s = xp.sum(exp, axis=axis, keepdims=True, dtype=exp.dtype)\n    s = xp.where(s == 0, s, s / m)\n    out = xp.log1p(s) + xp.log(m) + array_max\n    out = xp.squeeze(out, axis=axis)\n    out = out[()] if out.ndim == 0 else out\n\n    return out",
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant",
    "scikit-learn.sklearn.utils.validation.check_is_fitted": "def check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=all):\n    \"\"\"Perform is_fitted validation for estimator.\n\n    Checks if the estimator is fitted by verifying the presence of\n    fitted attributes (ending with a trailing underscore) and otherwise\n    raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this function will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.\n\n    Raises\n    ------\n    TypeError\n        If the estimator is a class or not an estimator instance\n\n    NotFittedError\n        If the attributes are not found.\n\n    Examples\n    --------\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.utils.validation import check_is_fitted\n    >>> from sklearn.exceptions import NotFittedError\n    >>> lr = LogisticRegression()\n    >>> try:\n    ...     check_is_fitted(lr)\n    ... except NotFittedError as exc:\n    ...     print(f\"Model is not fitted yet.\")\n    Model is not fitted yet.\n    >>> lr.fit([[1, 2], [1, 3]], [1, 0])\n    LogisticRegression()\n    >>> check_is_fitted(lr)\n    \"\"\"\n    if isclass(estimator):\n        raise TypeError(\"{} is a class, not an instance.\".format(estimator))\n    if msg is None:\n        msg = (\n            \"This %(name)s instance is not fitted yet. Call 'fit' with \"\n            \"appropriate arguments before using this estimator.\"\n        )\n\n    if not hasattr(estimator, \"fit\"):\n        raise TypeError(\"%s is not an estimator instance.\" % (estimator))\n\n    tags = get_tags(estimator)\n\n    if not tags.requires_fit and attributes is None:\n        return\n\n    if not _is_fitted(estimator, attributes, all_or_any):\n        raise NotFittedError(msg % {\"name\": type(estimator).__name__})"
}