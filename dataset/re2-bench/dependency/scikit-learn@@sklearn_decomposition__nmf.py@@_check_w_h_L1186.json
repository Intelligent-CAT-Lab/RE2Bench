{
    "scikit-learn.sklearn.decomposition._nmf._initialize_nmf": "def _initialize_nmf(X, n_components, init=None, eps=1e-6, random_state=None):\n    \"\"\"Algorithms for NMF initialization.\n\n    Computes an initial guess for the non-negative\n    rank k matrix approximation for X: X = WH.\n\n    Parameters\n    ----------\n    X : array-like of shape (n_samples, n_features)\n        The data matrix to be decomposed.\n\n    n_components : int\n        The number of components desired in the approximation.\n\n    init :  {'random', 'nndsvd', 'nndsvda', 'nndsvdar'}, default=None\n        Method used to initialize the procedure.\n        Valid options:\n\n        - None: 'nndsvda' if n_components <= min(n_samples, n_features),\n            otherwise 'random'.\n\n        - 'random': non-negative random matrices, scaled with:\n            sqrt(X.mean() / n_components)\n\n        - 'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)\n            initialization (better for sparseness)\n\n        - 'nndsvda': NNDSVD with zeros filled with the average of X\n            (better when sparsity is not desired)\n\n        - 'nndsvdar': NNDSVD with zeros filled with small random values\n            (generally faster, less accurate alternative to NNDSVDa\n            for when sparsity is not desired)\n\n        - 'custom': use custom matrices W and H\n\n        .. versionchanged:: 1.1\n            When `init=None` and n_components is less than n_samples and n_features\n            defaults to `nndsvda` instead of `nndsvd`.\n\n    eps : float, default=1e-6\n        Truncate all values less then this in output to zero.\n\n    random_state : int, RandomState instance or None, default=None\n        Used when ``init`` == 'nndsvdar' or 'random'. Pass an int for\n        reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    Returns\n    -------\n    W : array-like of shape (n_samples, n_components)\n        Initial guesses for solving X ~= WH.\n\n    H : array-like of shape (n_components, n_features)\n        Initial guesses for solving X ~= WH.\n\n    References\n    ----------\n    C. Boutsidis, E. Gallopoulos: SVD based initialization: A head start for\n    nonnegative matrix factorization - Pattern Recognition, 2008\n    http://tinyurl.com/nndsvd\n    \"\"\"\n    check_non_negative(X, \"NMF initialization\")\n    n_samples, n_features = X.shape\n\n    if (\n        init is not None\n        and init != \"random\"\n        and n_components > min(n_samples, n_features)\n    ):\n        raise ValueError(\n            \"init = '{}' can only be used when \"\n            \"n_components <= min(n_samples, n_features)\".format(init)\n        )\n\n    if init is None:\n        if n_components <= min(n_samples, n_features):\n            init = \"nndsvda\"\n        else:\n            init = \"random\"\n\n    # Random initialization\n    if init == \"random\":\n        avg = np.sqrt(X.mean() / n_components)\n        rng = check_random_state(random_state)\n        H = avg * rng.standard_normal(size=(n_components, n_features)).astype(\n            X.dtype, copy=False\n        )\n        W = avg * rng.standard_normal(size=(n_samples, n_components)).astype(\n            X.dtype, copy=False\n        )\n        np.abs(H, out=H)\n        np.abs(W, out=W)\n        return W, H\n\n    # NNDSVD initialization\n    U, S, V = _randomized_svd(X, n_components, random_state=random_state)\n    W = np.zeros_like(U)\n    H = np.zeros_like(V)\n\n    # The leading singular triplet is non-negative\n    # so it can be used as is for initialization.\n    W[:, 0] = np.sqrt(S[0]) * np.abs(U[:, 0])\n    H[0, :] = np.sqrt(S[0]) * np.abs(V[0, :])\n\n    for j in range(1, n_components):\n        x, y = U[:, j], V[j, :]\n\n        # extract positive and negative parts of column vectors\n        x_p, y_p = np.maximum(x, 0), np.maximum(y, 0)\n        x_n, y_n = np.abs(np.minimum(x, 0)), np.abs(np.minimum(y, 0))\n\n        # and their norms\n        x_p_nrm, y_p_nrm = norm(x_p), norm(y_p)\n        x_n_nrm, y_n_nrm = norm(x_n), norm(y_n)\n\n        m_p, m_n = x_p_nrm * y_p_nrm, x_n_nrm * y_n_nrm\n\n        # choose update\n        if m_p > m_n:\n            u = x_p / x_p_nrm\n            v = y_p / y_p_nrm\n            sigma = m_p\n        else:\n            u = x_n / x_n_nrm\n            v = y_n / y_n_nrm\n            sigma = m_n\n\n        lbd = np.sqrt(S[j] * sigma)\n        W[:, j] = lbd * u\n        H[j, :] = lbd * v\n\n    W[W < eps] = 0\n    H[H < eps] = 0\n\n    if init == \"nndsvd\":\n        pass\n    elif init == \"nndsvda\":\n        avg = X.mean()\n        W[W == 0] = avg\n        H[H == 0] = avg\n    elif init == \"nndsvdar\":\n        rng = check_random_state(random_state)\n        avg = X.mean()\n        W[W == 0] = abs(avg * rng.standard_normal(size=len(W[W == 0])) / 100)\n        H[H == 0] = abs(avg * rng.standard_normal(size=len(H[H == 0])) / 100)\n    else:\n        raise ValueError(\n            \"Invalid init parameter: got %r instead of one of %r\"\n            % (init, (None, \"random\", \"nndsvd\", \"nndsvda\", \"nndsvdar\"))\n        )\n\n    return W, H",
    "scikit-learn.sklearn.decomposition._nmf._check_init": "def _check_init(A, shape, whom):\n    A = check_array(A)\n    if shape[0] != \"auto\" and A.shape[0] != shape[0]:\n        raise ValueError(\n            f\"Array with wrong first dimension passed to {whom}. Expected {shape[0]}, \"\n            f\"but got {A.shape[0]}.\"\n        )\n    if shape[1] != \"auto\" and A.shape[1] != shape[1]:\n        raise ValueError(\n            f\"Array with wrong second dimension passed to {whom}. Expected {shape[1]}, \"\n            f\"but got {A.shape[1]}.\"\n        )\n    check_non_negative(A, whom)\n    if np.max(A) == 0:\n        raise ValueError(f\"Array passed to {whom} is full of zeros.\")"
}