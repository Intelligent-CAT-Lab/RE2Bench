{
    "scikit-learn.sklearn.decomposition._fastica._logcosh": "def _logcosh(x, fun_args=None):\n    alpha = fun_args.get(\"alpha\", 1.0)  # comment it out?\n\n    x *= alpha\n    gx = np.tanh(x, x)  # apply the tanh inplace\n    g_x = np.empty(x.shape[0], dtype=x.dtype)\n    # XXX compute in chunks to avoid extra allocation\n    for i, gx_i in enumerate(gx):  # please don't vectorize.\n        g_x[i] = (alpha * (1 - gx_i**2)).mean()\n    return gx, g_x",
    "scikit-learn.sklearn.decomposition._fastica._exp": "def _exp(x, fun_args):\n    exp = np.exp(-(x**2) / 2)\n    gx = x * exp\n    g_x = (1 - x**2) * exp\n    return gx, g_x.mean(axis=-1)",
    "scikit-learn.sklearn.decomposition._fastica._cube": "def _cube(x, fun_args):\n    return x**3, (3 * x**2).mean(axis=-1)",
    "scikit-learn.sklearn.decomposition._fastica._gs_decorrelation": "def _gs_decorrelation(w, W, j):\n    \"\"\"\n    Orthonormalize w wrt the first j rows of W.\n\n    Parameters\n    ----------\n    w : ndarray of shape (n,)\n        Array to be orthogonalized\n\n    W : ndarray of shape (p, n)\n        Null space definition\n\n    j : int < p\n        The no of (from the first) rows of Null space W wrt which w is\n        orthogonalized.\n\n    Notes\n    -----\n    Assumes that W is orthogonal\n    w changed in place\n    \"\"\"\n    w -= np.linalg.multi_dot([w, W[:j].T, W[:j]])\n    return w",
    "scikit-learn.sklearn.decomposition._fastica.g": "def g(x, fun_args):\n    return self.fun(x, **fun_args)"
}