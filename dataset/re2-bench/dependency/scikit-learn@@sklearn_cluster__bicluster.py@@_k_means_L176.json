{
    "scikit-learn.sklearn.base.wrapper": "@functools.wraps(fit_method)\ndef wrapper(estimator, *args, **kwargs):\n    global_skip_validation = get_config()[\"skip_parameter_validation\"]\n\n    # we don't want to validate again for each call to partial_fit\n    partial_fit_and_fitted = (\n        fit_method.__name__ == \"partial_fit\" and _is_fitted(estimator)\n    )\n\n    if not global_skip_validation and not partial_fit_and_fitted:\n        estimator._validate_params()\n\n    with config_context(\n        skip_parameter_validation=(\n            prefer_skip_nested_validation or global_skip_validation\n        )\n    ):\n        return fit_method(estimator, *args, **kwargs)",
    "scikit-learn.sklearn.cluster._kmeans.__init__": "def __init__(\n    self,\n    n_clusters=8,\n    *,\n    init=\"k-means++\",\n    max_iter=100,\n    batch_size=1024,\n    verbose=0,\n    compute_labels=True,\n    random_state=None,\n    tol=0.0,\n    max_no_improvement=10,\n    init_size=None,\n    n_init=\"auto\",\n    reassignment_ratio=0.01,\n):\n    super().__init__(\n        n_clusters=n_clusters,\n        init=init,\n        max_iter=max_iter,\n        verbose=verbose,\n        random_state=random_state,\n        tol=tol,\n        n_init=n_init,\n    )\n\n    self.max_no_improvement = max_no_improvement\n    self.batch_size = batch_size\n    self.compute_labels = compute_labels\n    self.init_size = init_size\n    self.reassignment_ratio = reassignment_ratio"
}