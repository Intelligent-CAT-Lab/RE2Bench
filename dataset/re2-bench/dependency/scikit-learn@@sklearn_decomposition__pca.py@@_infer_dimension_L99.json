{
    "scikit-learn.sklearn.decomposition._pca._assess_dimension": "def _assess_dimension(spectrum, rank, n_samples):\n    \"\"\"Compute the log-likelihood of a rank ``rank`` dataset.\n\n    The dataset is assumed to be embedded in gaussian noise of shape(n,\n    dimf) having spectrum ``spectrum``. This implements the method of\n    T. P. Minka.\n\n    Parameters\n    ----------\n    spectrum : ndarray of shape (n_features,)\n        Data spectrum.\n    rank : int\n        Tested rank value. It should be strictly lower than n_features,\n        otherwise the method isn't specified (division by zero in equation\n        (31) from the paper).\n    n_samples : int\n        Number of samples.\n\n    Returns\n    -------\n    ll : float\n        The log-likelihood.\n\n    References\n    ----------\n    This implements the method of `Thomas P. Minka:\n    Automatic Choice of Dimensionality for PCA. NIPS 2000: 598-604\n    <https://proceedings.neurips.cc/paper/2000/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf>`_\n    \"\"\"\n    xp, _ = get_namespace(spectrum)\n\n    n_features = spectrum.shape[0]\n    if not 1 <= rank < n_features:\n        raise ValueError(\"the tested rank should be in [1, n_features - 1]\")\n\n    eps = 1e-15\n\n    if spectrum[rank - 1] < eps:\n        # When the tested rank is associated with a small eigenvalue, there's\n        # no point in computing the log-likelihood: it's going to be very\n        # small and won't be the max anyway. Also, it can lead to numerical\n        # issues below when computing pa, in particular in log((spectrum[i] -\n        # spectrum[j]) because this will take the log of something very small.\n        return -xp.inf\n\n    pu = -rank * log(2.0)\n    for i in range(1, rank + 1):\n        pu += (\n            lgamma((n_features - i + 1) / 2.0) - log(xp.pi) * (n_features - i + 1) / 2.0\n        )\n\n    pl = xp.sum(xp.log(spectrum[:rank]))\n    pl = -pl * n_samples / 2.0\n\n    v = max(eps, xp.sum(spectrum[rank:]) / (n_features - rank))\n    pv = -log(v) * n_samples * (n_features - rank) / 2.0\n\n    m = n_features * rank - rank * (rank + 1.0) / 2.0\n    pp = log(2.0 * xp.pi) * (m + rank) / 2.0\n\n    pa = 0.0\n    spectrum_ = xp.asarray(spectrum, copy=True)\n    spectrum_[rank:n_features] = v\n    for i in range(rank):\n        for j in range(i + 1, spectrum.shape[0]):\n            pa += log(\n                (spectrum[i] - spectrum[j]) * (1.0 / spectrum_[j] - 1.0 / spectrum_[i])\n            ) + log(n_samples)\n\n    ll = pu + pl + pv + pp - pa / 2.0 - rank * log(n_samples) / 2.0\n\n    return ll",
    "scikit-learn.sklearn.externals.array_api_compat._internal.wrapped_f": "@wraps(f)\ndef wrapped_f(*args: object, **kwargs: object) -> object:\n    return f(*args, xp=xp, **kwargs)",
    "scikit-learn.sklearn.utils._array_api.get_namespace": "def get_namespace(*arrays, remove_none=True, remove_types=(str,), xp=None):\n    \"\"\"Get namespace of arrays.\n\n    Introspect `arrays` arguments and return their common Array API compatible\n    namespace object, if any.\n\n    Note that sparse arrays are filtered by default.\n\n    See: https://numpy.org/neps/nep-0047-array-api-standard.html\n\n    If `arrays` are regular numpy arrays, `array_api_compat.numpy` is returned instead.\n\n    Namespace support is not enabled by default. To enabled it call:\n\n      sklearn.set_config(array_api_dispatch=True)\n\n    or:\n\n      with sklearn.config_context(array_api_dispatch=True):\n          # your code here\n\n    Otherwise `array_api_compat.numpy` is\n    always returned irrespective of the fact that arrays implement the\n    `__array_namespace__` protocol or not.\n\n    Note that if no arrays pass the set filters, ``_NUMPY_API_WRAPPER_INSTANCE, False``\n    is returned.\n\n    Parameters\n    ----------\n    *arrays : array objects\n        Array objects.\n\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to the NumPy namespace.\n\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the array API spec (see\n        https://data-apis.org/array-api/latest/index.html).\n        Always False when array_api_dispatch=False.\n    \"\"\"\n    array_api_dispatch = get_config()[\"array_api_dispatch\"]\n    if not array_api_dispatch:\n        if xp is not None:\n            return xp, False\n        else:\n            return np_compat, False\n\n    if xp is not None:\n        return xp, True\n\n    arrays = _remove_non_arrays(\n        *arrays,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n\n    if not arrays:\n        return np_compat, False\n\n    _check_array_api_dispatch(array_api_dispatch)\n\n    namespace, is_array_api_compliant = array_api_compat.get_namespace(*arrays), True\n\n    if namespace.__name__ == \"array_api_strict\" and hasattr(\n        namespace, \"set_array_api_strict_flags\"\n    ):\n        namespace.set_array_api_strict_flags(api_version=\"2024.12\")\n\n    return namespace, is_array_api_compliant"
}