{
    "scikit-learn.sklearn.externals.array_api_compat._internal.wrapped_f": "@wraps(f)\ndef wrapped_f(*args: object, **kwargs: object) -> object:\n    return f(*args, xp=xp, **kwargs)",
    "scikit-learn.sklearn.externals.array_api_compat.numpy._aliases.astype": "def astype(\n    x: Array,\n    dtype: DType,\n    /,\n    *,\n    copy: py_bool = True,\n    device: Device | None = None,\n) -> Array:\n    _helpers._check_device(np, device)\n    return x.astype(dtype=dtype, copy=copy)",
    "scikit-learn.sklearn.utils._array_api.get_namespace_and_device": "def get_namespace_and_device(\n    *array_list, remove_none=True, remove_types=(str,), xp=None\n):\n    \"\"\"Combination into one single function of `get_namespace` and `device`.\n\n    Parameters\n    ----------\n    *array_list : array objects\n        Array objects.\n    remove_none : bool, default=True\n        Whether to ignore None objects passed in arrays.\n    remove_types : tuple or list, default=(str,)\n        Types to ignore in the arrays.\n    xp : module, default=None\n        Precomputed array namespace module. When passed, typically from a caller\n        that has already performed inspection of its own inputs, skips array\n        namespace inspection.\n\n    Returns\n    -------\n    namespace : module\n        Namespace shared by array objects. If any of the `arrays` are not arrays,\n        the namespace defaults to NumPy.\n    is_array_api_compliant : bool\n        True if the arrays are containers that implement the Array API spec.\n        Always False when array_api_dispatch=False.\n    device : device\n        `device` object (see the \"Device Support\" section of the array API spec).\n    \"\"\"\n    skip_remove_kwargs = dict(remove_none=False, remove_types=[])\n\n    array_list = _remove_non_arrays(\n        *array_list,\n        remove_none=remove_none,\n        remove_types=remove_types,\n    )\n    arrays_device = device(*array_list, **skip_remove_kwargs)\n\n    if xp is None:\n        xp, is_array_api = get_namespace(*array_list, **skip_remove_kwargs)\n    else:\n        xp, is_array_api = xp, True\n\n    if is_array_api:\n        return xp, is_array_api, arrays_device\n    else:\n        return xp, False, arrays_device",
    "scikit-learn.sklearn.utils._array_api._max_precision_float_dtype": "def _max_precision_float_dtype(xp, device):\n    \"\"\"Return the float dtype with the highest precision supported by the device.\"\"\"\n    # TODO: Update to use `__array_namespace__info__()` from array-api v2023.12\n    # when/if that becomes more widespread.\n    if _is_xp_namespace(xp, \"torch\") and str(device).startswith(\n        \"mps\"\n    ):  # pragma: no cover\n        return xp.float32\n    return xp.float64",
    "scikit-learn.sklearn.utils._chunking.gen_batches": "@validate_params(\n    {\n        \"n\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"batch_size\": [Interval(Integral, 1, None, closed=\"left\")],\n        \"min_batch_size\": [Interval(Integral, 0, None, closed=\"left\")],\n    },\n    prefer_skip_nested_validation=True,\n)\ndef gen_batches(n, batch_size, *, min_batch_size=0):\n    \"\"\"Generator to create slices containing `batch_size` elements from 0 to `n`.\n\n    The last slice may contain less than `batch_size` elements, when\n    `batch_size` does not divide `n`.\n\n    Parameters\n    ----------\n    n : int\n        Size of the sequence.\n    batch_size : int\n        Number of elements in each batch.\n    min_batch_size : int, default=0\n        Minimum number of elements in each batch.\n\n    Yields\n    ------\n    slice of `batch_size` elements\n\n    See Also\n    --------\n    gen_even_slices: Generator to create n_packs slices going up to n.\n\n    Examples\n    --------\n    >>> from sklearn.utils import gen_batches\n    >>> list(gen_batches(7, 3))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(6, 3))\n    [slice(0, 3, None), slice(3, 6, None)]\n    >>> list(gen_batches(2, 3))\n    [slice(0, 2, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=0))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=2))\n    [slice(0, 3, None), slice(3, 7, None)]\n    \"\"\"\n    start = 0\n    for _ in range(int(n // batch_size)):\n        end = start + batch_size\n        if end + min_batch_size > n:\n            continue\n        yield slice(start, end)\n        start = end\n    if start < n:\n        yield slice(start, n)",
    "scikit-learn.sklearn.utils._param_validation.wrapper": "@functools.wraps(func)\ndef wrapper(*args, **kwargs):\n    global_skip_validation = get_config()[\"skip_parameter_validation\"]\n    if global_skip_validation:\n        return func(*args, **kwargs)\n\n    func_sig = signature(func)\n\n    # Map *args/**kwargs to the function signature\n    params = func_sig.bind(*args, **kwargs)\n    params.apply_defaults()\n\n    # ignore self/cls and positional/keyword markers\n    to_ignore = [\n        p.name\n        for p in func_sig.parameters.values()\n        if p.kind in (p.VAR_POSITIONAL, p.VAR_KEYWORD)\n    ]\n    to_ignore += [\"self\", \"cls\"]\n    params = {k: v for k, v in params.arguments.items() if k not in to_ignore}\n\n    validate_parameter_constraints(\n        parameter_constraints, params, caller_name=func.__qualname__\n    )\n\n    try:\n        with config_context(\n            skip_parameter_validation=(\n                prefer_skip_nested_validation or global_skip_validation\n            )\n        ):\n            return func(*args, **kwargs)\n    except InvalidParameterError as e:\n        # When the function is just a wrapper around an estimator, we allow\n        # the function to delegate validation to the estimator, but we replace\n        # the name of the estimator by the name of the function in the error\n        # message to avoid confusion.\n        msg = re.sub(\n            r\"parameter of \\w+ must be\",\n            f\"parameter of {func.__qualname__} must be\",\n            str(e),\n        )\n        raise InvalidParameterError(msg) from e",
    "scikit-learn.sklearn.utils.extmath.safe_sparse_dot": "def safe_sparse_dot(a, b, *, dense_output=False):\n    \"\"\"Dot product that handle the sparse matrix case correctly.\n\n    Parameters\n    ----------\n    a : {ndarray, sparse matrix}\n    b : {ndarray, sparse matrix}\n    dense_output : bool, default=False\n        When False, ``a`` and ``b`` both being sparse will yield sparse output.\n        When True, output will always be a dense array.\n\n    Returns\n    -------\n    dot_product : {ndarray, sparse matrix}\n        Sparse if ``a`` and ``b`` are sparse and ``dense_output=False``.\n\n    Examples\n    --------\n    >>> from scipy.sparse import csr_matrix\n    >>> from sklearn.utils.extmath import safe_sparse_dot\n    >>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    >>> dot_product = safe_sparse_dot(X, X.T)\n    >>> dot_product.toarray()\n    array([[ 5, 11, 17],\n           [11, 25, 39],\n           [17, 39, 61]])\n    \"\"\"\n    xp, _ = get_namespace(a, b)\n    if a.ndim > 2 or b.ndim > 2:\n        if sparse.issparse(a):\n            # sparse is always 2D. Implies b is 3D+\n            # [i, j] @ [k, ..., l, m, n] -> [i, k, ..., l, n]\n            b_ = np.rollaxis(b, -2)\n            b_2d = b_.reshape((b.shape[-2], -1))\n            ret = a @ b_2d\n            ret = ret.reshape(a.shape[0], *b_.shape[1:])\n        elif sparse.issparse(b):\n            # sparse is always 2D. Implies a is 3D+\n            # [k, ..., l, m] @ [i, j] -> [k, ..., l, j]\n            a_2d = a.reshape(-1, a.shape[-1])\n            ret = a_2d @ b\n            ret = ret.reshape(*a.shape[:-1], b.shape[1])\n        else:\n            # Alternative for `np.dot` when dealing with a or b having\n            # more than 2 dimensions, that works with the array api.\n            # If b is 1-dim then the last axis for b is taken otherwise\n            # if b is >= 2-dim then the second to last axis is taken.\n            b_axis = -1 if b.ndim == 1 else -2\n            ret = xp.tensordot(a, b, axes=[-1, b_axis])\n    elif (\n        dense_output\n        and a.ndim == 2\n        and b.ndim == 2\n        and a.dtype in (np.float32, np.float64)\n        and b.dtype in (np.float32, np.float64)\n        and (sparse.issparse(a) and a.format in (\"csc\", \"csr\"))\n        and (sparse.issparse(b) and b.format in (\"csc\", \"csr\"))\n    ):\n        # Use dedicated fast method for dense_C = sparse_A @\u00a0sparse_B\n        return sparse_matmul_to_dense(a, b)\n    else:\n        ret = a @ b\n\n    if (\n        sparse.issparse(a)\n        and sparse.issparse(b)\n        and dense_output\n        and hasattr(ret, \"toarray\")\n    ):\n        return ret.toarray()\n    return ret",
    "scikit-learn.sklearn.utils.extmath.row_norms": "def row_norms(X, squared=False):\n    \"\"\"Row-wise (squared) Euclidean norm of X.\n\n    Equivalent to np.sqrt((X * X).sum(axis=1)), but also supports sparse\n    matrices and does not create an X.shape-sized temporary.\n\n    Performs no input validation.\n\n    Parameters\n    ----------\n    X : array-like\n        The input array.\n    squared : bool, default=False\n        If True, return squared norms.\n\n    Returns\n    -------\n    array-like\n        The row-wise (squared) Euclidean norm of X.\n    \"\"\"\n    if sparse.issparse(X):\n        X = X.tocsr()\n        norms = csr_row_norms(X)\n        if not squared:\n            norms = np.sqrt(norms)\n    else:\n        xp, _ = get_namespace(X)\n        if _is_numpy_namespace(xp):\n            X = np.asarray(X)\n            norms = np.einsum(\"ij,ij->i\", X, X)\n            norms = xp.asarray(norms)\n        else:\n            norms = xp.sum(xp.multiply(X, X), axis=1)\n        if not squared:\n            norms = xp.sqrt(norms)\n    return norms"
}