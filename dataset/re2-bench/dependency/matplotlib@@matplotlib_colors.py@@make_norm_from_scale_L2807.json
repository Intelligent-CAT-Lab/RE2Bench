{
    "matplotlib.lib.matplotlib.colors._make_norm_from_scale": "@functools.cache\ndef _make_norm_from_scale(\n    scale_cls, scale_args, scale_kwargs_items,\n    base_norm_cls, bound_init_signature,\n):\n    \"\"\"\n    Helper for `make_norm_from_scale`.\n\n    This function is split out to enable caching (in particular so that\n    different unpickles reuse the same class).  In order to do so,\n\n    - ``functools.partial`` *scale_cls* is expanded into ``func, args, kwargs``\n      to allow memoizing returned norms (partial instances always compare\n      unequal, but we can check identity based on ``func, args, kwargs``;\n    - *init* is replaced by *init_signature*, as signatures are picklable,\n      unlike to arbitrary lambdas.\n    \"\"\"\n\n    class ScaleNorm(base_norm_cls):\n        def __reduce__(self):\n            cls = type(self)\n            # If the class is toplevel-accessible, it is possible to directly\n            # pickle it \"by name\".  This is required to support norm classes\n            # defined at a module's toplevel, as the inner base_norm_cls is\n            # otherwise unpicklable (as it gets shadowed by the generated norm\n            # class).  If either import or attribute access fails, fall back to\n            # the general path.\n            try:\n                if cls is getattr(importlib.import_module(cls.__module__),\n                                  cls.__qualname__):\n                    return (_create_empty_object_of_class, (cls,), vars(self))\n            except (ImportError, AttributeError):\n                pass\n            return (_picklable_norm_constructor,\n                    (scale_cls, scale_args, scale_kwargs_items,\n                     base_norm_cls, bound_init_signature),\n                    vars(self))\n\n        def __init__(self, *args, **kwargs):\n            ba = bound_init_signature.bind(*args, **kwargs)\n            ba.apply_defaults()\n            super().__init__(\n                **{k: ba.arguments.pop(k) for k in [\"vmin\", \"vmax\", \"clip\"]})\n            self._scale = functools.partial(\n                scale_cls, *scale_args, **dict(scale_kwargs_items))(\n                    axis=None, **ba.arguments)\n            self._trf = self._scale.get_transform()\n\n        __init__.__signature__ = bound_init_signature.replace(parameters=[\n            inspect.Parameter(\"self\", inspect.Parameter.POSITIONAL_OR_KEYWORD),\n            *bound_init_signature.parameters.values()])\n\n        def __call__(self, value, clip=None):\n            value, is_scalar = self.process_value(value)\n            if self.vmin is None or self.vmax is None:\n                self.autoscale_None(value)\n            if self.vmin > self.vmax:\n                raise ValueError(\"vmin must be less or equal to vmax\")\n            if self.vmin == self.vmax:\n                return np.full_like(value, 0)\n            if clip is None:\n                clip = self.clip\n            if clip:\n                value = np.clip(value, self.vmin, self.vmax)\n            t_value = self._trf.transform(value).reshape(np.shape(value))\n            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n            if not np.isfinite([t_vmin, t_vmax]).all():\n                raise ValueError(\"Invalid vmin or vmax\")\n            t_value -= t_vmin\n            t_value /= (t_vmax - t_vmin)\n            t_value = np.ma.masked_invalid(t_value, copy=False)\n            return t_value[0] if is_scalar else t_value\n\n        def inverse(self, value):\n            if not self.scaled():\n                raise ValueError(\"Not invertible until scaled\")\n            if self.vmin > self.vmax:\n                raise ValueError(\"vmin must be less or equal to vmax\")\n            t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n            if not np.isfinite([t_vmin, t_vmax]).all():\n                raise ValueError(\"Invalid vmin or vmax\")\n            value, is_scalar = self.process_value(value)\n            rescaled = value * (t_vmax - t_vmin)\n            rescaled += t_vmin\n            value = (self._trf\n                     .inverted()\n                     .transform(rescaled)\n                     .reshape(np.shape(value)))\n            return value[0] if is_scalar else value\n\n        def autoscale_None(self, A):\n            # i.e. A[np.isfinite(...)], but also for non-array A's\n            in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n            if in_trf_domain.size == 0:\n                in_trf_domain = np.ma.masked\n            return super().autoscale_None(in_trf_domain)\n\n    if base_norm_cls is Normalize:\n        ScaleNorm.__name__ = f\"{scale_cls.__name__}Norm\"\n        ScaleNorm.__qualname__ = f\"{scale_cls.__qualname__}Norm\"\n    else:\n        ScaleNorm.__name__ = base_norm_cls.__name__\n        ScaleNorm.__qualname__ = base_norm_cls.__qualname__\n    ScaleNorm.__module__ = base_norm_cls.__module__\n    ScaleNorm.__doc__ = base_norm_cls.__doc__\n\n    return ScaleNorm"
}