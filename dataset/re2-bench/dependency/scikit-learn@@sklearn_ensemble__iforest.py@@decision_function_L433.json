{
    "scikit-learn.sklearn.ensemble._iforest.score_samples": "def score_samples(self, X):\n    \"\"\"\n    Opposite of the anomaly score defined in the original paper.\n\n    The anomaly score of an input sample is computed as\n    the mean anomaly score of the trees in the forest.\n\n    The measure of normality of an observation given a tree is the depth\n    of the leaf containing this observation, which is equivalent to\n    the number of splittings required to isolate this point. In case of\n    several observations n_left in the leaf, the average path length of\n    an n_left samples isolation tree is added.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The input samples.\n\n    Returns\n    -------\n    scores : ndarray of shape (n_samples,)\n        The anomaly score of the input samples.\n        The lower, the more abnormal.\n\n    Notes\n    -----\n    The score function method can be parallelized by setting a joblib context. This\n    inherently does NOT use the ``n_jobs`` parameter initialized in the class,\n    which is used during ``fit``. This is because, calculating the score may\n    actually be faster without parallelization for a small number of samples,\n    such as for 1000 samples or less.\n    The user can set the number of jobs in the joblib context to control the\n    number of parallel jobs.\n\n    .. code-block:: python\n\n        from joblib import parallel_backend\n\n        # Note, we use threading here as the score_samples method is not CPU bound.\n        with parallel_backend(\"threading\", n_jobs=4):\n            model.score(X)\n    \"\"\"\n    # Check data\n    X = validate_data(\n        self,\n        X,\n        accept_sparse=\"csr\",\n        dtype=tree_dtype,\n        reset=False,\n        ensure_all_finite=False,\n    )\n\n    return self._score_samples(X)"
}