{"types": {}, "values": {"inputs": {"self": {"input": "content", "encoding": "utf-8", "decode_error": "strict", "strip_accents": "ascii", "preprocessor": null, "tokenizer": null, "analyzer": "word", "lowercase": true, "token_pattern": "(?u)\\b\\w\\w+\\b", "stop_words": null, "max_df": 1.0, "min_df": 1, "max_features": null, "ngram_range": [1, 1], "vocabulary": null, "binary": false, "dtype": "<class 'numpy.int64'>", "_stop_words_id": 8798272}, "args": {"tokens": ["ai", "mange", "du", "kangourou", "ce", "midi", "etait", "pas", "tres", "bon"], "stop_words": null}, "kwargs": {}}, "return": ["ai", "mange", "du", "kangourou", "ce", "midi", "etait", "pas", "tres", "bon"]}, "name": "_word_ngrams"}
{"types": {}, "values": {"inputs": {"self": {"input": "content", "encoding": "utf-8", "decode_error": "strict", "strip_accents": "ascii", "preprocessor": null, "tokenizer": null, "analyzer": "word", "lowercase": true, "token_pattern": "(?u)\\b\\w\\w+\\b", "stop_words": null, "max_df": 1.0, "min_df": 1, "max_features": null, "ngram_range": [1, 1], "vocabulary": null, "binary": false, "dtype": "<class 'numpy.int64'>", "_stop_words_id": 8798272}, "args": {"tokens": ["this", "is", "test", "really", "met", "harry", "yesterday"], "stop_words": null}, "kwargs": {}}, "return": ["this", "is", "test", "really", "met", "harry", "yesterday"]}, "name": "_word_ngrams"}
{"types": {}, "values": {"inputs": {"self": {"input": "file", "encoding": "utf-8", "decode_error": "strict", "strip_accents": null, "preprocessor": null, "tokenizer": null, "analyzer": "word", "lowercase": true, "token_pattern": "(?u)\\b\\w\\w+\\b", "stop_words": null, "max_df": 1.0, "min_df": 1, "max_features": null, "ngram_range": [1, 1], "vocabulary": null, "binary": false, "dtype": "<class 'numpy.int64'>", "_stop_words_id": 8798272}, "args": {"tokens": ["this", "is", "test", "with", "file", "like", "object"], "stop_words": null}, "kwargs": {}}, "return": ["this", "is", "test", "with", "file", "like", "object"]}, "name": "_word_ngrams"}
{"types": {}, "values": {"inputs": {"self": {"input": "content", "encoding": "utf-8", "decode_error": "strict", "strip_accents": null, "preprocessor": "<function uppercase at 0x70e60f77ad40>", "tokenizer": null, "analyzer": "word", "lowercase": true, "token_pattern": "(?u)\\b\\w\\w+\\b", "stop_words": null, "max_df": 1.0, "min_df": 1, "max_features": null, "ngram_range": [1, 1], "vocabulary": null, "binary": false, "dtype": "<class 'numpy.int64'>", "_stop_words_id": 8798272}, "args": {"tokens": ["AI", "MANGE", "DU", "KANGOUROU", "CE", "MIDI", "ETAIT", "PAS", "TRES", "BON"], "stop_words": null}, "kwargs": {}}, "return": ["AI", "MANGE", "DU", "KANGOUROU", "CE", "MIDI", "ETAIT", "PAS", "TRES", "BON"]}, "name": "_word_ngrams"}
{"types": {}, "values": {"inputs": {"self": {"input": "content", "encoding": "utf-8", "decode_error": "strict", "strip_accents": "ascii", "preprocessor": null, "tokenizer": "<function split_tokenize at 0x70e60f77ae80>", "analyzer": "word", "lowercase": true, "token_pattern": "(?u)\\b\\w\\w+\\b", "stop_words": null, "max_df": 1.0, "min_df": 1, "max_features": null, "ngram_range": [1, 1], "vocabulary": null, "binary": false, "dtype": "<class 'numpy.int64'>", "_stop_words_id": 8798272}, "args": {"tokens": ["j'ai", "mange", "du", "kangourou", "ce", "midi,", "c'etait", "pas", "tres", "bon."], "stop_words": null}, "kwargs": {}}, "return": ["j'ai", "mange", "du", "kangourou", "ce", "midi,", "c'etait", "pas", "tres", "bon."]}, "name": "_word_ngrams"}
